{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f777b66-b5ce-4b51-a260-0f95e8c9dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "from numpy import hstack, vstack\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c268bd1-67cb-4cfb-842e-0bd9f4e75302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dkstj\\\\Desktop\\\\Rapid\\\\machine_learning'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_directory(foldername, filename = None, back_num = 0):\n",
    "    cur = os.getcwd()\n",
    "    for i in range(back_num):\n",
    "        cur = os.path.abspath(os.path.join(cur, os.pardir))\n",
    "    for folder in foldername:\n",
    "        cur = os.path.join(cur, folder)\n",
    "    if not os.path.exists(cur):\n",
    "        os.makedirs(cur)\n",
    "        print(f'{cur} created')\n",
    "    if filename != None:\n",
    "        cur = os.path.join(cur, filename)\n",
    "    return cur\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58e19cef-7f59-4f9c-a102-bce664fb00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_add = find_directory(foldername = [], filename = 'SOC_Point_Data.csv')\n",
    "dat = pd.read_csv(csv_add, index_col = (0,1,2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51190277-29e5-4a99-bb89-b99b751c7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Data_all(dat) :\n",
    "    \n",
    "    RPT_MODE = \"0.1C\"\n",
    "    SOC_Range = [9,10,11,12]\n",
    "\n",
    "    Time_Range = range(4, 1201, 2)\n",
    "    SOC_Range = [str(i) for i in SOC_Range]\n",
    "    \n",
    "    Data = dat\n",
    "\n",
    "    X = Data.loc[RPT_MODE, SOC_Range]\n",
    "    Y = Data.loc[RPT_MODE, [\"SOH\", \"Next_SOH\", \"Ratio_SOH\", \"Ratio_CYC\"]].groupby(level = [\"Next\", \"Path\", \"Number\"]).mean()\n",
    "    y = Y[\"Next_SOH\"]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19cdfd1a-dfb7-4066-ab61-9ef975b8d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Even_Split(X, y, test_size, rs):\n",
    "    XX = {n: X.xs(key=n, level='Next', drop_level=False) for n in [\"M\", \"D\", \"H\"]}\n",
    "    yy = {n: y.xs(key=n, level='Next', drop_level=False) for n in [\"M\", \"D\", \"H\"]}\n",
    "\n",
    "    XXX, yyy = {n: [] for n in [\"M\", \"D\", \"H\"]}, {n: [] for n in [\"M\", \"D\", \"H\"]}\n",
    "    for n in [\"M\", \"D\", \"H\"]:\n",
    "        for path in range(1, 5):\n",
    "            X_path = XX[n].loc[XX[n].index.get_level_values('Path').str.len() == path]\n",
    "            y_path = yy[n].loc[yy[n].index.get_level_values('Path').str.len() == path]\n",
    "\n",
    "            if 'Time' in y_path.index.names:\n",
    "                y_path = y_path.reset_index('Time', drop=True)\n",
    "\n",
    "            XXX[n].append(X_path)\n",
    "            yyy[n].append(y_path)\n",
    "\n",
    "    XX_tn, XX_te = {n: [] for n in [\"M\", \"D\", \"H\"]}, {n: [] for n in [\"M\", \"D\", \"H\"]}\n",
    "    yy_tn, yy_te = {n: [] for n in [\"M\", \"D\", \"H\"]}, {n: [] for n in [\"M\", \"D\", \"H\"]}\n",
    "\n",
    "    for n in [\"M\", \"D\", \"H\"]:\n",
    "        for path in range(1, 5):\n",
    "            X_temp = XXX[n][path-1]\n",
    "            y_temp = yyy[n][path-1]\n",
    "\n",
    "            cell_index = y_temp.index.drop_duplicates()\n",
    "\n",
    "            cells_tn, cells_te = train_test_split(cell_index, test_size=test_size, random_state=rs)\n",
    "\n",
    "            X_tn = X_temp[X_temp.index.droplevel('Time').isin(cells_tn)]\n",
    "            X_te = X_temp[X_temp.index.droplevel('Time').isin(cells_te)]\n",
    "\n",
    "            y_tn = y_temp.loc[cells_tn]\n",
    "            y_te = y_temp.loc[cells_te]\n",
    "\n",
    "            XX_tn[n].append(X_tn)\n",
    "            XX_te[n].append(X_te)\n",
    "            yy_tn[n].append(y_tn)\n",
    "            yy_te[n].append(y_te)\n",
    "\n",
    "    X_tn = pd.concat([pd.concat(XX_tn[n]) for n in [\"M\", \"D\", \"H\"]])\n",
    "    X_te = pd.concat([pd.concat(XX_te[n]) for n in [\"M\", \"D\", \"H\"]])\n",
    "    y_tn = pd.concat([pd.concat(yy_tn[n]) for n in [\"M\", \"D\", \"H\"]])\n",
    "    y_te = pd.concat([pd.concat(yy_te[n]) for n in [\"M\", \"D\", \"H\"]])\n",
    "\n",
    "    return X_tn, X_te, y_tn, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3133fc8d-0b8d-4c0c-b3bc-36226a0410d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor(X_tn, X_te, y_tn, y_te, batch_size=32, val_size=0.2, rs=100):\n",
    "    \"\"\"\n",
    "    X_tn, X_te: MultiIndex DataFrame (Next, Path, Number, Time)\n",
    "    y_tn, y_te: Series or DataFrame with index (Next, Path, Number)\n",
    "    \"\"\"\n",
    "\n",
    "    X_tr, X_vl, y_tr, y_vl = Even_Split(X_tn, y_tn, val_size, rs)\n",
    "    keys_train = y_tr.index\n",
    "    keys_val = y_vl.index\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_tn_scaled = X_tn.copy()\n",
    "    X_te_scaled = X_te.copy()\n",
    "\n",
    "    scaler.fit(X_tn.values)\n",
    "    X_tn_scaled.loc[:, :] = scaler.transform(X_tn.values)\n",
    "    X_te_scaled.loc[:, :] = scaler.transform(X_te.values)\n",
    "\n",
    "    next_map = {'M': 0, 'D': 1, 'H': 2}\n",
    "    get_next = lambda idx: torch.nn.functional.one_hot(torch.tensor([next_map[i] for i in idx.get_level_values(\"Next\")]), num_classes=3).float()\n",
    "\n",
    "    def to_tensor(X_df, y_df, keys):\n",
    "        X_group = X_df.groupby(level=[\"Next\", \"Path\", \"Number\"])\n",
    "        X_tensor = torch.stack([\n",
    "            torch.tensor(X_group.get_group(k).values, dtype=torch.float32)\n",
    "            for k in keys\n",
    "        ])\n",
    "        y_tensor = torch.tensor(y_df.loc[keys].values, dtype=torch.float32).unsqueeze(1)\n",
    "        return X_tensor, y_tensor\n",
    "\n",
    "    next_train = get_next(pd.MultiIndex.from_tuples(keys_train, names=[\"Next\", \"Path\", \"Number\"]))\n",
    "    next_val   = get_next(pd.MultiIndex.from_tuples(keys_val,   names=[\"Next\", \"Path\", \"Number\"]))\n",
    "    next_test  = get_next(y_te.index)\n",
    "    \n",
    "    X_train_tensor, y_train_tensor = to_tensor(X_tn_scaled, y_tn, keys_train)\n",
    "    X_val_tensor,   y_val_tensor   = to_tensor(X_tn_scaled, y_tn, keys_val)\n",
    "    X_test_tensor,  y_test_tensor  = to_tensor(X_te_scaled, y_te, y_te.index.drop_duplicates())\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train_tensor, next_train, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(TensorDataset(X_val_tensor, next_val,  y_val_tensor),   batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(TensorDataset(X_test_tensor, next_test,  y_test_tensor),  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, X_test_tensor, y_test_tensor, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a46fc84b-24e7-487b-a538-10e77c7e148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setRandomSeed(random_seed=0):\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a7a5600-ca48-42b9-a7d4-91ae59a8b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, lr=1e-3, weight_decay=0, epoch=1000, patience=50, random_seed = 0):\n",
    "        self.random_seed = random_seed\n",
    "        #setRandomSeed(self.random_seed)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.cri2 = MAPELoss()\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=200, gamma=0.8)\n",
    "        self.epoch = epoch\n",
    "        self.patience = patience\n",
    "\n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def train(self, train_loader, test_loader=None, val_loader=None):\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_state = None\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        for ep in range(1, self.epoch + 1):\n",
    "            self.model.train()\n",
    "            for x_batch, onehot, y_batch in train_loader:\n",
    "                x_batch, onehot, y_batch = x_batch.to(self.device), onehot.to(self.device), y_batch.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(x_batch, onehot)\n",
    "                loss = self.cri2(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            self.scheduler.step()\n",
    "\n",
    "            avg_train_loss = self.evaluate(train_loader)\n",
    "            test_loss = self.evaluate(test_loader) if test_loader else None\n",
    "            val_loss = self.evaluate(val_loader) if val_loader else None\n",
    "\n",
    "            self.train_loss.append(avg_train_loss)\n",
    "            self.test_loss.append(test_loss)\n",
    "            self.val_loss.append(val_loss)\n",
    "\n",
    "            if val_loader:\n",
    "                if val_loss < best_val_loss - 1e-4:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_model_state = self.model.state_dict()\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    if epochs_no_improve >= self.patience:\n",
    "                        print(f\"Early stopping at epoch {ep}\")\n",
    "                        break\n",
    "\n",
    "        if best_model_state:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        if data_loader is None:\n",
    "            return None\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, onehot, y_batch in data_loader:\n",
    "                x_batch, onehot, y_batch = x_batch.to(self.device), onehot.to(self.device), y_batch.to(self.device)\n",
    "                outputs = self.model(x_batch, onehot)\n",
    "                loss = self.cri2(outputs, y_batch)\n",
    "                total_loss += loss.item()\n",
    "        return total_loss / len(data_loader)\n",
    "\n",
    "    def predict(self, x, onehot):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = x.to(self.device)\n",
    "            onehot = onehot.to(self.device)\n",
    "            return self.model(x, onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9feefaab-7522-4dfb-8e3d-64e935acdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(model, info, train_loader, val_loader, test_loader, plot = True):\n",
    "    rs, rnn_hid, rnn_layer = info\n",
    "    \n",
    "    y_true_train = []\n",
    "    y_pred_train = []\n",
    "    \n",
    "    y_true_val = []\n",
    "    y_pred_val = []\n",
    "    \n",
    "    y_true_test = []\n",
    "    y_pred_test = []\n",
    "\n",
    "    y_true_test_M = []\n",
    "    y_pred_test_M = []\n",
    "\n",
    "    y_true_test_D = []\n",
    "    y_pred_test_D = []\n",
    "\n",
    "    y_true_test_H = []\n",
    "    y_pred_test_H = []\n",
    "    \n",
    "    for x_batch, onehot, y_batch in train_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_train.append(y_batch)\n",
    "        y_pred_train.append(preds.cpu())\n",
    "    \n",
    "    for x_batch, onehot, y_batch in val_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_val.append(y_batch)\n",
    "        y_pred_val.append(preds.cpu())\n",
    "    \n",
    "    for x_batch, onehot, y_batch in test_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_test.append(y_batch)\n",
    "        y_pred_test.append(preds.cpu())\n",
    "    \n",
    "        onehot_np = onehot.cpu().numpy()\n",
    "        y_true_np = y_batch.cpu().numpy()\n",
    "        y_pred_np = preds.cpu().numpy()\n",
    "    \n",
    "        for i in range(len(onehot_np)):\n",
    "            if np.array_equal(onehot_np[i], [1, 0, 0]):  # 'M'\n",
    "                y_true_test_M.append(y_true_np[i])\n",
    "                y_pred_test_M.append(y_pred_np[i])\n",
    "            elif np.array_equal(onehot_np[i], [0, 1, 0]):  # 'D'\n",
    "                y_true_test_D.append(y_true_np[i])\n",
    "                y_pred_test_D.append(y_pred_np[i])\n",
    "            elif np.array_equal(onehot_np[i], [0, 0, 1]):  # 'H'\n",
    "                y_true_test_H.append(y_true_np[i])\n",
    "                y_pred_test_H.append(y_pred_np[i])\n",
    "    \n",
    "    y_true_train = torch.cat(y_true_train).numpy()\n",
    "    y_pred_train = torch.cat(y_pred_train).numpy()\n",
    "    \n",
    "    y_true_val = torch.cat(y_true_val).numpy()\n",
    "    y_pred_val = torch.cat(y_pred_val).numpy()\n",
    "    \n",
    "    y_true_test = torch.cat(y_true_test).numpy()\n",
    "    y_pred_test = torch.cat(y_pred_test).numpy()\n",
    "\n",
    "    y_true_test_M = np.array(y_true_test_M)\n",
    "    y_pred_test_M = np.array(y_pred_test_M)\n",
    "    \n",
    "    y_true_test_D = np.array(y_true_test_D)\n",
    "    y_pred_test_D = np.array(y_pred_test_D)\n",
    "    \n",
    "    y_true_test_H = np.array(y_true_test_H)\n",
    "    y_pred_test_H = np.array(y_pred_test_H)\n",
    "    \n",
    "    mape_M = mean_absolute_percentage_error(y_true_test_M, y_pred_test_M) * 100 if len(y_true_test_M) > 0 else np.nan\n",
    "    mape_D = mean_absolute_percentage_error(y_true_test_D, y_pred_test_D) * 100 if len(y_true_test_D) > 0 else np.nan\n",
    "    mape_H = mean_absolute_percentage_error(y_true_test_H, y_pred_test_H) * 100 if len(y_true_test_H) > 0 else np.nan\n",
    "    \n",
    "    train_mape = mean_absolute_percentage_error(y_true_train, y_pred_train) * 100\n",
    "    val_mape = mean_absolute_percentage_error(y_true_val, y_pred_val) * 100\n",
    "    test_mape = mean_absolute_percentage_error(y_true_test, y_pred_test) * 100\n",
    "    print(f\"Model: {model}, rs: {rs}, hid: {rnn_hid}, layer: {rnn_layer}\\n Train MAPE: {train_mape:.2f}%, Val MAPE: {val_mape:.2f}%, Test MAPE: {test_mape:.2f}%\")\n",
    "    print(f\"Test MAPE by 'Next': M: {mape_M:.2f}%, D: {mape_D:.2f}%, H: {mape_H:.2f}%\")\n",
    "    \n",
    "    if plot == True:\n",
    "        _ = plt.figure()\n",
    "        _ = plt.scatter(y_true_train, y_pred_train, label = 'Train')\n",
    "        _ = plt.scatter(y_true_val, y_pred_val, label = 'Val')\n",
    "        _ = plt.scatter(y_true_test, y_pred_test, label = 'Test')\n",
    "        min_val = min(y_true_train.min(), y_true_test.min())\n",
    "        max_val = max(y_true_train.max(), y_true_test.max())\n",
    "        _ = plt.plot([min_val, max_val], [min_val, max_val], 'k--', label='Ideal line')\n",
    "        _ = plt.xlabel('True SOH')\n",
    "        _ = plt.ylabel('Predicted SOH')\n",
    "        _ = plt.legend()\n",
    "        _ = plt.title(f'Random state: {rs}, hid: {hid}, {nl} layer, lr: {lr}')\n",
    "    return train_mape, val_mape, test_mape, mape_M, mape_D, mape_H\n",
    "\n",
    "def plot_loss(info, train_loss, val_loss, test_loss):\n",
    "    rs, c1, c2, k1, k2 = info\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(train_loss, label = 'Train loss')\n",
    "    _ = plt.plot(val_loss, label = 'Val loss')\n",
    "    _ = plt.plot(test_loss, label = 'Test loss')\n",
    "    _ = plt.ylim([0, 2])\n",
    "    _ = plt.xlabel('Epoch')\n",
    "    _ = plt.ylabel('Loss')\n",
    "    _ = plt.legend()\n",
    "    _ = plt.title(f'Random state: {rs}, hid: {hid}, {nl} layers, lr: {lr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd12095-98bf-4144-9920-4d6a042b0b11",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5f5b70d-f010-49c0-8bfb-e6fe81fc0d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_Compressor(nn.Module):\n",
    "    def __init__(self, input_dim=4, hidden_dim=64, num_layers=1, output_dim=4):\n",
    "        super(GRU_Compressor, self).__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, h_n = self.gru(x)\n",
    "        h_last = h_n[-1]\n",
    "        return self.fc(h_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ab81703-2c07-484c-910f-12d4e46abdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_MLP(nn.Module):\n",
    "    def __init__(self, rnn_hid = 64, rnn_layers = 1, out_dim=4, hidden_dim=64, num_layers=2, next_dim = 3):\n",
    "        super(GRU_MLP, self).__init__()\n",
    "        self.encoder = GRU_Compressor(out_dim, rnn_hid, rnn_layers, out_dim)\n",
    "        \n",
    "        layers = []\n",
    "\n",
    "        input_dim = out_dim + next_dim\n",
    "        output_dim = 1\n",
    "\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, onehot):\n",
    "        x_feat = self.encoder(x)\n",
    "        x_concat = torch.cat([x_feat, onehot], dim=1)\n",
    "        return self.model(x_concat)\n",
    "\n",
    "class MAPELoss(nn.Module):\n",
    "    def __init__(self, epsilon=1e-7):\n",
    "        super(MAPELoss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.mean(torch.abs((y_true - y_pred) / (y_true + self.epsilon))) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b885de-fb30-489f-9710-8d5db83d8767",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dd8064f-8cbf-40f3-b87a-978d97e09ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 66\n",
      "Model: GRU, rs: 100, hid: 8, layer: 1\n",
      " Train MAPE: 0.93%, Val MAPE: 1.21%, Test MAPE: 1.28%\n",
      "Test MAPE by 'Next': M: 1.35%, D: 1.33%, H: 1.16%\n",
      "9.76 s\n",
      "Early stopping at epoch 73\n",
      "Model: GRU, rs: 100, hid: 8, layer: 2\n",
      " Train MAPE: 1.02%, Val MAPE: 1.34%, Test MAPE: 1.28%\n",
      "Test MAPE by 'Next': M: 1.32%, D: 1.39%, H: 1.13%\n",
      "13.75 s\n",
      "Early stopping at epoch 67\n",
      "Model: GRU, rs: 100, hid: 8, layer: 3\n",
      " Train MAPE: 0.89%, Val MAPE: 1.06%, Test MAPE: 1.22%\n",
      "Test MAPE by 'Next': M: 1.27%, D: 1.20%, H: 1.19%\n",
      "13.63 s\n",
      "Early stopping at epoch 74\n",
      "Model: GRU, rs: 100, hid: 16, layer: 1\n",
      " Train MAPE: 0.99%, Val MAPE: 1.28%, Test MAPE: 1.26%\n",
      "Test MAPE by 'Next': M: 1.29%, D: 1.37%, H: 1.12%\n",
      "11.13 s\n",
      "Early stopping at epoch 77\n",
      "Model: GRU, rs: 100, hid: 16, layer: 2\n",
      " Train MAPE: 0.90%, Val MAPE: 1.03%, Test MAPE: 1.19%\n",
      "Test MAPE by 'Next': M: 1.26%, D: 1.17%, H: 1.15%\n",
      "13.72 s\n",
      "Early stopping at epoch 79\n",
      "Model: GRU, rs: 100, hid: 16, layer: 3\n",
      " Train MAPE: 0.87%, Val MAPE: 1.12%, Test MAPE: 1.16%\n",
      "Test MAPE by 'Next': M: 1.19%, D: 1.21%, H: 1.08%\n",
      "16.14 s\n",
      "Early stopping at epoch 80\n",
      "Model: GRU, rs: 100, hid: 32, layer: 1\n",
      " Train MAPE: 1.25%, Val MAPE: 1.54%, Test MAPE: 1.38%\n",
      "Test MAPE by 'Next': M: 1.41%, D: 1.47%, H: 1.26%\n",
      "11.84 s\n",
      "Early stopping at epoch 123\n",
      "Model: GRU, rs: 100, hid: 32, layer: 2\n",
      " Train MAPE: 0.94%, Val MAPE: 1.02%, Test MAPE: 1.14%\n",
      "Test MAPE by 'Next': M: 1.18%, D: 1.19%, H: 1.06%\n",
      "21.89 s\n",
      "Early stopping at epoch 151\n",
      "Model: GRU, rs: 100, hid: 32, layer: 3\n",
      " Train MAPE: 0.92%, Val MAPE: 1.10%, Test MAPE: 1.20%\n",
      "Test MAPE by 'Next': M: 1.23%, D: 1.39%, H: 0.97%\n",
      "30.02 s\n",
      "Early stopping at epoch 88\n",
      "Model: GRU, rs: 100, hid: 64, layer: 1\n",
      " Train MAPE: 1.29%, Val MAPE: 1.43%, Test MAPE: 1.45%\n",
      "Test MAPE by 'Next': M: 1.42%, D: 1.66%, H: 1.28%\n",
      "13.88 s\n",
      "Early stopping at epoch 105\n",
      "Model: GRU, rs: 100, hid: 64, layer: 2\n",
      " Train MAPE: 0.92%, Val MAPE: 0.98%, Test MAPE: 1.13%\n",
      "Test MAPE by 'Next': M: 1.17%, D: 1.16%, H: 1.05%\n",
      "19.73 s\n",
      "Early stopping at epoch 83\n",
      "Model: GRU, rs: 100, hid: 64, layer: 3\n",
      " Train MAPE: 1.14%, Val MAPE: 1.04%, Test MAPE: 1.30%\n",
      "Test MAPE by 'Next': M: 1.31%, D: 1.39%, H: 1.21%\n",
      "18.49 s\n",
      "Early stopping at epoch 156\n",
      "Model: GRU, rs: 120, hid: 8, layer: 1\n",
      " Train MAPE: 1.03%, Val MAPE: 0.95%, Test MAPE: 0.80%\n",
      "Test MAPE by 'Next': M: 0.91%, D: 0.71%, H: 0.79%\n",
      "23.18 s\n",
      "Early stopping at epoch 258\n",
      "Model: GRU, rs: 120, hid: 8, layer: 2\n",
      " Train MAPE: 0.96%, Val MAPE: 0.95%, Test MAPE: 0.91%\n",
      "Test MAPE by 'Next': M: 1.03%, D: 0.80%, H: 0.90%\n",
      "45.03 s\n",
      "Early stopping at epoch 343\n",
      "Model: GRU, rs: 120, hid: 8, layer: 3\n",
      " Train MAPE: 0.97%, Val MAPE: 0.96%, Test MAPE: 0.81%\n",
      "Test MAPE by 'Next': M: 0.89%, D: 0.77%, H: 0.76%\n",
      "61.06 s\n",
      "Early stopping at epoch 168\n",
      "Model: GRU, rs: 120, hid: 16, layer: 1\n",
      " Train MAPE: 1.10%, Val MAPE: 0.93%, Test MAPE: 0.82%\n",
      "Test MAPE by 'Next': M: 0.94%, D: 0.71%, H: 0.80%\n",
      "21.38 s\n",
      "Early stopping at epoch 112\n",
      "Model: GRU, rs: 120, hid: 16, layer: 2\n",
      " Train MAPE: 1.03%, Val MAPE: 0.92%, Test MAPE: 0.80%\n",
      "Test MAPE by 'Next': M: 0.90%, D: 0.75%, H: 0.75%\n",
      "17.18 s\n",
      "Early stopping at epoch 211\n",
      "Model: GRU, rs: 120, hid: 16, layer: 3\n",
      " Train MAPE: 1.84%, Val MAPE: 1.58%, Test MAPE: 1.71%\n",
      "Test MAPE by 'Next': M: 1.76%, D: 1.68%, H: 1.69%\n",
      "36.67 s\n",
      "Early stopping at epoch 169\n",
      "Model: GRU, rs: 120, hid: 32, layer: 1\n",
      " Train MAPE: 1.05%, Val MAPE: 0.93%, Test MAPE: 0.86%\n",
      "Test MAPE by 'Next': M: 0.97%, D: 0.78%, H: 0.83%\n",
      "21.21 s\n",
      "Early stopping at epoch 316\n",
      "Model: GRU, rs: 120, hid: 32, layer: 2\n",
      " Train MAPE: 1.25%, Val MAPE: 1.20%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: 0.89%, D: 0.95%, H: 0.97%\n",
      "46.68 s\n",
      "Early stopping at epoch 194\n",
      "Model: GRU, rs: 120, hid: 32, layer: 3\n",
      " Train MAPE: 1.23%, Val MAPE: 1.02%, Test MAPE: 0.96%\n",
      "Test MAPE by 'Next': M: 1.04%, D: 0.84%, H: 1.00%\n",
      "33.04 s\n",
      "Early stopping at epoch 202\n",
      "Model: GRU, rs: 120, hid: 64, layer: 1\n",
      " Train MAPE: 1.18%, Val MAPE: 1.14%, Test MAPE: 0.83%\n",
      "Test MAPE by 'Next': M: 0.87%, D: 0.79%, H: 0.84%\n",
      "26.49 s\n",
      "Early stopping at epoch 125\n",
      "Model: GRU, rs: 120, hid: 64, layer: 2\n",
      " Train MAPE: 1.14%, Val MAPE: 0.96%, Test MAPE: 0.98%\n",
      "Test MAPE by 'Next': M: 1.12%, D: 0.92%, H: 0.92%\n",
      "20.30 s\n",
      "Early stopping at epoch 94\n",
      "Model: GRU, rs: 120, hid: 64, layer: 3\n",
      " Train MAPE: 1.15%, Val MAPE: 0.88%, Test MAPE: 0.96%\n",
      "Test MAPE by 'Next': M: 0.98%, D: 0.85%, H: 1.04%\n",
      "18.04 s\n",
      "Early stopping at epoch 284\n",
      "Model: GRU, rs: 140, hid: 8, layer: 1\n",
      " Train MAPE: 0.95%, Val MAPE: 1.17%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 1.05%, D: 1.28%, H: 1.01%\n",
      "34.90 s\n",
      "Early stopping at epoch 195\n",
      "Model: GRU, rs: 140, hid: 8, layer: 2\n",
      " Train MAPE: 0.83%, Val MAPE: 1.16%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: 1.02%, D: 1.04%, H: 0.95%\n",
      "28.92 s\n",
      "Early stopping at epoch 239\n",
      "Model: GRU, rs: 140, hid: 8, layer: 3\n",
      " Train MAPE: 1.18%, Val MAPE: 1.23%, Test MAPE: 1.29%\n",
      "Test MAPE by 'Next': M: 1.44%, D: 1.14%, H: 1.28%\n",
      "40.64 s\n",
      "Early stopping at epoch 182\n",
      "Model: GRU, rs: 140, hid: 16, layer: 1\n",
      " Train MAPE: 0.92%, Val MAPE: 1.04%, Test MAPE: 1.00%\n",
      "Test MAPE by 'Next': M: 1.03%, D: 1.04%, H: 0.93%\n",
      "22.89 s\n",
      "Early stopping at epoch 211\n",
      "Model: GRU, rs: 140, hid: 16, layer: 2\n",
      " Train MAPE: 0.86%, Val MAPE: 1.20%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.02%, D: 1.12%, H: 1.00%\n",
      "32.44 s\n",
      "Early stopping at epoch 129\n",
      "Model: GRU, rs: 140, hid: 16, layer: 3\n",
      " Train MAPE: 0.91%, Val MAPE: 1.06%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: 1.20%, D: 0.99%, H: 0.95%\n",
      "24.12 s\n",
      "Early stopping at epoch 224\n",
      "Model: GRU, rs: 140, hid: 32, layer: 1\n",
      " Train MAPE: 0.91%, Val MAPE: 1.18%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: 1.02%, D: 1.03%, H: 1.00%\n",
      "29.07 s\n",
      "Early stopping at epoch 357\n",
      "Model: GRU, rs: 140, hid: 32, layer: 2\n",
      " Train MAPE: 0.91%, Val MAPE: 1.04%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: 1.09%, D: 1.01%, H: 0.93%\n",
      "55.17 s\n",
      "Early stopping at epoch 134\n",
      "Model: GRU, rs: 140, hid: 32, layer: 3\n",
      " Train MAPE: 1.50%, Val MAPE: 1.72%, Test MAPE: 1.55%\n",
      "Test MAPE by 'Next': M: 1.67%, D: 1.43%, H: 1.55%\n",
      "21.98 s\n",
      "Early stopping at epoch 289\n",
      "Model: GRU, rs: 140, hid: 64, layer: 1\n",
      " Train MAPE: 0.94%, Val MAPE: 1.05%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 1.08%, D: 1.05%, H: 0.96%\n",
      "39.52 s\n",
      "Early stopping at epoch 208\n",
      "Model: GRU, rs: 140, hid: 64, layer: 2\n",
      " Train MAPE: 0.89%, Val MAPE: 1.10%, Test MAPE: 1.09%\n",
      "Test MAPE by 'Next': M: 1.19%, D: 1.06%, H: 1.02%\n",
      "35.51 s\n",
      "Early stopping at epoch 290\n",
      "Model: GRU, rs: 140, hid: 64, layer: 3\n",
      " Train MAPE: 0.82%, Val MAPE: 1.22%, Test MAPE: 1.14%\n",
      "Test MAPE by 'Next': M: 1.24%, D: 1.10%, H: 1.07%\n",
      "57.01 s\n",
      "Early stopping at epoch 90\n",
      "Model: GRU, rs: 160, hid: 8, layer: 1\n",
      " Train MAPE: 1.04%, Val MAPE: 0.96%, Test MAPE: 1.09%\n",
      "Test MAPE by 'Next': M: 1.24%, D: 0.99%, H: 1.05%\n",
      "12.00 s\n",
      "Early stopping at epoch 128\n",
      "Model: GRU, rs: 160, hid: 8, layer: 2\n",
      " Train MAPE: 1.08%, Val MAPE: 1.15%, Test MAPE: 1.21%\n",
      "Test MAPE by 'Next': M: 1.40%, D: 1.11%, H: 1.13%\n",
      "19.74 s\n",
      "Early stopping at epoch 142\n",
      "Model: GRU, rs: 160, hid: 8, layer: 3\n",
      " Train MAPE: 1.11%, Val MAPE: 1.07%, Test MAPE: 1.14%\n",
      "Test MAPE by 'Next': M: 1.26%, D: 1.08%, H: 1.09%\n",
      "25.31 s\n",
      "Early stopping at epoch 142\n",
      "Model: GRU, rs: 160, hid: 16, layer: 1\n",
      " Train MAPE: 0.92%, Val MAPE: 0.98%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: 1.33%, D: 0.92%, H: 0.86%\n",
      "18.17 s\n",
      "Early stopping at epoch 112\n",
      "Model: GRU, rs: 160, hid: 16, layer: 2\n",
      " Train MAPE: 0.97%, Val MAPE: 1.00%, Test MAPE: 1.06%\n",
      "Test MAPE by 'Next': M: 1.27%, D: 0.93%, H: 1.00%\n",
      "17.59 s\n",
      "Early stopping at epoch 242\n",
      "Model: GRU, rs: 160, hid: 16, layer: 3\n",
      " Train MAPE: 0.98%, Val MAPE: 0.99%, Test MAPE: 0.99%\n",
      "Test MAPE by 'Next': M: 1.11%, D: 0.93%, H: 0.94%\n",
      "43.28 s\n",
      "Early stopping at epoch 150\n",
      "Model: GRU, rs: 160, hid: 32, layer: 1\n",
      " Train MAPE: 0.89%, Val MAPE: 1.09%, Test MAPE: 1.06%\n",
      "Test MAPE by 'Next': M: 1.29%, D: 0.88%, H: 0.99%\n",
      "19.43 s\n",
      "Early stopping at epoch 78\n",
      "Model: GRU, rs: 160, hid: 32, layer: 2\n",
      " Train MAPE: 1.18%, Val MAPE: 1.21%, Test MAPE: 1.28%\n",
      "Test MAPE by 'Next': M: 1.30%, D: 1.12%, H: 1.42%\n",
      "12.32 s\n",
      "Early stopping at epoch 199\n",
      "Model: GRU, rs: 160, hid: 32, layer: 3\n",
      " Train MAPE: 0.98%, Val MAPE: 1.19%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: 1.19%, D: 1.03%, H: 1.03%\n",
      "34.90 s\n",
      "Early stopping at epoch 196\n",
      "Model: GRU, rs: 160, hid: 64, layer: 1\n",
      " Train MAPE: 0.95%, Val MAPE: 0.97%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.22%, D: 0.98%, H: 0.97%\n",
      "26.44 s\n",
      "Early stopping at epoch 138\n",
      "Model: GRU, rs: 160, hid: 64, layer: 2\n",
      " Train MAPE: 1.39%, Val MAPE: 1.67%, Test MAPE: 1.36%\n",
      "Test MAPE by 'Next': M: 1.45%, D: 1.35%, H: 1.26%\n",
      "23.09 s\n",
      "Early stopping at epoch 132\n",
      "Model: GRU, rs: 160, hid: 64, layer: 3\n",
      " Train MAPE: 1.05%, Val MAPE: 1.06%, Test MAPE: 1.18%\n",
      "Test MAPE by 'Next': M: 1.30%, D: 1.14%, H: 1.11%\n",
      "26.70 s\n",
      "Early stopping at epoch 197\n",
      "Model: GRU, rs: 180, hid: 8, layer: 1\n",
      " Train MAPE: 1.16%, Val MAPE: 1.57%, Test MAPE: 0.97%\n",
      "Test MAPE by 'Next': M: 1.03%, D: 0.83%, H: 1.06%\n",
      "25.67 s\n",
      "Early stopping at epoch 164\n",
      "Model: GRU, rs: 180, hid: 8, layer: 2\n",
      " Train MAPE: 0.93%, Val MAPE: 1.41%, Test MAPE: 1.06%\n",
      "Test MAPE by 'Next': M: 1.08%, D: 1.06%, H: 1.02%\n",
      "25.83 s\n",
      "Early stopping at epoch 269\n",
      "Model: GRU, rs: 180, hid: 8, layer: 3\n",
      " Train MAPE: 1.06%, Val MAPE: 1.28%, Test MAPE: 1.19%\n",
      "Test MAPE by 'Next': M: 1.27%, D: 1.07%, H: 1.22%\n",
      "45.85 s\n",
      "Early stopping at epoch 274\n",
      "Model: GRU, rs: 180, hid: 16, layer: 1\n",
      " Train MAPE: 1.08%, Val MAPE: 1.55%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: 1.05%, D: 0.90%, H: 0.86%\n",
      "35.05 s\n",
      "Early stopping at epoch 251\n",
      "Model: GRU, rs: 180, hid: 16, layer: 2\n",
      " Train MAPE: 0.86%, Val MAPE: 1.26%, Test MAPE: 0.90%\n",
      "Test MAPE by 'Next': M: 1.04%, D: 0.82%, H: 0.86%\n",
      "38.64 s\n",
      "Early stopping at epoch 163\n",
      "Model: GRU, rs: 180, hid: 16, layer: 3\n",
      " Train MAPE: 1.04%, Val MAPE: 1.43%, Test MAPE: 0.92%\n",
      "Test MAPE by 'Next': M: 0.96%, D: 0.85%, H: 0.96%\n",
      "28.84 s\n",
      "Early stopping at epoch 393\n",
      "Model: GRU, rs: 180, hid: 32, layer: 1\n",
      " Train MAPE: 0.74%, Val MAPE: 1.24%, Test MAPE: 0.92%\n",
      "Test MAPE by 'Next': M: 1.09%, D: 0.80%, H: 0.87%\n",
      "49.76 s\n",
      "Early stopping at epoch 178\n",
      "Model: GRU, rs: 180, hid: 32, layer: 2\n",
      " Train MAPE: 0.94%, Val MAPE: 1.26%, Test MAPE: 0.89%\n",
      "Test MAPE by 'Next': M: 0.93%, D: 0.85%, H: 0.87%\n",
      "27.29 s\n",
      "Early stopping at epoch 294\n",
      "Model: GRU, rs: 180, hid: 32, layer: 3\n",
      " Train MAPE: 0.69%, Val MAPE: 1.18%, Test MAPE: 0.81%\n",
      "Test MAPE by 'Next': M: 1.01%, D: 0.70%, H: 0.72%\n",
      "51.56 s\n",
      "Early stopping at epoch 257\n",
      "Model: GRU, rs: 180, hid: 64, layer: 1\n",
      " Train MAPE: 1.08%, Val MAPE: 1.39%, Test MAPE: 1.26%\n",
      "Test MAPE by 'Next': M: 1.27%, D: 1.26%, H: 1.25%\n",
      "34.45 s\n",
      "Early stopping at epoch 271\n",
      "Model: GRU, rs: 180, hid: 64, layer: 2\n",
      " Train MAPE: 1.06%, Val MAPE: 1.30%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: 0.96%, D: 0.92%, H: 0.93%\n",
      "44.89 s\n",
      "Early stopping at epoch 293\n",
      "Model: GRU, rs: 180, hid: 64, layer: 3\n",
      " Train MAPE: 0.72%, Val MAPE: 1.10%, Test MAPE: 0.88%\n",
      "Test MAPE by 'Next': M: 1.11%, D: 0.71%, H: 0.83%\n",
      "57.61 s\n"
     ]
    }
   ],
   "source": [
    "random_states = [100, 120, 140, 160, 180]\n",
    "bs = 12\n",
    "ep = 1000\n",
    "hid = 16\n",
    "layer = 5\n",
    "lr = 1e-3\n",
    "\n",
    "rnn_hids = [8, 16, 32, 64]\n",
    "rnn_layers = [1, 2, 3]\n",
    "\n",
    "results_df = pd.DataFrame(columns = ['rs', 'hids', 'layers', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE'])\n",
    "\n",
    "X, y = Get_Data_all(dat)\n",
    "\n",
    "for rs, rnn_hid, rnn_layer in product(random_states, rnn_hids, rnn_layers):\n",
    "    setRandomSeed(rs)\n",
    "    start = time.time()\n",
    "    X_tn, X_te, y_tn, y_te = Even_Split(X, y, 1/3, rs)\n",
    "    train_loader, val_loader, test_loader, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, X_test_tensor, y_test_tensor, scaler = convert_to_tensor(X_tn, X_te, y_tn, y_te, bs, 1/6, rs)\n",
    "\n",
    "    model = GRU_MLP(rnn_hid, rnn_layer, 4, hid, layer)\n",
    "    trainer = Trainer(model, lr=lr, epoch = ep, random_seed = rs)\n",
    "    \n",
    "    trainer.train(train_loader, val_loader, test_loader)\n",
    "\n",
    "    info = [rs, rnn_hid, rnn_layer]\n",
    "    results = plot_results(\"GRU\", info, train_loader, val_loader, test_loader, plot = False)\n",
    "\n",
    "    temp_df = pd.DataFrame(info+list(results)).T\n",
    "    temp_df.columns = ['rs', 'hids', 'layers', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']\n",
    "    results_df = pd.concat([results_df, temp_df])\n",
    "    print(f\"{time.time()-start:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4819d6c3-d539-4de0-9e83-ed6af617fa12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hids</th>\n",
       "      <th>layers</th>\n",
       "      <th>Train MAPE</th>\n",
       "      <th>Val MAPE</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Next M MAPE</th>\n",
       "      <th>Next D MAPE</th>\n",
       "      <th>Next H MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.020543</td>\n",
       "      <td>1.171531</td>\n",
       "      <td>1.051753</td>\n",
       "      <td>1.115015</td>\n",
       "      <td>1.026099</td>\n",
       "      <td>1.014146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.965584</td>\n",
       "      <td>1.201139</td>\n",
       "      <td>1.092418</td>\n",
       "      <td>1.172717</td>\n",
       "      <td>1.078507</td>\n",
       "      <td>1.026028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.041277</td>\n",
       "      <td>1.119393</td>\n",
       "      <td>1.128921</td>\n",
       "      <td>1.226177</td>\n",
       "      <td>1.052244</td>\n",
       "      <td>1.108342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999772</td>\n",
       "      <td>1.156515</td>\n",
       "      <td>1.009695</td>\n",
       "      <td>1.128865</td>\n",
       "      <td>0.987104</td>\n",
       "      <td>0.913116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.923666</td>\n",
       "      <td>1.084187</td>\n",
       "      <td>1.001379</td>\n",
       "      <td>1.097347</td>\n",
       "      <td>0.955155</td>\n",
       "      <td>0.951634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.128688</td>\n",
       "      <td>1.234996</td>\n",
       "      <td>1.165114</td>\n",
       "      <td>1.241601</td>\n",
       "      <td>1.130627</td>\n",
       "      <td>1.123115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970907</td>\n",
       "      <td>1.197753</td>\n",
       "      <td>1.046497</td>\n",
       "      <td>1.156167</td>\n",
       "      <td>0.992858</td>\n",
       "      <td>0.990466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.044468</td>\n",
       "      <td>1.144383</td>\n",
       "      <td>1.052187</td>\n",
       "      <td>1.079600</td>\n",
       "      <td>1.025232</td>\n",
       "      <td>1.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.063556</td>\n",
       "      <td>1.240974</td>\n",
       "      <td>1.122086</td>\n",
       "      <td>1.228571</td>\n",
       "      <td>1.081680</td>\n",
       "      <td>1.056008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.091435</td>\n",
       "      <td>1.195207</td>\n",
       "      <td>1.126048</td>\n",
       "      <td>1.172663</td>\n",
       "      <td>1.146710</td>\n",
       "      <td>1.058770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.079362</td>\n",
       "      <td>1.201868</td>\n",
       "      <td>1.098991</td>\n",
       "      <td>1.178329</td>\n",
       "      <td>1.083163</td>\n",
       "      <td>1.035481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>1.060358</td>\n",
       "      <td>1.092618</td>\n",
       "      <td>1.188311</td>\n",
       "      <td>1.038718</td>\n",
       "      <td>1.050824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hids  layers  Train MAPE  Val MAPE  Test MAPE  Next M MAPE  Next D MAPE  \\\n",
       "0    8.0     1.0    1.020543  1.171531   1.051753     1.115015     1.026099   \n",
       "1    8.0     2.0    0.965584  1.201139   1.092418     1.172717     1.078507   \n",
       "2    8.0     3.0    1.041277  1.119393   1.128921     1.226177     1.052244   \n",
       "3   16.0     1.0    0.999772  1.156515   1.009695     1.128865     0.987104   \n",
       "4   16.0     2.0    0.923666  1.084187   1.001379     1.097347     0.955155   \n",
       "5   16.0     3.0    1.128688  1.234996   1.165114     1.241601     1.130627   \n",
       "6   32.0     1.0    0.970907  1.197753   1.046497     1.156167     0.992858   \n",
       "7   32.0     2.0    1.044468  1.144383   1.052187     1.079600     1.025232   \n",
       "8   32.0     3.0    1.063556  1.240974   1.122086     1.228571     1.081680   \n",
       "9   64.0     1.0    1.091435  1.195207   1.126048     1.172663     1.146710   \n",
       "10  64.0     2.0    1.079362  1.201868   1.098991     1.178329     1.083163   \n",
       "11  64.0     3.0    0.976682  1.060358   1.092618     1.188311     1.038718   \n",
       "\n",
       "    Next H MAPE  \n",
       "0      1.014146  \n",
       "1      1.026028  \n",
       "2      1.108342  \n",
       "3      0.913116  \n",
       "4      0.951634  \n",
       "5      1.123115  \n",
       "6      0.990466  \n",
       "7      1.051731  \n",
       "8      1.056008  \n",
       "9      1.058770  \n",
       "10     1.035481  \n",
       "11     1.050824  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = results_df.groupby(['hids', 'layers'])[['Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']].mean().reset_index()\n",
    "summary_df\n",
    "summary_df.to_csv('GRU_next_info_sum.csv')\n",
    "results_df.to_csv('GRU_next_info.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
