{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f777b66-b5ce-4b51-a260-0f95e8c9dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "from numpy import hstack, vstack\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c268bd1-67cb-4cfb-842e-0bd9f4e75302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dkstj\\\\Desktop\\\\Rapid\\\\machine_learning'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_directory(foldername, filename = None, back_num = 0):\n",
    "    cur = os.getcwd()\n",
    "    for i in range(back_num):\n",
    "        cur = os.path.abspath(os.path.join(cur, os.pardir))\n",
    "    for folder in foldername:\n",
    "        cur = os.path.join(cur, folder)\n",
    "    if not os.path.exists(cur):\n",
    "        os.makedirs(cur)\n",
    "        print(f'{cur} created')\n",
    "    if filename != None:\n",
    "        cur = os.path.join(cur, filename)\n",
    "    return cur\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58e19cef-7f59-4f9c-a102-bce664fb00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_add = find_directory(foldername = [], filename = 'SOC_Point_Data.csv')\n",
    "dat = pd.read_csv(csv_add, index_col = (0,1,2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51190277-29e5-4a99-bb89-b99b751c7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Data_all(dat) :\n",
    "    \n",
    "    RPT_MODE = \"0.1C\"\n",
    "    SOC_Range = [9,10,11,12]\n",
    "\n",
    "    Time_Range = range(4, 1201, 2)\n",
    "    SOC_Range = [str(i) for i in SOC_Range]\n",
    "    \n",
    "    Data = dat\n",
    "\n",
    "    X = Data.loc[RPT_MODE, SOC_Range]\n",
    "    Y = Data.loc[RPT_MODE, [\"SOH\", \"Next_SOH\", \"Ratio_SOH\", \"Ratio_CYC\"]].groupby(level = [\"Next\", \"Path\", \"Number\"]).mean()\n",
    "    y = Y[\"Next_SOH\"]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19cdfd1a-dfb7-4066-ab61-9ef975b8d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Even_Split(X, y, test_size, rs):\n",
    "    XX = {n: X.xs(key=n, level='Next', drop_level=False) for n in [\"M\", \"D\", \"H\"]}\n",
    "    yy = {n: y.xs(key=n, level='Next', drop_level=False) for n in [\"M\", \"D\", \"H\"]}\n",
    "\n",
    "    XXX, yyy = {n: [] for n in [\"M\", \"D\", \"H\"]}, {n: [] for n in [\"M\", \"D\", \"H\"]}\n",
    "    for n in [\"M\", \"D\", \"H\"]:\n",
    "        for path in range(1, 5):\n",
    "            X_path = XX[n].loc[XX[n].index.get_level_values('Path').str.len() == path]\n",
    "            y_path = yy[n].loc[yy[n].index.get_level_values('Path').str.len() == path]\n",
    "\n",
    "            if 'Time' in y_path.index.names:\n",
    "                y_path = y_path.reset_index('Time', drop=True)\n",
    "\n",
    "            XXX[n].append(X_path)\n",
    "            yyy[n].append(y_path)\n",
    "\n",
    "    XX_tn, XX_te = {n: [] for n in [\"M\", \"D\", \"H\"]}, {n: [] for n in [\"M\", \"D\", \"H\"]}\n",
    "    yy_tn, yy_te = {n: [] for n in [\"M\", \"D\", \"H\"]}, {n: [] for n in [\"M\", \"D\", \"H\"]}\n",
    "\n",
    "    for n in [\"M\", \"D\", \"H\"]:\n",
    "        for path in range(1, 5):\n",
    "            X_temp = XXX[n][path-1]\n",
    "            y_temp = yyy[n][path-1]\n",
    "\n",
    "            cell_index = y_temp.index.drop_duplicates()\n",
    "\n",
    "            cells_tn, cells_te = train_test_split(cell_index, test_size=test_size, random_state=rs)\n",
    "\n",
    "            X_tn = X_temp[X_temp.index.droplevel('Time').isin(cells_tn)]\n",
    "            X_te = X_temp[X_temp.index.droplevel('Time').isin(cells_te)]\n",
    "\n",
    "            y_tn = y_temp.loc[cells_tn]\n",
    "            y_te = y_temp.loc[cells_te]\n",
    "\n",
    "            XX_tn[n].append(X_tn)\n",
    "            XX_te[n].append(X_te)\n",
    "            yy_tn[n].append(y_tn)\n",
    "            yy_te[n].append(y_te)\n",
    "\n",
    "    X_tn = pd.concat([pd.concat(XX_tn[n]) for n in [\"M\", \"D\", \"H\"]])\n",
    "    X_te = pd.concat([pd.concat(XX_te[n]) for n in [\"M\", \"D\", \"H\"]])\n",
    "    y_tn = pd.concat([pd.concat(yy_tn[n]) for n in [\"M\", \"D\", \"H\"]])\n",
    "    y_te = pd.concat([pd.concat(yy_te[n]) for n in [\"M\", \"D\", \"H\"]])\n",
    "\n",
    "    return X_tn, X_te, y_tn, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3133fc8d-0b8d-4c0c-b3bc-36226a0410d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor(X_tn, X_te, y_tn, y_te, batch_size=32, val_size=1/6, rs=100):\n",
    "    \"\"\"\n",
    "    X_tn, X_te: MultiIndex DataFrame (Next, Path, Number, Time)\n",
    "    y_tn, y_te: Series or DataFrame with index (Next, Path, Number)\n",
    "    \"\"\"\n",
    "\n",
    "    X_tr, X_vl, y_tr, y_vl = Even_Split(X_tn, y_tn, val_size, rs)\n",
    "    keys_train = y_tr.index\n",
    "    keys_val = y_vl.index\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_tn_scaled = X_tn.copy()\n",
    "    X_te_scaled = X_te.copy()\n",
    "\n",
    "    scaler.fit(X_tn.values)\n",
    "    X_tn_scaled.loc[:, :] = scaler.transform(X_tn.values)\n",
    "    X_te_scaled.loc[:, :] = scaler.transform(X_te.values)\n",
    "\n",
    "    next_map = {'M': 0, 'D': 1, 'H': 2}\n",
    "    get_next = lambda idx: torch.nn.functional.one_hot(torch.tensor([next_map[i] for i in idx.get_level_values(\"Next\")]), num_classes=3).float()\n",
    "\n",
    "    def to_tensor(X_df, y_df, keys):\n",
    "        X_group = X_df.groupby(level=[\"Next\", \"Path\", \"Number\"])\n",
    "        X_tensor = torch.stack([\n",
    "            torch.tensor(X_group.get_group(k).values, dtype=torch.float32)\n",
    "            for k in keys\n",
    "        ])\n",
    "        y_tensor = torch.tensor(y_df.loc[keys].values, dtype=torch.float32).unsqueeze(1)\n",
    "        return X_tensor, y_tensor\n",
    "\n",
    "    next_train = get_next(pd.MultiIndex.from_tuples(keys_train, names=[\"Next\", \"Path\", \"Number\"]))\n",
    "    next_val   = get_next(pd.MultiIndex.from_tuples(keys_val,   names=[\"Next\", \"Path\", \"Number\"]))\n",
    "    next_test  = get_next(y_te.index)\n",
    "    \n",
    "    X_train_tensor, y_train_tensor = to_tensor(X_tn_scaled, y_tn, keys_train)\n",
    "    X_val_tensor,   y_val_tensor   = to_tensor(X_tn_scaled, y_tn, keys_val)\n",
    "    X_test_tensor,  y_test_tensor  = to_tensor(X_te_scaled, y_te, y_te.index.drop_duplicates())\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train_tensor, next_train, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(TensorDataset(X_val_tensor, next_val,  y_val_tensor),   batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(TensorDataset(X_test_tensor, next_test,  y_test_tensor),  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, X_test_tensor, y_test_tensor, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a46fc84b-24e7-487b-a538-10e77c7e148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setRandomSeed(random_seed=0):\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a7a5600-ca48-42b9-a7d4-91ae59a8b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, lr=1e-3, weight_decay=0, epoch=1000, patience=50, random_seed = 0):\n",
    "        self.random_seed = random_seed\n",
    "        #setRandomSeed(self.random_seed)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.cri2 = MAPELoss()\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=200, gamma=0.8)\n",
    "        self.epoch = epoch\n",
    "        self.patience = patience\n",
    "\n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def train(self, train_loader, test_loader=None, val_loader=None):\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_state = None\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        for ep in range(1, self.epoch + 1):\n",
    "            self.model.train()\n",
    "            for x_batch, onehot, y_batch in train_loader:\n",
    "                x_batch, onehot, y_batch = x_batch.to(self.device), onehot.to(self.device), y_batch.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(x_batch, onehot)\n",
    "                loss = self.cri2(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            self.scheduler.step()\n",
    "\n",
    "            avg_train_loss = self.evaluate(train_loader)\n",
    "            test_loss = self.evaluate(test_loader) if test_loader else None\n",
    "            val_loss = self.evaluate(val_loader) if val_loader else None\n",
    "\n",
    "            self.train_loss.append(avg_train_loss)\n",
    "            self.test_loss.append(test_loss)\n",
    "            self.val_loss.append(val_loss)\n",
    "\n",
    "            if val_loader:\n",
    "                if val_loss < best_val_loss - 1e-4:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_model_state = self.model.state_dict()\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    if epochs_no_improve >= self.patience:\n",
    "                        print(f\"Early stopping at epoch {ep}\")\n",
    "                        break\n",
    "\n",
    "        if best_model_state:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        if data_loader is None:\n",
    "            return None\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, onehot, y_batch in data_loader:\n",
    "                x_batch, onehot, y_batch = x_batch.to(self.device), onehot.to(self.device), y_batch.to(self.device)\n",
    "                outputs = self.model(x_batch, onehot)\n",
    "                loss = self.cri2(outputs, y_batch)\n",
    "                total_loss += loss.item()\n",
    "        return total_loss / len(data_loader)\n",
    "\n",
    "    def predict(self, x, onehot):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = x.to(self.device)\n",
    "            onehot = onehot.to(self.device)\n",
    "            return self.model(x, onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9feefaab-7522-4dfb-8e3d-64e935acdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(model, info, train_loader, val_loader, test_loader, plot = True):\n",
    "    rs, c1, c2, k1, k2 = info\n",
    "    \n",
    "    y_true_train = []\n",
    "    y_pred_train = []\n",
    "    \n",
    "    y_true_val = []\n",
    "    y_pred_val = []\n",
    "    \n",
    "    y_true_test = []\n",
    "    y_pred_test = []\n",
    "\n",
    "    y_true_test_M = []\n",
    "    y_pred_test_M = []\n",
    "\n",
    "    y_true_test_D = []\n",
    "    y_pred_test_D = []\n",
    "\n",
    "    y_true_test_H = []\n",
    "    y_pred_test_H = []\n",
    "    \n",
    "    for x_batch, onehot, y_batch in train_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_train.append(y_batch)\n",
    "        y_pred_train.append(preds.cpu())\n",
    "    \n",
    "    for x_batch, onehot, y_batch in val_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_val.append(y_batch)\n",
    "        y_pred_val.append(preds.cpu())\n",
    "    \n",
    "    for x_batch, onehot, y_batch in test_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_test.append(y_batch)\n",
    "        y_pred_test.append(preds.cpu())\n",
    "    \n",
    "        onehot_np = onehot.cpu().numpy()\n",
    "        y_true_np = y_batch.cpu().numpy()\n",
    "        y_pred_np = preds.cpu().numpy()\n",
    "    \n",
    "        for i in range(len(onehot_np)):\n",
    "            if np.array_equal(onehot_np[i], [1, 0, 0]):  # 'M'\n",
    "                y_true_test_M.append(y_true_np[i])\n",
    "                y_pred_test_M.append(y_pred_np[i])\n",
    "            elif np.array_equal(onehot_np[i], [0, 1, 0]):  # 'D'\n",
    "                y_true_test_D.append(y_true_np[i])\n",
    "                y_pred_test_D.append(y_pred_np[i])\n",
    "            elif np.array_equal(onehot_np[i], [0, 0, 1]):  # 'H'\n",
    "                y_true_test_H.append(y_true_np[i])\n",
    "                y_pred_test_H.append(y_pred_np[i])\n",
    "\n",
    "    y_true_train = torch.cat(y_true_train).numpy()\n",
    "    y_pred_train = torch.cat(y_pred_train).numpy()\n",
    "    \n",
    "    y_true_val = torch.cat(y_true_val).numpy()\n",
    "    y_pred_val = torch.cat(y_pred_val).numpy()\n",
    "    \n",
    "    y_true_test = torch.cat(y_true_test).numpy()\n",
    "    y_pred_test = torch.cat(y_pred_test).numpy()\n",
    "\n",
    "    y_true_test_M = np.array(y_true_test_M)\n",
    "    y_pred_test_M = np.array(y_pred_test_M)\n",
    "    \n",
    "    y_true_test_D = np.array(y_true_test_D)\n",
    "    y_pred_test_D = np.array(y_pred_test_D)\n",
    "    \n",
    "    y_true_test_H = np.array(y_true_test_H)\n",
    "    y_pred_test_H = np.array(y_pred_test_H)\n",
    "    \n",
    "    mape_M = mean_absolute_percentage_error(y_true_test_M, y_pred_test_M) * 100 if len(y_true_test_M) > 0 else np.nan\n",
    "    mape_D = mean_absolute_percentage_error(y_true_test_D, y_pred_test_D) * 100 if len(y_true_test_D) > 0 else np.nan\n",
    "    mape_H = mean_absolute_percentage_error(y_true_test_H, y_pred_test_H) * 100 if len(y_true_test_H) > 0 else np.nan\n",
    "    \n",
    "    train_mape = mean_absolute_percentage_error(y_true_train, y_pred_train) * 100\n",
    "    val_mape = mean_absolute_percentage_error(y_true_val, y_pred_val) * 100\n",
    "    test_mape = mean_absolute_percentage_error(y_true_test, y_pred_test) * 100\n",
    "    print(f\"Model: {model}, rs: {rs}, c1: {c1}, c2: {c2}, k1: {k1}, k2: {k2}\\n Train MAPE: {train_mape:.2f}%, Val MAPE: {val_mape:.2f}%, Test MAPE: {test_mape:.2f}%\")\n",
    "    print(f\"Test MAPE by 'Next': M: {mape_M:.2f}%, D: {mape_D:.2f}%, H: {mape_H:.2f}%\")\n",
    "    \n",
    "    if plot == True:\n",
    "        _ = plt.figure()\n",
    "        _ = plt.scatter(y_true_train, y_pred_train, label = 'Train')\n",
    "        _ = plt.scatter(y_true_val, y_pred_val, label = 'Val')\n",
    "        _ = plt.scatter(y_true_test, y_pred_test, label = 'Test')\n",
    "        min_val = min(y_true_train.min(), y_true_test.min())\n",
    "        max_val = max(y_true_train.max(), y_true_test.max())\n",
    "        _ = plt.plot([min_val, max_val], [min_val, max_val], 'k--', label='Ideal line')\n",
    "        _ = plt.xlabel('True SOH')\n",
    "        _ = plt.ylabel('Predicted SOH')\n",
    "        _ = plt.legend()\n",
    "        _ = plt.title(f'Random state: {rs}, hid: {hid}, {nl} layer, lr: {lr}')\n",
    "    return train_mape, val_mape, test_mape, mape_M, mape_D, mape_H\n",
    "\n",
    "def plot_loss(info, train_loss, val_loss, test_loss):\n",
    "    rs, c1, c2, k1, k2 = info\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(train_loss, label = 'Train loss')\n",
    "    _ = plt.plot(val_loss, label = 'Val loss')\n",
    "    _ = plt.plot(test_loss, label = 'Test loss')\n",
    "    _ = plt.ylim([0, 2])\n",
    "    _ = plt.xlabel('Epoch')\n",
    "    _ = plt.ylabel('Loss')\n",
    "    _ = plt.legend()\n",
    "    _ = plt.title(f'Random state: {rs}, hid: {hid}, {nl} layers, lr: {lr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd12095-98bf-4144-9920-4d6a042b0b11",
   "metadata": {},
   "source": [
    "## 1. 2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5f5b70d-f010-49c0-8bfb-e6fe81fc0d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2D_Compressor(nn.Module):\n",
    "    def __init__(self, \n",
    "                 output_dim=4,\n",
    "                 conv1_channels=16,\n",
    "                 conv2_channels=16,\n",
    "                 kernel_size1=(5, 2),\n",
    "                 kernel_size2=(3, 1)):\n",
    "        super(CNN2D_Compressor, self).__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=conv1_channels, kernel_size=kernel_size1, stride=1,\n",
    "                      padding=(kernel_size1[0] // 2, kernel_size1[1] // 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Conv2d(conv1_channels, conv2_channels, kernel_size=kernel_size2,\n",
    "                      padding=(kernel_size2[0] // 2, kernel_size2[1] // 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(conv2_channels, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ab81703-2c07-484c-910f-12d4e46abdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2D_MLP(nn.Module):\n",
    "    def __init__(self, conv1_channels, conv2_channels, kernel_size1, kernel_size2, out_dim=4, hidden_dim=64, num_layers=2, next_dim = 3):\n",
    "        super(CNN2D_MLP, self).__init__()\n",
    "        self.encoder = CNN2D_Compressor(out_dim, conv1_channels, conv2_channels, kernel_size1, kernel_size2)\n",
    "        \n",
    "        layers = []\n",
    "\n",
    "        input_dim = out_dim + next_dim\n",
    "        output_dim = 1\n",
    "\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "\n",
    "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, onehot):\n",
    "        x_feat = self.encoder(x)\n",
    "        x_concat = torch.cat([x_feat, onehot], dim=1)\n",
    "        return self.model(x_concat)\n",
    "\n",
    "class MAPELoss(nn.Module):\n",
    "    def __init__(self, epsilon=1e-7):\n",
    "        super(MAPELoss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.mean(torch.abs((y_true - y_pred) / (y_true + self.epsilon))) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b885de-fb30-489f-9710-8d5db83d8767",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4dd8064f-8cbf-40f3-b87a-978d97e09ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 160\n",
      "Model: 2D CNN, rs: 100, c1: 8, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.95%, Val MAPE: 1.12%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 1.14%, D: 1.11%, H: 1.07%\n",
      "22.81 s\n",
      "Early stopping at epoch 214\n",
      "Model: 2D CNN, rs: 100, c1: 8, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.13%, Val MAPE: 1.15%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: 1.03%, D: 1.16%, H: 1.03%\n",
      "29.54 s\n",
      "Early stopping at epoch 154\n",
      "Model: 2D CNN, rs: 100, c1: 8, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.95%, Val MAPE: 1.09%, Test MAPE: 1.15%\n",
      "Test MAPE by 'Next': M: 1.22%, D: 1.14%, H: 1.08%\n",
      "21.92 s\n",
      "Early stopping at epoch 245\n",
      "Model: 2D CNN, rs: 100, c1: 8, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.98%, Val MAPE: 1.13%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.04%, D: 1.05%, H: 1.05%\n",
      "33.26 s\n",
      "Early stopping at epoch 206\n",
      "Model: 2D CNN, rs: 100, c1: 8, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.04%, Val MAPE: 1.02%, Test MAPE: 1.20%\n",
      "Test MAPE by 'Next': M: 1.26%, D: 1.11%, H: 1.25%\n",
      "30.29 s\n",
      "Early stopping at epoch 164\n",
      "Model: 2D CNN, rs: 100, c1: 8, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 0.92%, Val MAPE: 0.97%, Test MAPE: 1.13%\n",
      "Test MAPE by 'Next': M: 1.29%, D: 1.10%, H: 1.00%\n",
      "23.36 s\n",
      "Early stopping at epoch 167\n",
      "Model: 2D CNN, rs: 100, c1: 8, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.97%, Val MAPE: 1.05%, Test MAPE: 1.10%\n",
      "Test MAPE by 'Next': M: 1.14%, D: 1.00%, H: 1.17%\n",
      "26.04 s\n",
      "Early stopping at epoch 127\n",
      "Model: 2D CNN, rs: 100, c1: 8, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.14%, Val MAPE: 1.25%, Test MAPE: 1.07%\n",
      "Test MAPE by 'Next': M: 1.09%, D: 1.14%, H: 0.98%\n",
      "17.09 s\n",
      "Early stopping at epoch 286\n",
      "Model: 2D CNN, rs: 100, c1: 16, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.98%, Val MAPE: 1.32%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 1.12%, D: 1.20%, H: 1.00%\n",
      "38.72 s\n",
      "Early stopping at epoch 153\n",
      "Model: 2D CNN, rs: 100, c1: 16, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.08%, Val MAPE: 1.14%, Test MAPE: 1.32%\n",
      "Test MAPE by 'Next': M: 1.31%, D: 1.29%, H: 1.36%\n",
      "22.63 s\n",
      "Early stopping at epoch 119\n",
      "Model: 2D CNN, rs: 100, c1: 16, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.08%, Val MAPE: 1.07%, Test MAPE: 1.07%\n",
      "Test MAPE by 'Next': M: 1.15%, D: 1.08%, H: 0.99%\n",
      "16.93 s\n",
      "Early stopping at epoch 235\n",
      "Model: 2D CNN, rs: 100, c1: 16, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.95%, Val MAPE: 0.99%, Test MAPE: 1.14%\n",
      "Test MAPE by 'Next': M: 1.27%, D: 1.03%, H: 1.11%\n",
      "32.38 s\n",
      "Early stopping at epoch 250\n",
      "Model: 2D CNN, rs: 100, c1: 16, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.97%, Val MAPE: 1.01%, Test MAPE: 1.13%\n",
      "Test MAPE by 'Next': M: 1.21%, D: 1.14%, H: 1.03%\n",
      "28.35 s\n",
      "Early stopping at epoch 228\n",
      "Model: 2D CNN, rs: 100, c1: 16, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.01%, Val MAPE: 0.99%, Test MAPE: 1.21%\n",
      "Test MAPE by 'Next': M: 1.35%, D: 1.04%, H: 1.24%\n",
      "30.09 s\n",
      "Early stopping at epoch 277\n",
      "Model: 2D CNN, rs: 100, c1: 16, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.18%, Val MAPE: 1.41%, Test MAPE: 1.27%\n",
      "Test MAPE by 'Next': M: 1.35%, D: 1.25%, H: 1.21%\n",
      "34.10 s\n",
      "Early stopping at epoch 214\n",
      "Model: 2D CNN, rs: 100, c1: 16, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.88%, Val MAPE: 1.01%, Test MAPE: 1.13%\n",
      "Test MAPE by 'Next': M: 1.23%, D: 1.10%, H: 1.04%\n",
      "26.16 s\n",
      "Early stopping at epoch 567\n",
      "Model: 2D CNN, rs: 120, c1: 8, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.98%, Val MAPE: 0.93%, Test MAPE: 0.77%\n",
      "Test MAPE by 'Next': M: 0.81%, D: 0.66%, H: 0.85%\n",
      "69.45 s\n",
      "Early stopping at epoch 218\n",
      "Model: 2D CNN, rs: 120, c1: 8, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 0.96%, Val MAPE: 1.02%, Test MAPE: 0.81%\n",
      "Test MAPE by 'Next': M: 0.97%, D: 0.69%, H: 0.78%\n",
      "26.56 s\n",
      "Early stopping at epoch 373\n",
      "Model: 2D CNN, rs: 120, c1: 8, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.98%, Val MAPE: 0.99%, Test MAPE: 0.85%\n",
      "Test MAPE by 'Next': M: 0.89%, D: 0.75%, H: 0.90%\n",
      "46.49 s\n",
      "Early stopping at epoch 79\n",
      "Model: 2D CNN, rs: 120, c1: 8, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.58%, Val MAPE: 1.52%, Test MAPE: 1.35%\n",
      "Test MAPE by 'Next': M: 1.36%, D: 1.36%, H: 1.33%\n",
      "9.29 s\n",
      "Early stopping at epoch 220\n",
      "Model: 2D CNN, rs: 120, c1: 8, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.02%, Val MAPE: 0.97%, Test MAPE: 0.78%\n",
      "Test MAPE by 'Next': M: 0.89%, D: 0.68%, H: 0.77%\n",
      "26.04 s\n",
      "Early stopping at epoch 110\n",
      "Model: 2D CNN, rs: 120, c1: 8, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.23%, Val MAPE: 1.06%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 1.16%, D: 0.98%, H: 1.19%\n",
      "14.13 s\n",
      "Early stopping at epoch 136\n",
      "Model: 2D CNN, rs: 120, c1: 8, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.19%, Val MAPE: 0.94%, Test MAPE: 0.93%\n",
      "Test MAPE by 'Next': M: 1.00%, D: 0.85%, H: 0.93%\n",
      "18.44 s\n",
      "Early stopping at epoch 264\n",
      "Model: 2D CNN, rs: 120, c1: 8, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.95%, Val MAPE: 1.02%, Test MAPE: 0.83%\n",
      "Test MAPE by 'Next': M: 0.87%, D: 0.79%, H: 0.83%\n",
      "33.24 s\n",
      "Early stopping at epoch 132\n",
      "Model: 2D CNN, rs: 120, c1: 16, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.37%, Val MAPE: 1.26%, Test MAPE: 1.09%\n",
      "Test MAPE by 'Next': M: 1.12%, D: 1.04%, H: 1.10%\n",
      "15.63 s\n",
      "Early stopping at epoch 457\n",
      "Model: 2D CNN, rs: 120, c1: 16, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 0.98%, Val MAPE: 0.94%, Test MAPE: 0.85%\n",
      "Test MAPE by 'Next': M: 0.94%, D: 0.73%, H: 0.89%\n",
      "60.07 s\n",
      "Early stopping at epoch 113\n",
      "Model: 2D CNN, rs: 120, c1: 16, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.23%, Val MAPE: 1.08%, Test MAPE: 0.99%\n",
      "Test MAPE by 'Next': M: 1.07%, D: 0.87%, H: 1.02%\n",
      "13.76 s\n",
      "Early stopping at epoch 130\n",
      "Model: 2D CNN, rs: 120, c1: 16, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.22%, Val MAPE: 1.11%, Test MAPE: 1.16%\n",
      "Test MAPE by 'Next': M: 1.31%, D: 1.06%, H: 1.11%\n",
      "16.81 s\n",
      "Early stopping at epoch 201\n",
      "Model: 2D CNN, rs: 120, c1: 16, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.32%, Val MAPE: 1.15%, Test MAPE: 1.17%\n",
      "Test MAPE by 'Next': M: 1.28%, D: 0.98%, H: 1.26%\n",
      "25.98 s\n",
      "Early stopping at epoch 224\n",
      "Model: 2D CNN, rs: 120, c1: 16, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.03%, Val MAPE: 0.95%, Test MAPE: 0.80%\n",
      "Test MAPE by 'Next': M: 0.89%, D: 0.71%, H: 0.80%\n",
      "29.07 s\n",
      "Early stopping at epoch 339\n",
      "Model: 2D CNN, rs: 120, c1: 16, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.38%, Val MAPE: 1.23%, Test MAPE: 1.35%\n",
      "Test MAPE by 'Next': M: 1.82%, D: 0.94%, H: 1.29%\n",
      "41.24 s\n",
      "Early stopping at epoch 294\n",
      "Model: 2D CNN, rs: 120, c1: 16, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.11%, Val MAPE: 1.00%, Test MAPE: 0.81%\n",
      "Test MAPE by 'Next': M: 0.92%, D: 0.70%, H: 0.81%\n",
      "40.08 s\n",
      "Early stopping at epoch 251\n",
      "Model: 2D CNN, rs: 140, c1: 8, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.86%, Val MAPE: 1.21%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: 1.06%, D: 1.05%, H: 0.92%\n",
      "37.72 s\n",
      "Early stopping at epoch 320\n",
      "Model: 2D CNN, rs: 140, c1: 8, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 0.96%, Val MAPE: 1.27%, Test MAPE: 1.09%\n",
      "Test MAPE by 'Next': M: 1.05%, D: 1.11%, H: 1.10%\n",
      "43.71 s\n",
      "Early stopping at epoch 203\n",
      "Model: 2D CNN, rs: 140, c1: 8, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.86%, Val MAPE: 1.22%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.12%, D: 1.11%, H: 0.91%\n",
      "27.00 s\n",
      "Early stopping at epoch 218\n",
      "Model: 2D CNN, rs: 140, c1: 8, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.95%, Val MAPE: 1.14%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.17%, D: 1.01%, H: 0.98%\n",
      "27.06 s\n",
      "Early stopping at epoch 349\n",
      "Model: 2D CNN, rs: 140, c1: 8, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.88%, Val MAPE: 1.31%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: 1.05%, D: 0.99%, H: 1.01%\n",
      "46.34 s\n",
      "Early stopping at epoch 219\n",
      "Model: 2D CNN, rs: 140, c1: 8, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.00%, Val MAPE: 1.23%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: 1.18%, D: 1.03%, H: 1.03%\n",
      "28.32 s\n",
      "Early stopping at epoch 193\n",
      "Model: 2D CNN, rs: 140, c1: 8, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.45%, Val MAPE: 1.36%, Test MAPE: 1.49%\n",
      "Test MAPE by 'Next': M: 1.70%, D: 1.32%, H: 1.45%\n",
      "23.72 s\n",
      "Early stopping at epoch 365\n",
      "Model: 2D CNN, rs: 140, c1: 8, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.88%, Val MAPE: 1.16%, Test MAPE: 1.00%\n",
      "Test MAPE by 'Next': M: 1.10%, D: 0.92%, H: 0.98%\n",
      "47.94 s\n",
      "Early stopping at epoch 205\n",
      "Model: 2D CNN, rs: 140, c1: 16, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.90%, Val MAPE: 1.23%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 1.01%, D: 1.05%, H: 1.03%\n",
      "26.46 s\n",
      "Early stopping at epoch 250\n",
      "Model: 2D CNN, rs: 140, c1: 16, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.03%, Val MAPE: 1.48%, Test MAPE: 1.24%\n",
      "Test MAPE by 'Next': M: 1.18%, D: 1.31%, H: 1.23%\n",
      "36.77 s\n",
      "Early stopping at epoch 254\n",
      "Model: 2D CNN, rs: 140, c1: 16, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.86%, Val MAPE: 1.19%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: 1.17%, D: 1.06%, H: 0.89%\n",
      "30.45 s\n",
      "Early stopping at epoch 253\n",
      "Model: 2D CNN, rs: 140, c1: 16, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.87%, Val MAPE: 1.26%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: 1.07%, D: 1.04%, H: 0.95%\n",
      "35.12 s\n",
      "Early stopping at epoch 312\n",
      "Model: 2D CNN, rs: 140, c1: 16, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.94%, Val MAPE: 1.19%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: 1.13%, D: 1.00%, H: 0.99%\n",
      "38.58 s\n",
      "Early stopping at epoch 163\n",
      "Model: 2D CNN, rs: 140, c1: 16, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.00%, Val MAPE: 1.21%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: 1.20%, D: 1.03%, H: 1.02%\n",
      "19.44 s\n",
      "Early stopping at epoch 188\n",
      "Model: 2D CNN, rs: 140, c1: 16, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.91%, Val MAPE: 1.37%, Test MAPE: 1.07%\n",
      "Test MAPE by 'Next': M: 1.04%, D: 1.13%, H: 1.04%\n",
      "24.08 s\n",
      "Early stopping at epoch 185\n",
      "Model: 2D CNN, rs: 140, c1: 16, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.99%, Val MAPE: 1.30%, Test MAPE: 1.15%\n",
      "Test MAPE by 'Next': M: 1.20%, D: 1.18%, H: 1.08%\n",
      "24.55 s\n",
      "Early stopping at epoch 224\n",
      "Model: 2D CNN, rs: 160, c1: 8, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.07%, Val MAPE: 1.28%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: 1.30%, D: 0.98%, H: 0.97%\n",
      "29.72 s\n",
      "Early stopping at epoch 227\n",
      "Model: 2D CNN, rs: 160, c1: 8, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.01%, Val MAPE: 1.19%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 1.16%, D: 0.94%, H: 1.01%\n",
      "26.87 s\n",
      "Early stopping at epoch 230\n",
      "Model: 2D CNN, rs: 160, c1: 8, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.91%, Val MAPE: 1.12%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: 1.15%, D: 0.91%, H: 0.98%\n",
      "27.38 s\n",
      "Early stopping at epoch 390\n",
      "Model: 2D CNN, rs: 160, c1: 8, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.90%, Val MAPE: 0.97%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.16%, D: 0.83%, H: 1.17%\n",
      "53.22 s\n",
      "Early stopping at epoch 269\n",
      "Model: 2D CNN, rs: 160, c1: 8, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.94%, Val MAPE: 1.22%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.27%, D: 0.85%, H: 1.03%\n",
      "33.71 s\n",
      "Early stopping at epoch 310\n",
      "Model: 2D CNN, rs: 160, c1: 8, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.01%, Val MAPE: 1.19%, Test MAPE: 1.10%\n",
      "Test MAPE by 'Next': M: 1.29%, D: 0.93%, H: 1.08%\n",
      "40.51 s\n",
      "Early stopping at epoch 207\n",
      "Model: 2D CNN, rs: 160, c1: 8, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.31%, Val MAPE: 1.38%, Test MAPE: 1.44%\n",
      "Test MAPE by 'Next': M: 1.62%, D: 1.35%, H: 1.35%\n",
      "28.79 s\n",
      "Early stopping at epoch 166\n",
      "Model: 2D CNN, rs: 160, c1: 8, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.90%, Val MAPE: 1.08%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 1.13%, D: 0.88%, H: 1.08%\n",
      "26.13 s\n",
      "Early stopping at epoch 289\n",
      "Model: 2D CNN, rs: 160, c1: 16, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.93%, Val MAPE: 1.15%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: 1.32%, D: 0.90%, H: 0.91%\n",
      "34.95 s\n",
      "Early stopping at epoch 309\n",
      "Model: 2D CNN, rs: 160, c1: 16, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.00%, Val MAPE: 1.06%, Test MAPE: 1.09%\n",
      "Test MAPE by 'Next': M: 1.19%, D: 1.00%, H: 1.08%\n",
      "28.17 s\n",
      "Early stopping at epoch 189\n",
      "Model: 2D CNN, rs: 160, c1: 16, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.95%, Val MAPE: 1.04%, Test MAPE: 0.98%\n",
      "Test MAPE by 'Next': M: 1.13%, D: 0.84%, H: 0.97%\n",
      "17.36 s\n",
      "Early stopping at epoch 269\n",
      "Model: 2D CNN, rs: 160, c1: 16, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.08%, Val MAPE: 1.13%, Test MAPE: 1.14%\n",
      "Test MAPE by 'Next': M: 1.23%, D: 1.05%, H: 1.14%\n",
      "24.67 s\n",
      "Early stopping at epoch 355\n",
      "Model: 2D CNN, rs: 160, c1: 16, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.08%, Val MAPE: 1.05%, Test MAPE: 1.20%\n",
      "Test MAPE by 'Next': M: 1.32%, D: 1.03%, H: 1.26%\n",
      "31.91 s\n",
      "Early stopping at epoch 368\n",
      "Model: 2D CNN, rs: 160, c1: 16, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 0.99%, Val MAPE: 1.13%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 1.15%, D: 0.97%, H: 0.97%\n",
      "32.60 s\n",
      "Early stopping at epoch 165\n",
      "Model: 2D CNN, rs: 160, c1: 16, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.97%, Val MAPE: 1.11%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: 1.20%, D: 0.91%, H: 0.93%\n",
      "15.40 s\n",
      "Early stopping at epoch 225\n",
      "Model: 2D CNN, rs: 160, c1: 16, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.95%, Val MAPE: 1.05%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: 1.28%, D: 0.94%, H: 1.01%\n",
      "20.62 s\n",
      "Early stopping at epoch 531\n",
      "Model: 2D CNN, rs: 180, c1: 8, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.91%, Val MAPE: 1.18%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: 1.04%, D: 0.86%, H: 0.92%\n",
      "47.77 s\n",
      "Early stopping at epoch 132\n",
      "Model: 2D CNN, rs: 180, c1: 8, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.09%, Val MAPE: 1.26%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: 1.06%, D: 0.97%, H: 1.01%\n",
      "12.50 s\n",
      "Early stopping at epoch 431\n",
      "Model: 2D CNN, rs: 180, c1: 8, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.21%, Val MAPE: 1.42%, Test MAPE: 1.38%\n",
      "Test MAPE by 'Next': M: 1.45%, D: 1.36%, H: 1.33%\n",
      "39.04 s\n",
      "Early stopping at epoch 157\n",
      "Model: 2D CNN, rs: 180, c1: 8, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.00%, Val MAPE: 1.16%, Test MAPE: 1.10%\n",
      "Test MAPE by 'Next': M: 1.12%, D: 1.00%, H: 1.18%\n",
      "14.56 s\n",
      "Early stopping at epoch 110\n",
      "Model: 2D CNN, rs: 180, c1: 8, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.00%, Val MAPE: 1.14%, Test MAPE: 0.99%\n",
      "Test MAPE by 'Next': M: 1.04%, D: 0.89%, H: 1.03%\n",
      "10.31 s\n",
      "Early stopping at epoch 225\n",
      "Model: 2D CNN, rs: 180, c1: 8, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 0.94%, Val MAPE: 1.13%, Test MAPE: 1.07%\n",
      "Test MAPE by 'Next': M: 1.16%, D: 0.91%, H: 1.16%\n",
      "20.84 s\n",
      "Early stopping at epoch 692\n",
      "Model: 2D CNN, rs: 180, c1: 8, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.74%, Val MAPE: 1.25%, Test MAPE: 0.96%\n",
      "Test MAPE by 'Next': M: 1.13%, D: 0.83%, H: 0.92%\n",
      "62.17 s\n",
      "Early stopping at epoch 130\n",
      "Model: 2D CNN, rs: 180, c1: 8, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.92%, Val MAPE: 1.18%, Test MAPE: 0.99%\n",
      "Test MAPE by 'Next': M: 1.06%, D: 0.87%, H: 1.05%\n",
      "12.45 s\n",
      "Early stopping at epoch 110\n",
      "Model: 2D CNN, rs: 180, c1: 16, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.00%, Val MAPE: 1.13%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: 1.18%, D: 0.91%, H: 1.02%\n",
      "10.33 s\n",
      "Early stopping at epoch 414\n",
      "Model: 2D CNN, rs: 180, c1: 16, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.02%, Val MAPE: 1.33%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: 1.26%, D: 0.90%, H: 0.89%\n",
      "37.82 s\n",
      "Early stopping at epoch 353\n",
      "Model: 2D CNN, rs: 180, c1: 16, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.42%, Val MAPE: 1.93%, Test MAPE: 1.69%\n",
      "Test MAPE by 'Next': M: 1.74%, D: 1.91%, H: 1.41%\n",
      "31.87 s\n",
      "Early stopping at epoch 234\n",
      "Model: 2D CNN, rs: 180, c1: 16, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.99%, Val MAPE: 1.26%, Test MAPE: 0.98%\n",
      "Test MAPE by 'Next': M: 1.05%, D: 0.90%, H: 0.99%\n",
      "21.61 s\n",
      "Early stopping at epoch 248\n",
      "Model: 2D CNN, rs: 180, c1: 16, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.91%, Val MAPE: 1.19%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 1.04%, D: 0.96%, H: 1.10%\n",
      "22.61 s\n",
      "Early stopping at epoch 110\n",
      "Model: 2D CNN, rs: 180, c1: 16, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.00%, Val MAPE: 1.08%, Test MAPE: 1.13%\n",
      "Test MAPE by 'Next': M: 1.17%, D: 1.02%, H: 1.21%\n",
      "10.39 s\n",
      "Early stopping at epoch 371\n",
      "Model: 2D CNN, rs: 180, c1: 16, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.02%, Val MAPE: 1.19%, Test MAPE: 0.93%\n",
      "Test MAPE by 'Next': M: 1.00%, D: 0.80%, H: 0.99%\n",
      "33.28 s\n",
      "Early stopping at epoch 178\n",
      "Model: 2D CNN, rs: 180, c1: 16, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.05%, Val MAPE: 1.31%, Test MAPE: 0.98%\n",
      "Test MAPE by 'Next': M: 1.08%, D: 0.91%, H: 0.95%\n",
      "16.52 s\n"
     ]
    }
   ],
   "source": [
    "random_states = [100, 120, 140, 160, 180]\n",
    "bs = 12\n",
    "ep = 1000\n",
    "hid = 16\n",
    "layer = 5\n",
    "lr = 1e-3\n",
    "\n",
    "conv1_channels = [8, 16]\n",
    "conv2_channels = [8, 16]\n",
    "kernel_size1 = [(2,2), (3,2)]\n",
    "kernel_size2 = [(2,2), (3,2)]\n",
    "\n",
    "results_df = pd.DataFrame(columns = ['rs', 'c1', 'c2', 'k1', 'k2', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE'])\n",
    "\n",
    "X, y = Get_Data_all(dat)\n",
    "\n",
    "for rs, c1, c2, k1, k2 in product(random_states, conv1_channels, conv2_channels, kernel_size1, kernel_size2):\n",
    "    setRandomSeed(rs)\n",
    "    start = time.time()\n",
    "    X_tn, X_te, y_tn, y_te = Even_Split(X, y, 1/3, rs)\n",
    "    train_loader, val_loader, test_loader, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, X_test_tensor, y_test_tensor, scaler = convert_to_tensor(X_tn, X_te, y_tn, y_te, bs, 1/6, rs)\n",
    "    \n",
    "    model = CNN2D_MLP(c1, c2, k1, k2, 4, hid, layer)\n",
    "    trainer = Trainer(model, lr=lr, epoch = ep, random_seed = rs)\n",
    "    \n",
    "    trainer.train(train_loader, val_loader, test_loader)\n",
    "\n",
    "    info = [rs, c1, c2, k1, k2]\n",
    "    results = plot_results(\"2D CNN\", info, train_loader, val_loader, test_loader, plot = False)\n",
    "\n",
    "    temp_df = pd.DataFrame(info+list(results)).T\n",
    "    temp_df.columns = ['rs', 'c1', 'c2', 'k1', 'k2', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']\n",
    "    results_df = pd.concat([results_df, temp_df])\n",
    "    print(f\"{time.time()-start:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4819d6c3-d539-4de0-9e83-ed6af617fa12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "      <th>Train MAPE</th>\n",
       "      <th>Val MAPE</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Next M MAPE</th>\n",
       "      <th>Next D MAPE</th>\n",
       "      <th>Next H MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.954008</td>\n",
       "      <td>1.145687</td>\n",
       "      <td>0.981896</td>\n",
       "      <td>1.068266</td>\n",
       "      <td>0.930788</td>\n",
       "      <td>0.946634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>1.031902</td>\n",
       "      <td>1.178456</td>\n",
       "      <td>1.003655</td>\n",
       "      <td>1.052415</td>\n",
       "      <td>0.973837</td>\n",
       "      <td>0.984712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.983071</td>\n",
       "      <td>1.167823</td>\n",
       "      <td>1.087242</td>\n",
       "      <td>1.165246</td>\n",
       "      <td>1.054766</td>\n",
       "      <td>1.041715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>1.083834</td>\n",
       "      <td>1.183927</td>\n",
       "      <td>1.120445</td>\n",
       "      <td>1.168796</td>\n",
       "      <td>1.050875</td>\n",
       "      <td>1.141663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.975927</td>\n",
       "      <td>1.129331</td>\n",
       "      <td>1.007508</td>\n",
       "      <td>1.101383</td>\n",
       "      <td>0.903629</td>\n",
       "      <td>1.017512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>1.020755</td>\n",
       "      <td>1.115666</td>\n",
       "      <td>1.099553</td>\n",
       "      <td>1.216827</td>\n",
       "      <td>0.990186</td>\n",
       "      <td>1.091646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.132988</td>\n",
       "      <td>1.195284</td>\n",
       "      <td>1.183142</td>\n",
       "      <td>1.317258</td>\n",
       "      <td>1.069226</td>\n",
       "      <td>1.162944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>0.957826</td>\n",
       "      <td>1.133699</td>\n",
       "      <td>0.984758</td>\n",
       "      <td>1.049777</td>\n",
       "      <td>0.920061</td>\n",
       "      <td>0.984434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.03734</td>\n",
       "      <td>1.218445</td>\n",
       "      <td>1.059832</td>\n",
       "      <td>1.150992</td>\n",
       "      <td>1.017884</td>\n",
       "      <td>1.01062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>1.022197</td>\n",
       "      <td>1.190422</td>\n",
       "      <td>1.10386</td>\n",
       "      <td>1.174179</td>\n",
       "      <td>1.047484</td>\n",
       "      <td>1.089918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.108342</td>\n",
       "      <td>1.263323</td>\n",
       "      <td>1.15294</td>\n",
       "      <td>1.251743</td>\n",
       "      <td>1.15133</td>\n",
       "      <td>1.055745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>1.022229</td>\n",
       "      <td>1.149501</td>\n",
       "      <td>1.087478</td>\n",
       "      <td>1.186821</td>\n",
       "      <td>1.014492</td>\n",
       "      <td>1.061122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.043634</td>\n",
       "      <td>1.118913</td>\n",
       "      <td>1.115723</td>\n",
       "      <td>1.195658</td>\n",
       "      <td>1.023169</td>\n",
       "      <td>1.128342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>1.005813</td>\n",
       "      <td>1.072278</td>\n",
       "      <td>1.051922</td>\n",
       "      <td>1.152491</td>\n",
       "      <td>0.956145</td>\n",
       "      <td>1.047132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.091576</td>\n",
       "      <td>1.261706</td>\n",
       "      <td>1.12744</td>\n",
       "      <td>1.281224</td>\n",
       "      <td>1.00756</td>\n",
       "      <td>1.093535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>0.996109</td>\n",
       "      <td>1.134682</td>\n",
       "      <td>1.029757</td>\n",
       "      <td>1.142722</td>\n",
       "      <td>0.967127</td>\n",
       "      <td>0.979423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    c1  c2      k1      k2 Train MAPE  Val MAPE Test MAPE Next M MAPE  \\\n",
       "0    8   8  (2, 2)  (2, 2)   0.954008  1.145687  0.981896    1.068266   \n",
       "1    8   8  (2, 2)  (3, 2)   1.031902  1.178456  1.003655    1.052415   \n",
       "2    8   8  (3, 2)  (2, 2)   0.983071  1.167823  1.087242    1.165246   \n",
       "3    8   8  (3, 2)  (3, 2)   1.083834  1.183927  1.120445    1.168796   \n",
       "4    8  16  (2, 2)  (2, 2)   0.975927  1.129331  1.007508    1.101383   \n",
       "5    8  16  (2, 2)  (3, 2)   1.020755  1.115666  1.099553    1.216827   \n",
       "6    8  16  (3, 2)  (2, 2)   1.132988  1.195284  1.183142    1.317258   \n",
       "7    8  16  (3, 2)  (3, 2)   0.957826  1.133699  0.984758    1.049777   \n",
       "8   16   8  (2, 2)  (2, 2)    1.03734  1.218445  1.059832    1.150992   \n",
       "9   16   8  (2, 2)  (3, 2)   1.022197  1.190422   1.10386    1.174179   \n",
       "10  16   8  (3, 2)  (2, 2)   1.108342  1.263323   1.15294    1.251743   \n",
       "11  16   8  (3, 2)  (3, 2)   1.022229  1.149501  1.087478    1.186821   \n",
       "12  16  16  (2, 2)  (2, 2)   1.043634  1.118913  1.115723    1.195658   \n",
       "13  16  16  (2, 2)  (3, 2)   1.005813  1.072278  1.051922    1.152491   \n",
       "14  16  16  (3, 2)  (2, 2)   1.091576  1.261706   1.12744    1.281224   \n",
       "15  16  16  (3, 2)  (3, 2)   0.996109  1.134682  1.029757    1.142722   \n",
       "\n",
       "   Next D MAPE Next H MAPE  \n",
       "0     0.930788    0.946634  \n",
       "1     0.973837    0.984712  \n",
       "2     1.054766    1.041715  \n",
       "3     1.050875    1.141663  \n",
       "4     0.903629    1.017512  \n",
       "5     0.990186    1.091646  \n",
       "6     1.069226    1.162944  \n",
       "7     0.920061    0.984434  \n",
       "8     1.017884     1.01062  \n",
       "9     1.047484    1.089918  \n",
       "10     1.15133    1.055745  \n",
       "11    1.014492    1.061122  \n",
       "12    1.023169    1.128342  \n",
       "13    0.956145    1.047132  \n",
       "14     1.00756    1.093535  \n",
       "15    0.967127    0.979423  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = results_df.groupby(['c1', 'c2', 'k1', 'k2'])[['Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']].mean().reset_index()\n",
    "summary_df \n",
    "summary_df.to_csv('2D CNN_next_info_sum.csv')\n",
    "results_df.to_csv('2D CNN_next_info.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
