{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f777b66-b5ce-4b51-a260-0f95e8c9dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "from numpy import hstack, vstack\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c268bd1-67cb-4cfb-842e-0bd9f4e75302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Ansh\\\\Desktop\\\\MEST\\\\HMG3\\\\Rapid_fin\\\\deep learning modeling'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_directory(foldername, filename = None, back_num = 0):\n",
    "    cur = os.getcwd()\n",
    "    for i in range(back_num):\n",
    "        cur = os.path.abspath(os.path.join(cur, os.pardir))\n",
    "    for folder in foldername:\n",
    "        cur = os.path.join(cur, folder)\n",
    "    if not os.path.exists(cur):\n",
    "        os.makedirs(cur)\n",
    "        print(f'{cur} created')\n",
    "    if filename != None:\n",
    "        cur = os.path.join(cur, filename)\n",
    "    return cur\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e19cef-7f59-4f9c-a102-bce664fb00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_add = find_directory(foldername = [], filename = 'SOC_Point_Data.csv')\n",
    "dat = pd.read_csv(csv_add, index_col = (0,1,2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51190277-29e5-4a99-bb89-b99b751c7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Data_all(dat) :\n",
    "    \n",
    "    RPT_MODE = \"0.1C\"\n",
    "    SOC_Range = [9,10,11,12]\n",
    "\n",
    "    Time_Range = range(4, 1201, 2)\n",
    "    SOC_Range = [str(i) for i in SOC_Range]\n",
    "    \n",
    "    Data = dat\n",
    "\n",
    "    X = Data.loc[RPT_MODE, SOC_Range]\n",
    "    Y = Data.loc[RPT_MODE, [\"SOH\", \"Next_SOH\", \"Ratio_SOH\", \"Ratio_CYC\"]].groupby(level = [\"Next\", \"Path\", \"Number\"]).mean()\n",
    "    y = Y[\"Next_SOH\"]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19cdfd1a-dfb7-4066-ab61-9ef975b8d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Even_Split(X, y, test_size, rs):\n",
    "    XX = {n: X.xs(key=n, level='Next', drop_level=False) for n in [\"M\", \"D\", \"H\"]}\n",
    "    yy = {n: y.xs(key=n, level='Next', drop_level=False) for n in [\"M\", \"D\", \"H\"]}\n",
    "\n",
    "    XXX, yyy = {n: [] for n in [\"M\", \"D\", \"H\"]}, {n: [] for n in [\"M\", \"D\", \"H\"]}\n",
    "    for n in [\"M\", \"D\", \"H\"]:\n",
    "        for path in range(1, 5):\n",
    "            X_path = XX[n].loc[XX[n].index.get_level_values('Path').str.len() == path]\n",
    "            y_path = yy[n].loc[yy[n].index.get_level_values('Path').str.len() == path]\n",
    "\n",
    "            if 'Time' in y_path.index.names:\n",
    "                y_path = y_path.reset_index('Time', drop=True)\n",
    "\n",
    "            XXX[n].append(X_path)\n",
    "            yyy[n].append(y_path)\n",
    "\n",
    "    XX_tn, XX_te = {n: [] for n in [\"M\", \"D\", \"H\"]}, {n: [] for n in [\"M\", \"D\", \"H\"]}\n",
    "    yy_tn, yy_te = {n: [] for n in [\"M\", \"D\", \"H\"]}, {n: [] for n in [\"M\", \"D\", \"H\"]}\n",
    "\n",
    "    for n in [\"M\", \"D\", \"H\"]:\n",
    "        for path in range(1, 5):\n",
    "            X_temp = XXX[n][path-1]\n",
    "            y_temp = yyy[n][path-1]\n",
    "\n",
    "            cell_index = y_temp.index.drop_duplicates()\n",
    "\n",
    "            cells_tn, cells_te = train_test_split(cell_index, test_size=test_size, random_state=rs)\n",
    "\n",
    "            X_tn = X_temp[X_temp.index.droplevel('Time').isin(cells_tn)]\n",
    "            X_te = X_temp[X_temp.index.droplevel('Time').isin(cells_te)]\n",
    "\n",
    "            y_tn = y_temp.loc[cells_tn]\n",
    "            y_te = y_temp.loc[cells_te]\n",
    "\n",
    "            XX_tn[n].append(X_tn)\n",
    "            XX_te[n].append(X_te)\n",
    "            yy_tn[n].append(y_tn)\n",
    "            yy_te[n].append(y_te)\n",
    "\n",
    "    X_tn = pd.concat([pd.concat(XX_tn[n]) for n in [\"M\", \"D\", \"H\"]])\n",
    "    X_te = pd.concat([pd.concat(XX_te[n]) for n in [\"M\", \"D\", \"H\"]])\n",
    "    y_tn = pd.concat([pd.concat(yy_tn[n]) for n in [\"M\", \"D\", \"H\"]])\n",
    "    y_te = pd.concat([pd.concat(yy_te[n]) for n in [\"M\", \"D\", \"H\"]])\n",
    "\n",
    "    return X_tn, X_te, y_tn, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3133fc8d-0b8d-4c0c-b3bc-36226a0410d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor(X_tn, X_te, y_tn, y_te, batch_size=32, val_size=1/6, rs=100):\n",
    "    \"\"\"\n",
    "    X_tn, X_te: MultiIndex DataFrame (Next, Path, Number, Time)\n",
    "    y_tn, y_te: Series or DataFrame with index (Next, Path, Number)\n",
    "    \"\"\"\n",
    "\n",
    "    X_tr, X_vl, y_tr, y_vl = Even_Split(X_tn, y_tn, val_size, rs)\n",
    "    keys_train = y_tr.index\n",
    "    keys_val = y_vl.index\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_tn_scaled = X_tn.copy()\n",
    "    X_te_scaled = X_te.copy()\n",
    "\n",
    "    scaler.fit(X_tn.values)\n",
    "    X_tn_scaled.loc[:, :] = scaler.transform(X_tn.values)\n",
    "    X_te_scaled.loc[:, :] = scaler.transform(X_te.values)\n",
    "\n",
    "    next_map = {'M': 0, 'D': 1, 'H': 2}\n",
    "    get_next = lambda idx: torch.nn.functional.one_hot(torch.tensor([next_map[i] for i in idx.get_level_values(\"Next\")]), num_classes=3).float()\n",
    "\n",
    "    def to_tensor(X_df, y_df, keys):\n",
    "        X_group = X_df.groupby(level=[\"Next\", \"Path\", \"Number\"])\n",
    "        X_tensor = torch.stack([\n",
    "            torch.tensor(X_group.get_group(k).values, dtype=torch.float32)\n",
    "            for k in keys\n",
    "        ])\n",
    "        y_tensor = torch.tensor(y_df.loc[keys].values, dtype=torch.float32).unsqueeze(1)\n",
    "        return X_tensor, y_tensor\n",
    "\n",
    "    next_train = get_next(pd.MultiIndex.from_tuples(keys_train, names=[\"Next\", \"Path\", \"Number\"]))\n",
    "    next_val   = get_next(pd.MultiIndex.from_tuples(keys_val,   names=[\"Next\", \"Path\", \"Number\"]))\n",
    "    next_test  = get_next(y_te.index)\n",
    "    \n",
    "    X_train_tensor, y_train_tensor = to_tensor(X_tn_scaled, y_tn, keys_train)\n",
    "    X_val_tensor,   y_val_tensor   = to_tensor(X_tn_scaled, y_tn, keys_val)\n",
    "    X_test_tensor,  y_test_tensor  = to_tensor(X_te_scaled, y_te, y_te.index.drop_duplicates())\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train_tensor, next_train, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(TensorDataset(X_val_tensor, next_val,  y_val_tensor),   batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(TensorDataset(X_test_tensor, next_test,  y_test_tensor),  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, X_test_tensor, y_test_tensor, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a46fc84b-24e7-487b-a538-10e77c7e148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setRandomSeed(random_seed=0):\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a7a5600-ca48-42b9-a7d4-91ae59a8b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, lr=1e-3, weight_decay=0, epoch=1000, patience=50, random_seed = 0):\n",
    "        self.random_seed = random_seed\n",
    "        #setRandomSeed(self.random_seed)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.cri2 = MAPELoss()\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=200, gamma=0.8)\n",
    "        self.epoch = epoch\n",
    "        self.patience = patience\n",
    "\n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def train(self, train_loader, test_loader=None, val_loader=None):\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_state = None\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        for ep in range(1, self.epoch + 1):\n",
    "            self.model.train()\n",
    "            for x_batch, onehot, y_batch in train_loader:\n",
    "                x_batch, onehot, y_batch = x_batch.to(self.device), onehot.to(self.device), y_batch.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(x_batch, onehot)\n",
    "                loss = self.cri2(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            self.scheduler.step()\n",
    "\n",
    "            avg_train_loss = self.evaluate(train_loader)\n",
    "            test_loss = self.evaluate(test_loader) if test_loader else None\n",
    "            val_loss = self.evaluate(val_loader) if val_loader else None\n",
    "\n",
    "            self.train_loss.append(avg_train_loss)\n",
    "            self.test_loss.append(test_loss)\n",
    "            self.val_loss.append(val_loss)\n",
    "\n",
    "            if val_loader:\n",
    "                if val_loss < best_val_loss - 1e-4:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_model_state = self.model.state_dict()\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    if epochs_no_improve >= self.patience:\n",
    "                        print(f\"Early stopping at epoch {ep}\")\n",
    "                        break\n",
    "\n",
    "        if best_model_state:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        if data_loader is None:\n",
    "            return None\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, onehot, y_batch in data_loader:\n",
    "                x_batch, onehot, y_batch = x_batch.to(self.device), onehot.to(self.device), y_batch.to(self.device)\n",
    "                outputs = self.model(x_batch, onehot)\n",
    "                loss = self.cri2(outputs, y_batch)\n",
    "                total_loss += loss.item()\n",
    "        return total_loss / len(data_loader)\n",
    "\n",
    "    def predict(self, x, onehot):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = x.to(self.device)\n",
    "            onehot = onehot.to(self.device)\n",
    "            return self.model(x, onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9feefaab-7522-4dfb-8e3d-64e935acdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(model, info, train_loader, val_loader, test_loader, plot = True):\n",
    "    rs, c1, c2, k1, k2 = info\n",
    "    \n",
    "    y_true_train = []\n",
    "    y_pred_train = []\n",
    "    \n",
    "    y_true_val = []\n",
    "    y_pred_val = []\n",
    "    \n",
    "    y_true_test = []\n",
    "    y_pred_test = []\n",
    "\n",
    "    y_true_test_M = []\n",
    "    y_pred_test_M = []\n",
    "\n",
    "    y_true_test_D = []\n",
    "    y_pred_test_D = []\n",
    "\n",
    "    y_true_test_H = []\n",
    "    y_pred_test_H = []\n",
    "    \n",
    "    for x_batch, onehot, y_batch in train_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_train.append(y_batch)\n",
    "        y_pred_train.append(preds.cpu())\n",
    "    \n",
    "    for x_batch, onehot, y_batch in val_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_val.append(y_batch)\n",
    "        y_pred_val.append(preds.cpu())\n",
    "    \n",
    "    for x_batch, onehot, y_batch in test_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_test.append(y_batch)\n",
    "        y_pred_test.append(preds.cpu())\n",
    "    \n",
    "        onehot_np = onehot.cpu().numpy()\n",
    "        y_true_np = y_batch.cpu().numpy()\n",
    "        y_pred_np = preds.cpu().numpy()\n",
    "    \n",
    "        for i in range(len(onehot_np)):\n",
    "            if np.array_equal(onehot_np[i], [1, 0, 0]):  # 'M'\n",
    "                y_true_test_M.append(y_true_np[i])\n",
    "                y_pred_test_M.append(y_pred_np[i])\n",
    "            elif np.array_equal(onehot_np[i], [0, 1, 0]):  # 'D'\n",
    "                y_true_test_D.append(y_true_np[i])\n",
    "                y_pred_test_D.append(y_pred_np[i])\n",
    "            elif np.array_equal(onehot_np[i], [0, 0, 1]):  # 'H'\n",
    "                y_true_test_H.append(y_true_np[i])\n",
    "                y_pred_test_H.append(y_pred_np[i])\n",
    "\n",
    "    y_true_train = torch.cat(y_true_train).numpy()\n",
    "    y_pred_train = torch.cat(y_pred_train).numpy()\n",
    "    \n",
    "    y_true_val = torch.cat(y_true_val).numpy()\n",
    "    y_pred_val = torch.cat(y_pred_val).numpy()\n",
    "    \n",
    "    y_true_test = torch.cat(y_true_test).numpy()\n",
    "    y_pred_test = torch.cat(y_pred_test).numpy()\n",
    "\n",
    "    y_true_test_M = np.array(y_true_test_M)\n",
    "    y_pred_test_M = np.array(y_pred_test_M)\n",
    "    \n",
    "    y_true_test_D = np.array(y_true_test_D)\n",
    "    y_pred_test_D = np.array(y_pred_test_D)\n",
    "    \n",
    "    y_true_test_H = np.array(y_true_test_H)\n",
    "    y_pred_test_H = np.array(y_pred_test_H)\n",
    "    \n",
    "    mape_M = mean_absolute_percentage_error(y_true_test_M, y_pred_test_M) * 100 if len(y_true_test_M) > 0 else np.nan\n",
    "    mape_D = mean_absolute_percentage_error(y_true_test_D, y_pred_test_D) * 100 if len(y_true_test_D) > 0 else np.nan\n",
    "    mape_H = mean_absolute_percentage_error(y_true_test_H, y_pred_test_H) * 100 if len(y_true_test_H) > 0 else np.nan\n",
    "    \n",
    "    train_mape = mean_absolute_percentage_error(y_true_train, y_pred_train) * 100\n",
    "    val_mape = mean_absolute_percentage_error(y_true_val, y_pred_val) * 100\n",
    "    test_mape = mean_absolute_percentage_error(y_true_test, y_pred_test) * 100\n",
    "    print(f\"Model: {model}, rs: {rs}, c1: {c1}, c2: {c2}, k1: {k1}, k2: {k2}\\n Train MAPE: {train_mape:.2f}%, Val MAPE: {val_mape:.2f}%, Test MAPE: {test_mape:.2f}%\")\n",
    "    print(f\"Test MAPE by 'Next': M: {mape_M:.2f}%, D: {mape_D:.2f}%, H: {mape_H:.2f}%\")\n",
    "    \n",
    "    if plot == True:\n",
    "        _ = plt.figure()\n",
    "        _ = plt.scatter(y_true_train, y_pred_train, label = 'Train')\n",
    "        _ = plt.scatter(y_true_val, y_pred_val, label = 'Val')\n",
    "        _ = plt.scatter(y_true_test, y_pred_test, label = 'Test')\n",
    "        min_val = min(y_true_train.min(), y_true_test.min())\n",
    "        max_val = max(y_true_train.max(), y_true_test.max())\n",
    "        _ = plt.plot([min_val, max_val], [min_val, max_val], 'k--', label='Ideal line')\n",
    "        _ = plt.xlabel('True SOH')\n",
    "        _ = plt.ylabel('Predicted SOH')\n",
    "        _ = plt.legend()\n",
    "        _ = plt.title(f'Random state: {rs}, hid: {hid}, {nl} layer, lr: {lr}')\n",
    "    return train_mape, val_mape, test_mape, mape_M, mape_D, mape_H\n",
    "\n",
    "def plot_loss(info, train_loss, val_loss, test_loss):\n",
    "    rs, c1, c2, k1, k2 = info\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(train_loss, label = 'Train loss')\n",
    "    _ = plt.plot(val_loss, label = 'Val loss')\n",
    "    _ = plt.plot(test_loss, label = 'Test loss')\n",
    "    _ = plt.ylim([0, 2])\n",
    "    _ = plt.xlabel('Epoch')\n",
    "    _ = plt.ylabel('Loss')\n",
    "    _ = plt.legend()\n",
    "    _ = plt.title(f'Random state: {rs}, hid: {hid}, {nl} layers, lr: {lr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd12095-98bf-4144-9920-4d6a042b0b11",
   "metadata": {},
   "source": [
    "## 1. 2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5f5b70d-f010-49c0-8bfb-e6fe81fc0d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2D_Compressor(nn.Module):\n",
    "    def __init__(self, \n",
    "                 output_dim=4,\n",
    "                 conv1_channels=16,\n",
    "                 conv2_channels=16,\n",
    "                 kernel_size1=(5, 2),\n",
    "                 kernel_size2=(3, 1)):\n",
    "        super(CNN2D_Compressor, self).__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=conv1_channels, kernel_size=kernel_size1, stride=1,\n",
    "                      padding=(kernel_size1[0] // 2, kernel_size1[1] // 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Conv2d(conv1_channels, conv2_channels, kernel_size=kernel_size2,\n",
    "                      padding=(kernel_size2[0] // 2, kernel_size2[1] // 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(conv2_channels, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ab81703-2c07-484c-910f-12d4e46abdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2D_MLP(nn.Module):\n",
    "    def __init__(self, conv1_channels, conv2_channels, kernel_size1, kernel_size2, out_dim=4, hidden_dim=64, num_layers=2, next_dim = 3):\n",
    "        super(CNN2D_MLP, self).__init__()\n",
    "        self.encoder = CNN2D_Compressor(out_dim, conv1_channels, conv2_channels, kernel_size1, kernel_size2)\n",
    "        \n",
    "        layers = []\n",
    "\n",
    "        input_dim = out_dim + next_dim\n",
    "        output_dim = 1\n",
    "\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "\n",
    "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, onehot):\n",
    "        x_feat = self.encoder(x)\n",
    "        x_concat = torch.cat([x_feat, onehot], dim=1)\n",
    "        return self.model(x_concat)\n",
    "\n",
    "class MAPELoss(nn.Module):\n",
    "    def __init__(self, epsilon=1e-7):\n",
    "        super(MAPELoss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.mean(torch.abs((y_true - y_pred) / (y_true + self.epsilon))) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b885de-fb30-489f-9710-8d5db83d8767",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dd8064f-8cbf-40f3-b87a-978d97e09ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 195\n",
      "Model: 2D CNN, rs: 100, c1: 8, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.07%, Val MAPE: 1.36%, Test MAPE: 1.20%\n",
      "Test MAPE by 'Next': M: 1.26%, D: 1.24%, H: 1.10%\n",
      "9.96 s\n",
      "Early stopping at epoch 214\n",
      "Model: 2D CNN, rs: 100, c1: 8, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.06%, Val MAPE: 1.09%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 1.03%, D: 1.06%, H: 1.01%\n",
      "9.09 s\n",
      "Early stopping at epoch 147\n",
      "Model: 2D CNN, rs: 100, c1: 8, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.21%, Val MAPE: 1.42%, Test MAPE: 1.28%\n",
      "Test MAPE by 'Next': M: 1.29%, D: 1.38%, H: 1.18%\n",
      "6.52 s\n",
      "Early stopping at epoch 326\n",
      "Model: 2D CNN, rs: 100, c1: 8, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.98%, Val MAPE: 1.00%, Test MAPE: 1.07%\n",
      "Test MAPE by 'Next': M: 1.11%, D: 1.05%, H: 1.06%\n",
      "13.10 s\n",
      "Early stopping at epoch 215\n",
      "Model: 2D CNN, rs: 100, c1: 8, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.01%, Val MAPE: 1.20%, Test MAPE: 1.09%\n",
      "Test MAPE by 'Next': M: 1.11%, D: 1.09%, H: 1.07%\n",
      "8.81 s\n",
      "Early stopping at epoch 167\n",
      "Model: 2D CNN, rs: 100, c1: 8, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 0.95%, Val MAPE: 1.15%, Test MAPE: 1.13%\n",
      "Test MAPE by 'Next': M: 1.18%, D: 1.22%, H: 0.98%\n",
      "6.96 s\n",
      "Early stopping at epoch 229\n",
      "Model: 2D CNN, rs: 100, c1: 8, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.91%, Val MAPE: 0.98%, Test MAPE: 1.06%\n",
      "Test MAPE by 'Next': M: 1.08%, D: 1.04%, H: 1.06%\n",
      "9.20 s\n",
      "Early stopping at epoch 162\n",
      "Model: 2D CNN, rs: 100, c1: 8, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.25%, Val MAPE: 1.23%, Test MAPE: 1.37%\n",
      "Test MAPE by 'Next': M: 1.45%, D: 1.31%, H: 1.35%\n",
      "6.57 s\n",
      "Early stopping at epoch 254\n",
      "Model: 2D CNN, rs: 100, c1: 16, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.97%, Val MAPE: 1.28%, Test MAPE: 1.06%\n",
      "Test MAPE by 'Next': M: 1.11%, D: 1.14%, H: 0.92%\n",
      "10.36 s\n",
      "Early stopping at epoch 156\n",
      "Model: 2D CNN, rs: 100, c1: 16, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 0.91%, Val MAPE: 1.04%, Test MAPE: 1.09%\n",
      "Test MAPE by 'Next': M: 1.13%, D: 1.14%, H: 1.01%\n",
      "6.41 s\n",
      "Early stopping at epoch 136\n",
      "Model: 2D CNN, rs: 100, c1: 16, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.11%, Val MAPE: 1.12%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 1.22%, D: 1.11%, H: 0.99%\n",
      "5.60 s\n",
      "Early stopping at epoch 241\n",
      "Model: 2D CNN, rs: 100, c1: 16, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.94%, Val MAPE: 0.97%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 1.24%, D: 1.05%, H: 1.06%\n",
      "9.92 s\n",
      "Early stopping at epoch 237\n",
      "Model: 2D CNN, rs: 100, c1: 16, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.92%, Val MAPE: 1.00%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: 1.16%, D: 1.06%, H: 0.91%\n",
      "9.60 s\n",
      "Early stopping at epoch 233\n",
      "Model: 2D CNN, rs: 100, c1: 16, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 0.99%, Val MAPE: 1.15%, Test MAPE: 1.15%\n",
      "Test MAPE by 'Next': M: 1.20%, D: 1.06%, H: 1.18%\n",
      "9.42 s\n",
      "Early stopping at epoch 178\n",
      "Model: 2D CNN, rs: 100, c1: 16, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.97%, Val MAPE: 1.09%, Test MAPE: 1.23%\n",
      "Test MAPE by 'Next': M: 1.36%, D: 1.11%, H: 1.21%\n",
      "7.11 s\n",
      "Early stopping at epoch 175\n",
      "Model: 2D CNN, rs: 100, c1: 16, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.93%, Val MAPE: 0.96%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: 1.16%, D: 1.05%, H: 1.03%\n",
      "7.10 s\n",
      "Early stopping at epoch 561\n",
      "Model: 2D CNN, rs: 120, c1: 8, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.06%, Val MAPE: 0.95%, Test MAPE: 0.90%\n",
      "Test MAPE by 'Next': M: 1.02%, D: 0.74%, H: 0.95%\n",
      "22.20 s\n",
      "Early stopping at epoch 234\n",
      "Model: 2D CNN, rs: 120, c1: 8, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.18%, Val MAPE: 1.17%, Test MAPE: 1.14%\n",
      "Test MAPE by 'Next': M: 1.25%, D: 1.05%, H: 1.13%\n",
      "9.39 s\n",
      "Early stopping at epoch 306\n",
      "Model: 2D CNN, rs: 120, c1: 8, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.08%, Val MAPE: 1.04%, Test MAPE: 0.82%\n",
      "Test MAPE by 'Next': M: 0.91%, D: 0.73%, H: 0.82%\n",
      "12.35 s\n",
      "Early stopping at epoch 80\n",
      "Model: 2D CNN, rs: 120, c1: 8, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.18%, Val MAPE: 1.00%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: 1.14%, D: 0.93%, H: 1.00%\n",
      "3.42 s\n",
      "Early stopping at epoch 266\n",
      "Model: 2D CNN, rs: 120, c1: 8, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.04%, Val MAPE: 1.00%, Test MAPE: 0.79%\n",
      "Test MAPE by 'Next': M: 0.88%, D: 0.74%, H: 0.76%\n",
      "11.13 s\n",
      "Early stopping at epoch 135\n",
      "Model: 2D CNN, rs: 120, c1: 8, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.40%, Val MAPE: 1.32%, Test MAPE: 1.13%\n",
      "Test MAPE by 'Next': M: 1.14%, D: 1.17%, H: 1.08%\n",
      "5.81 s\n",
      "Early stopping at epoch 403\n",
      "Model: 2D CNN, rs: 120, c1: 8, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.95%, Val MAPE: 0.94%, Test MAPE: 0.78%\n",
      "Test MAPE by 'Next': M: 0.83%, D: 0.69%, H: 0.81%\n",
      "16.80 s\n",
      "Early stopping at epoch 270\n",
      "Model: 2D CNN, rs: 120, c1: 8, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.16%, Val MAPE: 1.13%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 1.24%, D: 0.95%, H: 1.15%\n",
      "11.46 s\n",
      "Early stopping at epoch 220\n",
      "Model: 2D CNN, rs: 120, c1: 16, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.05%, Val MAPE: 1.00%, Test MAPE: 0.92%\n",
      "Test MAPE by 'Next': M: 1.02%, D: 0.84%, H: 0.89%\n",
      "9.21 s\n",
      "Early stopping at epoch 360\n",
      "Model: 2D CNN, rs: 120, c1: 16, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.08%, Val MAPE: 1.08%, Test MAPE: 0.84%\n",
      "Test MAPE by 'Next': M: 0.91%, D: 0.78%, H: 0.84%\n",
      "15.05 s\n",
      "Early stopping at epoch 115\n",
      "Model: 2D CNN, rs: 120, c1: 16, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.15%, Val MAPE: 1.02%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: 1.06%, D: 0.85%, H: 0.93%\n",
      "4.88 s\n",
      "Early stopping at epoch 130\n",
      "Model: 2D CNN, rs: 120, c1: 16, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.43%, Val MAPE: 1.23%, Test MAPE: 1.40%\n",
      "Test MAPE by 'Next': M: 1.56%, D: 1.41%, H: 1.22%\n",
      "5.61 s\n",
      "Early stopping at epoch 87\n",
      "Model: 2D CNN, rs: 120, c1: 16, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.25%, Val MAPE: 1.02%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: 1.16%, D: 0.84%, H: 1.13%\n",
      "3.78 s\n",
      "Early stopping at epoch 289\n",
      "Model: 2D CNN, rs: 120, c1: 16, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 0.99%, Val MAPE: 0.92%, Test MAPE: 0.81%\n",
      "Test MAPE by 'Next': M: 0.92%, D: 0.70%, H: 0.82%\n",
      "11.43 s\n",
      "Early stopping at epoch 198\n",
      "Model: 2D CNN, rs: 120, c1: 16, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.18%, Val MAPE: 1.06%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.25%, D: 1.02%, H: 0.89%\n",
      "7.92 s\n",
      "Early stopping at epoch 311\n",
      "Model: 2D CNN, rs: 120, c1: 16, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.21%, Val MAPE: 1.02%, Test MAPE: 1.00%\n",
      "Test MAPE by 'Next': M: 1.13%, D: 0.85%, H: 1.03%\n",
      "12.34 s\n",
      "Early stopping at epoch 251\n",
      "Model: 2D CNN, rs: 140, c1: 8, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.89%, Val MAPE: 1.31%, Test MAPE: 1.06%\n",
      "Test MAPE by 'Next': M: 1.05%, D: 1.13%, H: 1.00%\n",
      "10.08 s\n",
      "Early stopping at epoch 306\n",
      "Model: 2D CNN, rs: 140, c1: 8, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 0.96%, Val MAPE: 1.09%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.13%, D: 1.01%, H: 1.00%\n",
      "12.55 s\n",
      "Early stopping at epoch 282\n",
      "Model: 2D CNN, rs: 140, c1: 8, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.81%, Val MAPE: 1.21%, Test MAPE: 1.07%\n",
      "Test MAPE by 'Next': M: 1.14%, D: 1.16%, H: 0.89%\n",
      "11.15 s\n",
      "Early stopping at epoch 356\n",
      "Model: 2D CNN, rs: 140, c1: 8, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.82%, Val MAPE: 1.03%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: 1.08%, D: 0.96%, H: 0.78%\n",
      "14.28 s\n",
      "Early stopping at epoch 236\n",
      "Model: 2D CNN, rs: 140, c1: 8, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.89%, Val MAPE: 1.26%, Test MAPE: 1.00%\n",
      "Test MAPE by 'Next': M: 1.05%, D: 0.99%, H: 0.97%\n",
      "12.27 s\n",
      "Early stopping at epoch 219\n",
      "Model: 2D CNN, rs: 140, c1: 8, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.15%, Val MAPE: 1.32%, Test MAPE: 1.22%\n",
      "Test MAPE by 'Next': M: 1.39%, D: 1.11%, H: 1.17%\n",
      "13.08 s\n",
      "Early stopping at epoch 115\n",
      "Model: 2D CNN, rs: 140, c1: 8, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.13%, Val MAPE: 1.15%, Test MAPE: 1.15%\n",
      "Test MAPE by 'Next': M: 1.28%, D: 1.13%, H: 1.04%\n",
      "7.05 s\n",
      "Early stopping at epoch 412\n",
      "Model: 2D CNN, rs: 140, c1: 8, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.14%, Val MAPE: 1.61%, Test MAPE: 1.30%\n",
      "Test MAPE by 'Next': M: 1.20%, D: 1.40%, H: 1.31%\n",
      "25.06 s\n",
      "Early stopping at epoch 182\n",
      "Model: 2D CNN, rs: 140, c1: 16, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.01%, Val MAPE: 1.52%, Test MAPE: 1.16%\n",
      "Test MAPE by 'Next': M: 1.06%, D: 1.23%, H: 1.18%\n",
      "11.23 s\n",
      "Early stopping at epoch 198\n",
      "Model: 2D CNN, rs: 140, c1: 16, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.09%, Val MAPE: 1.27%, Test MAPE: 1.20%\n",
      "Test MAPE by 'Next': M: 1.33%, D: 1.15%, H: 1.12%\n",
      "15.05 s\n",
      "Early stopping at epoch 724\n",
      "Model: 2D CNN, rs: 140, c1: 16, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.80%, Val MAPE: 1.14%, Test MAPE: 1.00%\n",
      "Test MAPE by 'Next': M: 1.01%, D: 1.08%, H: 0.92%\n",
      "47.35 s\n",
      "Early stopping at epoch 285\n",
      "Model: 2D CNN, rs: 140, c1: 16, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.08%, Val MAPE: 1.37%, Test MAPE: 1.19%\n",
      "Test MAPE by 'Next': M: 1.32%, D: 1.15%, H: 1.10%\n",
      "17.72 s\n",
      "Early stopping at epoch 288\n",
      "Model: 2D CNN, rs: 140, c1: 16, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.88%, Val MAPE: 1.18%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 1.06%, D: 1.04%, H: 0.99%\n",
      "16.61 s\n",
      "Early stopping at epoch 228\n",
      "Model: 2D CNN, rs: 140, c1: 16, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.35%, Val MAPE: 1.49%, Test MAPE: 1.39%\n",
      "Test MAPE by 'Next': M: 1.56%, D: 1.22%, H: 1.38%\n",
      "14.78 s\n",
      "Early stopping at epoch 185\n",
      "Model: 2D CNN, rs: 140, c1: 16, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.08%, Val MAPE: 1.36%, Test MAPE: 1.17%\n",
      "Test MAPE by 'Next': M: 1.32%, D: 1.13%, H: 1.05%\n",
      "11.97 s\n",
      "Early stopping at epoch 217\n",
      "Model: 2D CNN, rs: 140, c1: 16, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.89%, Val MAPE: 1.14%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: 1.11%, D: 1.03%, H: 0.99%\n",
      "12.57 s\n",
      "Early stopping at epoch 275\n",
      "Model: 2D CNN, rs: 160, c1: 8, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.97%, Val MAPE: 1.29%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.32%, D: 0.87%, H: 0.97%\n",
      "15.97 s\n",
      "Early stopping at epoch 283\n",
      "Model: 2D CNN, rs: 160, c1: 8, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.07%, Val MAPE: 1.24%, Test MAPE: 1.22%\n",
      "Test MAPE by 'Next': M: 1.37%, D: 1.08%, H: 1.22%\n",
      "16.89 s\n",
      "Early stopping at epoch 126\n",
      "Model: 2D CNN, rs: 160, c1: 8, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.09%, Val MAPE: 1.32%, Test MAPE: 1.25%\n",
      "Test MAPE by 'Next': M: 1.48%, D: 1.04%, H: 1.22%\n",
      "7.30 s\n",
      "Early stopping at epoch 167\n",
      "Model: 2D CNN, rs: 160, c1: 8, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.12%, Val MAPE: 1.24%, Test MAPE: 1.14%\n",
      "Test MAPE by 'Next': M: 1.24%, D: 0.98%, H: 1.22%\n",
      "10.57 s\n",
      "Early stopping at epoch 177\n",
      "Model: 2D CNN, rs: 160, c1: 8, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.02%, Val MAPE: 1.27%, Test MAPE: 1.13%\n",
      "Test MAPE by 'Next': M: 1.30%, D: 0.94%, H: 1.13%\n",
      "9.97 s\n",
      "Early stopping at epoch 274\n",
      "Model: 2D CNN, rs: 160, c1: 8, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.21%, Val MAPE: 1.31%, Test MAPE: 1.19%\n",
      "Test MAPE by 'Next': M: 1.34%, D: 1.07%, H: 1.17%\n",
      "16.74 s\n",
      "Early stopping at epoch 155\n",
      "Model: 2D CNN, rs: 160, c1: 8, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.17%, Val MAPE: 1.29%, Test MAPE: 1.28%\n",
      "Test MAPE by 'Next': M: 1.44%, D: 1.13%, H: 1.28%\n",
      "10.73 s\n",
      "Early stopping at epoch 196\n",
      "Model: 2D CNN, rs: 160, c1: 8, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.88%, Val MAPE: 1.08%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: 1.13%, D: 0.84%, H: 1.05%\n",
      "12.33 s\n",
      "Early stopping at epoch 340\n",
      "Model: 2D CNN, rs: 160, c1: 16, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.10%, Val MAPE: 1.25%, Test MAPE: 1.14%\n",
      "Test MAPE by 'Next': M: 1.23%, D: 1.06%, H: 1.12%\n",
      "18.82 s\n",
      "Early stopping at epoch 346\n",
      "Model: 2D CNN, rs: 160, c1: 16, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 0.94%, Val MAPE: 1.02%, Test MAPE: 0.98%\n",
      "Test MAPE by 'Next': M: 1.15%, D: 0.89%, H: 0.91%\n",
      "22.06 s\n",
      "Early stopping at epoch 225\n",
      "Model: 2D CNN, rs: 160, c1: 16, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.96%, Val MAPE: 1.03%, Test MAPE: 0.98%\n",
      "Test MAPE by 'Next': M: 1.14%, D: 0.86%, H: 0.93%\n",
      "13.58 s\n",
      "Early stopping at epoch 325\n",
      "Model: 2D CNN, rs: 160, c1: 16, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.97%, Val MAPE: 1.01%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: 1.14%, D: 0.90%, H: 1.01%\n",
      "17.76 s\n",
      "Early stopping at epoch 341\n",
      "Model: 2D CNN, rs: 160, c1: 16, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.29%, Val MAPE: 1.25%, Test MAPE: 1.41%\n",
      "Test MAPE by 'Next': M: 1.48%, D: 1.33%, H: 1.42%\n",
      "21.24 s\n",
      "Early stopping at epoch 367\n",
      "Model: 2D CNN, rs: 160, c1: 16, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.06%, Val MAPE: 1.24%, Test MAPE: 1.24%\n",
      "Test MAPE by 'Next': M: 1.52%, D: 1.05%, H: 1.15%\n",
      "20.90 s\n",
      "Early stopping at epoch 216\n",
      "Model: 2D CNN, rs: 160, c1: 16, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.18%, Val MAPE: 1.27%, Test MAPE: 1.19%\n",
      "Test MAPE by 'Next': M: 1.28%, D: 1.25%, H: 1.03%\n",
      "12.32 s\n",
      "Early stopping at epoch 219\n",
      "Model: 2D CNN, rs: 160, c1: 16, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.92%, Val MAPE: 1.02%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.29%, D: 0.86%, H: 0.98%\n",
      "12.93 s\n",
      "Early stopping at epoch 589\n",
      "Model: 2D CNN, rs: 180, c1: 8, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.93%, Val MAPE: 1.19%, Test MAPE: 0.92%\n",
      "Test MAPE by 'Next': M: 0.93%, D: 0.89%, H: 0.95%\n",
      "34.06 s\n",
      "Early stopping at epoch 139\n",
      "Model: 2D CNN, rs: 180, c1: 8, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 1.03%, Val MAPE: 1.23%, Test MAPE: 1.10%\n",
      "Test MAPE by 'Next': M: 1.27%, D: 1.01%, H: 1.02%\n",
      "9.58 s\n",
      "Early stopping at epoch 657\n",
      "Model: 2D CNN, rs: 180, c1: 8, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.05%, Val MAPE: 1.35%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: 0.97%, D: 0.89%, H: 0.98%\n",
      "37.82 s\n",
      "Early stopping at epoch 208\n",
      "Model: 2D CNN, rs: 180, c1: 8, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.95%, Val MAPE: 1.17%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: 1.08%, D: 0.97%, H: 1.07%\n",
      "11.46 s\n",
      "Early stopping at epoch 266\n",
      "Model: 2D CNN, rs: 180, c1: 8, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 0.94%, Val MAPE: 1.10%, Test MAPE: 1.09%\n",
      "Test MAPE by 'Next': M: 1.10%, D: 0.96%, H: 1.22%\n",
      "15.11 s\n",
      "Early stopping at epoch 165\n",
      "Model: 2D CNN, rs: 180, c1: 8, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 0.98%, Val MAPE: 1.12%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.14%, D: 0.93%, H: 1.09%\n",
      "10.77 s\n",
      "Early stopping at epoch 214\n",
      "Model: 2D CNN, rs: 180, c1: 8, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 0.92%, Val MAPE: 1.13%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: 1.14%, D: 0.88%, H: 1.20%\n",
      "13.74 s\n",
      "Early stopping at epoch 141\n",
      "Model: 2D CNN, rs: 180, c1: 8, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 0.99%, Val MAPE: 1.29%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: 1.10%, D: 0.89%, H: 1.08%\n",
      "7.78 s\n",
      "Early stopping at epoch 110\n",
      "Model: 2D CNN, rs: 180, c1: 16, c2: 8, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.01%, Val MAPE: 1.11%, Test MAPE: 1.06%\n",
      "Test MAPE by 'Next': M: 1.22%, D: 0.92%, H: 1.05%\n",
      "6.18 s\n",
      "Early stopping at epoch 341\n",
      "Model: 2D CNN, rs: 180, c1: 16, c2: 8, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 0.88%, Val MAPE: 1.09%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 1.15%, D: 0.84%, H: 1.09%\n",
      "20.70 s\n",
      "Early stopping at epoch 281\n",
      "Model: 2D CNN, rs: 180, c1: 16, c2: 8, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.05%, Val MAPE: 1.67%, Test MAPE: 1.15%\n",
      "Test MAPE by 'Next': M: 1.23%, D: 1.09%, H: 1.13%\n",
      "15.77 s\n",
      "Early stopping at epoch 286\n",
      "Model: 2D CNN, rs: 180, c1: 16, c2: 8, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.00%, Val MAPE: 1.35%, Test MAPE: 1.10%\n",
      "Test MAPE by 'Next': M: 1.15%, D: 1.05%, H: 1.09%\n",
      "16.48 s\n",
      "Early stopping at epoch 209\n",
      "Model: 2D CNN, rs: 180, c1: 16, c2: 16, k1: (2, 2), k2: (2, 2)\n",
      " Train MAPE: 1.14%, Val MAPE: 1.41%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.20%, D: 0.93%, H: 1.03%\n",
      "12.23 s\n",
      "Early stopping at epoch 105\n",
      "Model: 2D CNN, rs: 180, c1: 16, c2: 16, k1: (2, 2), k2: (3, 2)\n",
      " Train MAPE: 0.97%, Val MAPE: 1.12%, Test MAPE: 1.06%\n",
      "Test MAPE by 'Next': M: 1.13%, D: 0.88%, H: 1.15%\n",
      "5.99 s\n",
      "Early stopping at epoch 397\n",
      "Model: 2D CNN, rs: 180, c1: 16, c2: 16, k1: (3, 2), k2: (2, 2)\n",
      " Train MAPE: 1.06%, Val MAPE: 1.30%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: 1.05%, D: 0.82%, H: 0.97%\n",
      "25.50 s\n",
      "Early stopping at epoch 199\n",
      "Model: 2D CNN, rs: 180, c1: 16, c2: 16, k1: (3, 2), k2: (3, 2)\n",
      " Train MAPE: 1.07%, Val MAPE: 1.30%, Test MAPE: 0.98%\n",
      "Test MAPE by 'Next': M: 1.08%, D: 0.91%, H: 0.96%\n",
      "14.36 s\n"
     ]
    }
   ],
   "source": [
    "random_states = [100, 120, 140, 160, 180]\n",
    "bs = 12\n",
    "ep = 1000\n",
    "hid = 16\n",
    "layer = 5\n",
    "lr = 1e-3\n",
    "\n",
    "conv1_channels = [8, 16]\n",
    "conv2_channels = [8, 16]\n",
    "kernel_size1 = [(2,2), (3,2)]\n",
    "kernel_size2 = [(2,2), (3,2)]\n",
    "\n",
    "results_df = pd.DataFrame(columns = ['rs', 'c1', 'c2', 'k1', 'k2', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE'])\n",
    "\n",
    "X, y = Get_Data_all(dat)\n",
    "\n",
    "for rs, c1, c2, k1, k2 in product(random_states, conv1_channels, conv2_channels, kernel_size1, kernel_size2):\n",
    "    setRandomSeed(rs)\n",
    "    start = time.time()\n",
    "    X_tn, X_te, y_tn, y_te = Even_Split(X, y, 1/3, rs)\n",
    "    train_loader, val_loader, test_loader, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, X_test_tensor, y_test_tensor, scaler = convert_to_tensor(X_tn, X_te, y_tn, y_te, bs, 1/6, rs)\n",
    "    \n",
    "    model = CNN2D_MLP(c1, c2, k1, k2, 4, hid, layer)\n",
    "    trainer = Trainer(model, lr=lr, epoch = ep, random_seed = rs)\n",
    "    \n",
    "    trainer.train(train_loader, val_loader, test_loader)\n",
    "\n",
    "    info = [rs, c1, c2, k1, k2]\n",
    "    results = plot_results(\"2D CNN\", info, train_loader, val_loader, test_loader, plot = False)\n",
    "\n",
    "    temp_df = pd.DataFrame(info+list(results)).T\n",
    "    temp_df.columns = ['rs', 'c1', 'c2', 'k1', 'k2', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']\n",
    "    results_df = pd.concat([results_df, temp_df])\n",
    "    print(f\"{time.time()-start:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4819d6c3-d539-4de0-9e83-ed6af617fa12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "      <th>Train MAPE</th>\n",
       "      <th>Val MAPE</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Next M MAPE</th>\n",
       "      <th>Next D MAPE</th>\n",
       "      <th>Next H MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.98399</td>\n",
       "      <td>1.21884</td>\n",
       "      <td>1.027502</td>\n",
       "      <td>1.114629</td>\n",
       "      <td>0.975528</td>\n",
       "      <td>0.992349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>1.059908</td>\n",
       "      <td>1.164218</td>\n",
       "      <td>1.109621</td>\n",
       "      <td>1.211943</td>\n",
       "      <td>1.042025</td>\n",
       "      <td>1.074894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.047781</td>\n",
       "      <td>1.267648</td>\n",
       "      <td>1.073107</td>\n",
       "      <td>1.159264</td>\n",
       "      <td>1.040201</td>\n",
       "      <td>1.019855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>1.00803</td>\n",
       "      <td>1.086551</td>\n",
       "      <td>1.043382</td>\n",
       "      <td>1.127388</td>\n",
       "      <td>0.977068</td>\n",
       "      <td>1.025689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.978392</td>\n",
       "      <td>1.167541</td>\n",
       "      <td>1.021079</td>\n",
       "      <td>1.090528</td>\n",
       "      <td>0.943751</td>\n",
       "      <td>1.028958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>1.138768</td>\n",
       "      <td>1.241994</td>\n",
       "      <td>1.145412</td>\n",
       "      <td>1.237425</td>\n",
       "      <td>1.100555</td>\n",
       "      <td>1.098255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.016486</td>\n",
       "      <td>1.098549</td>\n",
       "      <td>1.06961</td>\n",
       "      <td>1.154421</td>\n",
       "      <td>0.974049</td>\n",
       "      <td>1.08036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>1.083417</td>\n",
       "      <td>1.267553</td>\n",
       "      <td>1.163317</td>\n",
       "      <td>1.222369</td>\n",
       "      <td>1.079433</td>\n",
       "      <td>1.188148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.025761</td>\n",
       "      <td>1.232375</td>\n",
       "      <td>1.065935</td>\n",
       "      <td>1.129492</td>\n",
       "      <td>1.038033</td>\n",
       "      <td>1.030279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>0.977204</td>\n",
       "      <td>1.101304</td>\n",
       "      <td>1.028893</td>\n",
       "      <td>1.132944</td>\n",
       "      <td>0.960548</td>\n",
       "      <td>0.993188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.012441</td>\n",
       "      <td>1.195457</td>\n",
       "      <td>1.036188</td>\n",
       "      <td>1.131962</td>\n",
       "      <td>0.996521</td>\n",
       "      <td>0.98008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>1.084357</td>\n",
       "      <td>1.184813</td>\n",
       "      <td>1.163554</td>\n",
       "      <td>1.281584</td>\n",
       "      <td>1.111728</td>\n",
       "      <td>1.09735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.096347</td>\n",
       "      <td>1.173898</td>\n",
       "      <td>1.114587</td>\n",
       "      <td>1.210165</td>\n",
       "      <td>1.038401</td>\n",
       "      <td>1.095194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>1.071006</td>\n",
       "      <td>1.182369</td>\n",
       "      <td>1.129538</td>\n",
       "      <td>1.267961</td>\n",
       "      <td>0.983322</td>\n",
       "      <td>1.13733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.09422</td>\n",
       "      <td>1.216113</td>\n",
       "      <td>1.116421</td>\n",
       "      <td>1.252153</td>\n",
       "      <td>1.069352</td>\n",
       "      <td>1.027759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>1.004246</td>\n",
       "      <td>1.087491</td>\n",
       "      <td>1.030861</td>\n",
       "      <td>1.153709</td>\n",
       "      <td>0.941073</td>\n",
       "      <td>0.997799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    c1  c2      k1      k2 Train MAPE  Val MAPE Test MAPE Next M MAPE  \\\n",
       "0    8   8  (2, 2)  (2, 2)    0.98399   1.21884  1.027502    1.114629   \n",
       "1    8   8  (2, 2)  (3, 2)   1.059908  1.164218  1.109621    1.211943   \n",
       "2    8   8  (3, 2)  (2, 2)   1.047781  1.267648  1.073107    1.159264   \n",
       "3    8   8  (3, 2)  (3, 2)    1.00803  1.086551  1.043382    1.127388   \n",
       "4    8  16  (2, 2)  (2, 2)   0.978392  1.167541  1.021079    1.090528   \n",
       "5    8  16  (2, 2)  (3, 2)   1.138768  1.241994  1.145412    1.237425   \n",
       "6    8  16  (3, 2)  (2, 2)   1.016486  1.098549   1.06961    1.154421   \n",
       "7    8  16  (3, 2)  (3, 2)   1.083417  1.267553  1.163317    1.222369   \n",
       "8   16   8  (2, 2)  (2, 2)   1.025761  1.232375  1.065935    1.129492   \n",
       "9   16   8  (2, 2)  (3, 2)   0.977204  1.101304  1.028893    1.132944   \n",
       "10  16   8  (3, 2)  (2, 2)   1.012441  1.195457  1.036188    1.131962   \n",
       "11  16   8  (3, 2)  (3, 2)   1.084357  1.184813  1.163554    1.281584   \n",
       "12  16  16  (2, 2)  (2, 2)   1.096347  1.173898  1.114587    1.210165   \n",
       "13  16  16  (2, 2)  (3, 2)   1.071006  1.182369  1.129538    1.267961   \n",
       "14  16  16  (3, 2)  (2, 2)    1.09422  1.216113  1.116421    1.252153   \n",
       "15  16  16  (3, 2)  (3, 2)   1.004246  1.087491  1.030861    1.153709   \n",
       "\n",
       "   Next D MAPE Next H MAPE  \n",
       "0     0.975528    0.992349  \n",
       "1     1.042025    1.074894  \n",
       "2     1.040201    1.019855  \n",
       "3     0.977068    1.025689  \n",
       "4     0.943751    1.028958  \n",
       "5     1.100555    1.098255  \n",
       "6     0.974049     1.08036  \n",
       "7     1.079433    1.188148  \n",
       "8     1.038033    1.030279  \n",
       "9     0.960548    0.993188  \n",
       "10    0.996521     0.98008  \n",
       "11    1.111728     1.09735  \n",
       "12    1.038401    1.095194  \n",
       "13    0.983322     1.13733  \n",
       "14    1.069352    1.027759  \n",
       "15    0.941073    0.997799  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = results_df.groupby(['c1', 'c2', 'k1', 'k2'])[['Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']].mean().reset_index()\n",
    "summary_df \n",
    "summary_df.to_csv('2D CNN_next_info_sum.csv')\n",
    "results_df.to_csv('2D CNN_next_info.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
