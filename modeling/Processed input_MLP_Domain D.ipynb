{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f777b66-b5ce-4b51-a260-0f95e8c9dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from numpy import hstack, vstack\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c268bd1-67cb-4cfb-842e-0bd9f4e75302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dkstj\\\\Desktop\\\\연구\\\\현대차 3차\\\\Rapid_fin\\\\deep learning modeling'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_directory(foldername, filename = None, back_num = 0):\n",
    "    cur = os.getcwd()\n",
    "    for i in range(back_num):\n",
    "        cur = os.path.abspath(os.path.join(cur, os.pardir))\n",
    "    for folder in foldername:\n",
    "        cur = os.path.join(cur, folder)\n",
    "    if not os.path.exists(cur):\n",
    "        os.makedirs(cur)\n",
    "        print(f'{cur} created')\n",
    "    if filename != None:\n",
    "        cur = os.path.join(cur, filename)\n",
    "    return cur\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e19cef-7f59-4f9c-a102-bce664fb00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_add = find_directory(foldername = [], filename = 'SOC_Point_Data.csv')\n",
    "dat = pd.read_csv(csv_add, index_col = (0,1,2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51190277-29e5-4a99-bb89-b99b751c7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Data(dat) :\n",
    "    \n",
    "    RPT_MODE = \"0.1C\"\n",
    "    SOC_Range = [9,10,11,12]\n",
    "\n",
    "    Time_Range = range(6, 15, 2)\n",
    "    SOC_Range = [str(i) for i in SOC_Range]\n",
    "    \n",
    "\n",
    "    Data = dat\n",
    "\n",
    "    X = Data.loc[RPT_MODE, \"0\" : \"16\"]\n",
    "    Y = Data.loc[RPT_MODE, [\"SOH\", \"Next_SOH\", \"Ratio_SOH\", \"Ratio_CYC\"]].groupby(level = [\"Next\", \"Path\", \"Number\"]).mean()\n",
    "    \n",
    "    y = pd.Series(Y[\"Next_SOH\"] - Y[\"SOH\"], name = \"Delta_SOH\")\n",
    "    \n",
    "    Y = pd.concat([Y, y], axis = 1)\n",
    "\n",
    "    X_seek = X.loc[X.index.get_level_values(\"Time\").isin(Time_Range), SOC_Range]\n",
    "\n",
    "\n",
    "    X_std = X_seek.groupby(level = [\"Next\", \"Path\", \"Number\"]).std()\n",
    "    \n",
    "    return X_std, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19cdfd1a-dfb7-4066-ab61-9ef975b8d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Even_Split(X, y, no_next, test_size, rs) :\n",
    "\n",
    "    Nexts = [n for n in ['M', 'D', 'H'] if n not in no_next]\n",
    "\n",
    "    XX = {n: X.xs(key = n, level = 'Next', drop_level = False) for n in Nexts}\n",
    "    yy = {n: y.xs(key = n, level = 'Next', drop_level = False) for n in Nexts}\n",
    "    \n",
    "    \n",
    "    XXX = {n: [] for n in Nexts}\n",
    "    yyy = {n: [] for n in Nexts}\n",
    "    \n",
    "    \n",
    "    for n in Nexts:\n",
    "        for path in range(1,5) :\n",
    "            X_path = XX[n].loc[XX[n].index.get_level_values(level = 'Path').str.len() == path]\n",
    "            y_path = yy[n].loc[yy[n].index.get_level_values(level = 'Path').str.len() == path]\n",
    "            \n",
    "            XXX[n].append(X_path)\n",
    "            yyy[n].append(y_path)\n",
    "            \n",
    "            \n",
    "    XX_tn = {n: [] for n in Nexts}\n",
    "    XX_te = {n: [] for n in Nexts}\n",
    "    \n",
    "    yy_tn = {n: [] for n in Nexts}\n",
    "    yy_te = {n: [] for n in Nexts}\n",
    "        \n",
    "    for n in Nexts :\n",
    "        for path in range(1,5) :\n",
    "            X_temp = XXX[n][path-1]\n",
    "            y_temp = yyy[n][path-1]\n",
    "            \n",
    "            X_tn, X_te, y_tn, y_te = train_test_split(X_temp, y_temp, test_size = test_size, random_state = rs)\n",
    "            \n",
    "            XX_tn[n].append(X_tn)\n",
    "            XX_te[n].append(X_te)\n",
    "            yy_tn[n].append(y_tn)\n",
    "            yy_te[n].append(y_te)\n",
    "                  \n",
    "    for n in Nexts :\n",
    "        XX_tn[n] = pd.concat(XX_tn[n])\n",
    "        XX_te[n] = pd.concat(XX_te[n])\n",
    "        yy_tn[n] = pd.concat(yy_tn[n])\n",
    "        yy_te[n] = pd.concat(yy_te[n])\n",
    "        \n",
    "        \n",
    "    X_tn = pd.concat(XX_tn.values())\n",
    "    X_te = pd.concat(XX_te.values())\n",
    "    \n",
    "    y_tn = pd.concat(yy_tn.values())\n",
    "    y_te = pd.concat(yy_te.values())\n",
    "    \n",
    "    return X_tn, X_te, y_tn, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "982efbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Domain_Split(X, y, test_domain):\n",
    "    X_M = X.xs(key = 'M', level = 'Next', drop_level = False)\n",
    "    X_D = X.xs(key = 'D', level = 'Next', drop_level = False)\n",
    "    X_H = X.xs(key = 'H', level = 'Next', drop_level = False)\n",
    "    \n",
    "    XX = {\"M\" : X_M, \"D\" : X_D, \"H\" : X_H}\n",
    "    \n",
    "    y_M = y.xs(key = 'M', level = 'Next', drop_level = False)\n",
    "    y_D = y.xs(key = 'D', level = 'Next', drop_level = False)\n",
    "    y_H = y.xs(key = 'H', level = 'Next', drop_level = False)\n",
    "    \n",
    "    yy = {\"M\" : y_M, \"D\" : y_D, \"H\" : y_H}\n",
    "    \n",
    "    \n",
    "    X_tn = pd.concat([XX[n] for n in ['M', 'D', 'H'] if n not in test_domain])\n",
    "    X_te = pd.concat([XX[n] for n in ['M', 'D', 'H'] if n in test_domain])\n",
    "\n",
    "    y_tn = pd.concat([yy[n] for n in ['M', 'D', 'H'] if n not in test_domain])\n",
    "    y_te = pd.concat([yy[n] for n in ['M', 'D', 'H'] if n in test_domain])\n",
    "    \n",
    "    return X_tn, X_te, y_tn, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f240b499-f460-4d4d-a641-1427605d59ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_tensor(index_list):\n",
    "    next_mapping = {'M': 0, 'D': 1, 'H': 2}\n",
    "    next_index = [next_mapping[idx[0]] for idx in index_list] \n",
    "    next_tensor = torch.tensor(next_index)\n",
    "    one_hot = torch.nn.functional.one_hot(next_tensor, num_classes=3).float()\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f614def-b4a4-481d-835c-7798c2ac0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setRandomSeed(random_seed=0):\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ab81703-2c07-484c-910f-12d4e46abdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, num_layers=2, next_dim = 3):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        input_dim = 4 + next_dim\n",
    "        output_dim = 1\n",
    "\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, onehot):\n",
    "        x_concat = torch.cat([x, onehot], dim=1)\n",
    "        return self.model(x_concat)\n",
    "\n",
    "class MAPELoss(nn.Module):\n",
    "    def __init__(self, epsilon=1e-7):\n",
    "        super(MAPELoss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.mean(torch.abs((y_true - y_pred) / (y_true + self.epsilon))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a7a5600-ca48-42b9-a7d4-91ae59a8b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, lr=1e-3, weight_decay=0, epoch=1000, patience=50, random_seed = 0, optimizer = None):\n",
    "        self.random_seed = random_seed\n",
    "        #setRandomSeed(self.random_seed)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.cri2 = MAPELoss()\n",
    "        if optimizer is None:\n",
    "            self.optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        else:\n",
    "            self.optimizer = optimizer\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=200, gamma=0.8)\n",
    "        self.epoch = epoch\n",
    "        self.patience = patience\n",
    "\n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def train(self, train_loader, test_loader=None, val_loader=None):\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_state = None\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        for ep in range(1, self.epoch + 1):\n",
    "            self.model.train()\n",
    "            for x_batch, onehot, y_batch in train_loader:\n",
    "                x_batch, onehot, y_batch = x_batch.to(self.device), onehot.to(self.device), y_batch.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(x_batch, onehot)\n",
    "                loss = self.cri2(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            self.scheduler.step()\n",
    "\n",
    "            avg_train_loss = self.evaluate(train_loader)\n",
    "            test_loss = self.evaluate(test_loader) if test_loader else None\n",
    "            val_loss = self.evaluate(val_loader) if val_loader else None\n",
    "\n",
    "            self.train_loss.append(avg_train_loss)\n",
    "            self.test_loss.append(test_loss)\n",
    "            self.val_loss.append(val_loss)\n",
    "\n",
    "            if val_loader:\n",
    "                if val_loss < best_val_loss - 1e-4:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_model_state = self.model.state_dict()\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    if epochs_no_improve >= self.patience:\n",
    "                        print(f\"Early stopping at epoch {ep}\")\n",
    "                        break\n",
    "\n",
    "        if best_model_state:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        if data_loader is None:\n",
    "            return None\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, onehot, y_batch in data_loader:\n",
    "                x_batch, onehot, y_batch = x_batch.to(self.device), onehot.to(self.device), y_batch.to(self.device)\n",
    "                outputs = self.model(x_batch, onehot)\n",
    "                loss = self.cri2(outputs, y_batch)\n",
    "                total_loss += loss.item()\n",
    "        return total_loss / len(data_loader)\n",
    "\n",
    "    def predict(self, x, onehot):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = x.to(self.device)\n",
    "            onehot = onehot.to(self.device)\n",
    "            return self.model(x, onehot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9feefaab-7522-4dfb-8e3d-64e935acdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(info, train_loader, val_loader, test_loader, plot = True):\n",
    "    rs, hid, nl, lr = info\n",
    "    \n",
    "    y_true_train = []\n",
    "    y_pred_train = []\n",
    "    \n",
    "    y_true_val = []\n",
    "    y_pred_val = []\n",
    "    \n",
    "    y_true_test = []\n",
    "    y_pred_test = []\n",
    "\n",
    "    y_true_test_M = []\n",
    "    y_pred_test_M = []\n",
    "\n",
    "    y_true_test_D = []\n",
    "    y_pred_test_D = []\n",
    "\n",
    "    y_true_test_H = []\n",
    "    y_pred_test_H = []\n",
    "    \n",
    "    for x_batch, onehot, y_batch in train_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_train.append(y_batch)\n",
    "        y_pred_train.append(preds.cpu())\n",
    "    \n",
    "    for x_batch, onehot, y_batch in val_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_val.append(y_batch)\n",
    "        y_pred_val.append(preds.cpu())\n",
    "    \n",
    "    for x_batch, onehot, y_batch in test_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_test.append(y_batch)\n",
    "        y_pred_test.append(preds.cpu())\n",
    "    \n",
    "        onehot_np = onehot.cpu().numpy()\n",
    "        y_true_np = y_batch.cpu().numpy()\n",
    "        y_pred_np = preds.cpu().numpy()\n",
    "    \n",
    "        for i in range(len(onehot_np)):\n",
    "            if np.array_equal(onehot_np[i], [1, 0, 0]):  # 'M'\n",
    "                y_true_test_M.append(y_true_np[i])\n",
    "                y_pred_test_M.append(y_pred_np[i])\n",
    "            elif np.array_equal(onehot_np[i], [0, 1, 0]):  # 'D'\n",
    "                y_true_test_D.append(y_true_np[i])\n",
    "                y_pred_test_D.append(y_pred_np[i])\n",
    "            elif np.array_equal(onehot_np[i], [0, 0, 1]):  # 'H'\n",
    "                y_true_test_H.append(y_true_np[i])\n",
    "                y_pred_test_H.append(y_pred_np[i])\n",
    "    \n",
    "    y_true_train = torch.cat(y_true_train).numpy()\n",
    "    y_pred_train = torch.cat(y_pred_train).numpy()\n",
    "    \n",
    "    y_true_val = torch.cat(y_true_val).numpy()\n",
    "    y_pred_val = torch.cat(y_pred_val).numpy()\n",
    "    \n",
    "    y_true_test = torch.cat(y_true_test).numpy()\n",
    "    y_pred_test = torch.cat(y_pred_test).numpy()\n",
    "\n",
    "    y_true_test_M = np.array(y_true_test_M)\n",
    "    y_pred_test_M = np.array(y_pred_test_M)\n",
    "    \n",
    "    y_true_test_D = np.array(y_true_test_D)\n",
    "    y_pred_test_D = np.array(y_pred_test_D)\n",
    "    \n",
    "    y_true_test_H = np.array(y_true_test_H)\n",
    "    y_pred_test_H = np.array(y_pred_test_H)\n",
    "    \n",
    "    mape_M = mean_absolute_percentage_error(y_true_test_M, y_pred_test_M) * 100 if len(y_true_test_M) > 0 else np.nan\n",
    "    mape_D = mean_absolute_percentage_error(y_true_test_D, y_pred_test_D) * 100 if len(y_true_test_D) > 0 else np.nan\n",
    "    mape_H = mean_absolute_percentage_error(y_true_test_H, y_pred_test_H) * 100 if len(y_true_test_H) > 0 else np.nan\n",
    "    \n",
    "    train_mape = mean_absolute_percentage_error(y_true_train, y_pred_train) * 100\n",
    "    val_mape = mean_absolute_percentage_error(y_true_val, y_pred_val) * 100\n",
    "    test_mape = mean_absolute_percentage_error(y_true_test, y_pred_test) * 100\n",
    "    print(f\"Rs: {rs}, hid: {hid}, {nl} layers, lr: {lr}\\n Train MAPE: {train_mape:.2f}%, Val MAPE: {val_mape:.2f}%, Test MAPE: {test_mape:.2f}%\")\n",
    "    print(f\"Test MAPE by 'Next': M: {mape_M:.2f}%, D: {mape_D:.2f}%, H: {mape_H:.2f}%\")\n",
    "    if plot == True:\n",
    "        _ = plt.figure()\n",
    "        _ = plt.scatter(y_true_train, y_pred_train, label = 'Train')\n",
    "        _ = plt.scatter(y_true_val, y_pred_val, label = 'Val')\n",
    "        _ = plt.scatter(y_true_test, y_pred_test, label = 'Test')\n",
    "        min_val = min(y_true_train.min(), y_true_test.min())\n",
    "        max_val = max(y_true_train.max(), y_true_test.max())\n",
    "        _ = plt.plot([min_val, max_val], [min_val, max_val], 'k--', label='Ideal line')\n",
    "        _ = plt.xlabel('True SOH')\n",
    "        _ = plt.ylabel('Predicted SOH')\n",
    "        _ = plt.legend()\n",
    "        _ = plt.title(f'Random state: {rs}, hid: {hid}, {nl} layer, lr: {lr}')\n",
    "    return train_mape, val_mape, test_mape, mape_M, mape_D, mape_H\n",
    "\n",
    "def plot_loss(info, train_loss, val_loss, test_loss):\n",
    "    rs, hid, nl, lr = info\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(train_loss, label = 'Train loss')\n",
    "    _ = plt.plot(val_loss, label = 'Val loss')\n",
    "    _ = plt.plot(test_loss, label = 'Test loss')\n",
    "    _ = plt.ylim([0, 2])\n",
    "    _ = plt.xlabel('Epoch')\n",
    "    _ = plt.ylabel('Loss')\n",
    "    _ = plt.legend()\n",
    "    _ = plt.title(f'Random state: {rs}, hid: {hid}, {nl} layers, lr: {lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c6ff2bf-41cc-4b6a-9773-02ee2dbbf98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 279\n",
      "Rs: 100, hid: 8, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.74%, Val MAPE: 0.78%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 0.98%, D: nan%, H: 1.07%\n",
      "Rs: 100, hid: 8, 2 layers, lr: 0.0001\n",
      " Train MAPE: 1.00%, Val MAPE: 1.22%, Test MAPE: 1.48%\n",
      "Test MAPE by 'Next': M: 1.01%, D: nan%, H: 1.95%\n",
      "Early stopping at epoch 189\n",
      "Rs: 100, hid: 8, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.80%, Val MAPE: 0.84%, Test MAPE: 0.89%\n",
      "Test MAPE by 'Next': M: 0.96%, D: nan%, H: 0.81%\n",
      "Rs: 100, hid: 8, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.87%, Val MAPE: 0.88%, Test MAPE: 1.00%\n",
      "Test MAPE by 'Next': M: 1.01%, D: nan%, H: 0.99%\n",
      "Early stopping at epoch 251\n",
      "Rs: 100, hid: 8, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.93%, Val MAPE: 0.98%, Test MAPE: 0.82%\n",
      "Test MAPE by 'Next': M: 0.90%, D: nan%, H: 0.73%\n",
      "Rs: 100, hid: 8, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.83%, Val MAPE: 0.84%, Test MAPE: 0.98%\n",
      "Test MAPE by 'Next': M: 0.95%, D: nan%, H: 1.00%\n",
      "Early stopping at epoch 282\n",
      "Rs: 100, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.90%, Val MAPE: 0.99%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 1.04%, D: nan%, H: 1.18%\n",
      "Rs: 100, hid: 8, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.97%, Val MAPE: 0.93%, Test MAPE: 1.31%\n",
      "Test MAPE by 'Next': M: 1.12%, D: nan%, H: 1.49%\n",
      "Early stopping at epoch 138\n",
      "Rs: 100, hid: 8, 6 layers, lr: 0.001\n",
      " Train MAPE: 1.91%, Val MAPE: 1.79%, Test MAPE: 1.84%\n",
      "Test MAPE by 'Next': M: 1.95%, D: nan%, H: 1.73%\n",
      "Rs: 100, hid: 8, 6 layers, lr: 0.0001\n",
      " Train MAPE: 2.25%, Val MAPE: 2.22%, Test MAPE: 2.28%\n",
      "Test MAPE by 'Next': M: 2.49%, D: nan%, H: 2.07%\n",
      "Early stopping at epoch 222\n",
      "Rs: 100, hid: 16, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.77%, Val MAPE: 1.03%, Test MAPE: 1.07%\n",
      "Test MAPE by 'Next': M: 1.21%, D: nan%, H: 0.93%\n",
      "Early stopping at epoch 907\n",
      "Rs: 100, hid: 16, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.82%, Val MAPE: 1.22%, Test MAPE: 1.22%\n",
      "Test MAPE by 'Next': M: 1.25%, D: nan%, H: 1.19%\n",
      "Early stopping at epoch 179\n",
      "Rs: 100, hid: 16, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.67%, Val MAPE: 0.81%, Test MAPE: 0.91%\n",
      "Test MAPE by 'Next': M: 0.88%, D: nan%, H: 0.94%\n",
      "Early stopping at epoch 648\n",
      "Rs: 100, hid: 16, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.69%, Val MAPE: 0.93%, Test MAPE: 1.17%\n",
      "Test MAPE by 'Next': M: 0.99%, D: nan%, H: 1.34%\n",
      "Early stopping at epoch 417\n",
      "Rs: 100, hid: 16, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.63%, Val MAPE: 0.90%, Test MAPE: 1.21%\n",
      "Test MAPE by 'Next': M: 1.16%, D: nan%, H: 1.27%\n",
      "Early stopping at epoch 420\n",
      "Rs: 100, hid: 16, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.85%, Val MAPE: 1.16%, Test MAPE: 1.28%\n",
      "Test MAPE by 'Next': M: 1.11%, D: nan%, H: 1.45%\n",
      "Early stopping at epoch 80\n",
      "Rs: 100, hid: 16, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.71%, Val MAPE: 0.73%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: 0.99%, D: nan%, H: 0.89%\n",
      "Early stopping at epoch 497\n",
      "Rs: 100, hid: 16, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.73%, Val MAPE: 0.91%, Test MAPE: 0.96%\n",
      "Test MAPE by 'Next': M: 0.93%, D: nan%, H: 0.99%\n",
      "Early stopping at epoch 154\n",
      "Rs: 100, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.65%, Val MAPE: 0.71%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 1.12%, D: nan%, H: 0.93%\n",
      "Early stopping at epoch 451\n",
      "Rs: 100, hid: 16, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.81%, Val MAPE: 0.98%, Test MAPE: 1.23%\n",
      "Test MAPE by 'Next': M: 1.03%, D: nan%, H: 1.43%\n",
      "Early stopping at epoch 217\n",
      "Rs: 100, hid: 32, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.53%, Val MAPE: 0.82%, Test MAPE: 1.27%\n",
      "Test MAPE by 'Next': M: 1.55%, D: nan%, H: 1.00%\n",
      "Early stopping at epoch 375\n",
      "Rs: 100, hid: 32, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.81%, Val MAPE: 1.38%, Test MAPE: 1.59%\n",
      "Test MAPE by 'Next': M: 1.47%, D: nan%, H: 1.71%\n",
      "Early stopping at epoch 229\n",
      "Rs: 100, hid: 32, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.51%, Val MAPE: 0.95%, Test MAPE: 1.64%\n",
      "Test MAPE by 'Next': M: 1.52%, D: nan%, H: 1.77%\n",
      "Early stopping at epoch 578\n",
      "Rs: 100, hid: 32, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.71%, Val MAPE: 1.48%, Test MAPE: 1.80%\n",
      "Test MAPE by 'Next': M: 1.55%, D: nan%, H: 2.05%\n",
      "Early stopping at epoch 152\n",
      "Rs: 100, hid: 32, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.66%, Val MAPE: 0.69%, Test MAPE: 1.33%\n",
      "Test MAPE by 'Next': M: 1.36%, D: nan%, H: 1.31%\n",
      "Early stopping at epoch 402\n",
      "Rs: 100, hid: 32, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.58%, Val MAPE: 1.06%, Test MAPE: 1.24%\n",
      "Test MAPE by 'Next': M: 1.15%, D: nan%, H: 1.33%\n",
      "Early stopping at epoch 191\n",
      "Rs: 100, hid: 32, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.81%, Val MAPE: 0.79%, Test MAPE: 1.29%\n",
      "Test MAPE by 'Next': M: 1.32%, D: nan%, H: 1.27%\n",
      "Early stopping at epoch 565\n",
      "Rs: 100, hid: 32, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.50%, Val MAPE: 0.93%, Test MAPE: 1.15%\n",
      "Test MAPE by 'Next': M: 1.18%, D: nan%, H: 1.12%\n",
      "Early stopping at epoch 126\n",
      "Rs: 100, hid: 32, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.96%, Val MAPE: 1.08%, Test MAPE: 1.37%\n",
      "Test MAPE by 'Next': M: 1.32%, D: nan%, H: 1.42%\n",
      "Early stopping at epoch 439\n",
      "Rs: 100, hid: 32, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.67%, Val MAPE: 0.90%, Test MAPE: 1.14%\n",
      "Test MAPE by 'Next': M: 1.07%, D: nan%, H: 1.21%\n",
      "Early stopping at epoch 206\n",
      "Rs: 120, hid: 8, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.76%, Val MAPE: 0.84%, Test MAPE: 0.83%\n",
      "Test MAPE by 'Next': M: 1.05%, D: nan%, H: 0.61%\n",
      "Rs: 120, hid: 8, 2 layers, lr: 0.0001\n",
      " Train MAPE: 1.14%, Val MAPE: 1.50%, Test MAPE: 1.30%\n",
      "Test MAPE by 'Next': M: 1.35%, D: nan%, H: 1.24%\n",
      "Early stopping at epoch 160\n",
      "Rs: 120, hid: 8, 3 layers, lr: 0.001\n",
      " Train MAPE: 1.12%, Val MAPE: 1.30%, Test MAPE: 0.89%\n",
      "Test MAPE by 'Next': M: 1.04%, D: nan%, H: 0.74%\n",
      "Early stopping at epoch 638\n",
      "Rs: 120, hid: 8, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.96%, Val MAPE: 0.97%, Test MAPE: 0.69%\n",
      "Test MAPE by 'Next': M: 0.73%, D: nan%, H: 0.65%\n",
      "Early stopping at epoch 221\n",
      "Rs: 120, hid: 8, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.80%, Val MAPE: 0.85%, Test MAPE: 0.75%\n",
      "Test MAPE by 'Next': M: 0.88%, D: nan%, H: 0.61%\n",
      "Early stopping at epoch 885\n",
      "Rs: 120, hid: 8, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.88%, Val MAPE: 0.97%, Test MAPE: 0.84%\n",
      "Test MAPE by 'Next': M: 0.97%, D: nan%, H: 0.72%\n",
      "Early stopping at epoch 124\n",
      "Rs: 120, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.83%, Val MAPE: 0.90%, Test MAPE: 0.80%\n",
      "Test MAPE by 'Next': M: 0.99%, D: nan%, H: 0.61%\n",
      "Early stopping at epoch 536\n",
      "Rs: 120, hid: 8, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.90%, Val MAPE: 1.16%, Test MAPE: 0.73%\n",
      "Test MAPE by 'Next': M: 0.83%, D: nan%, H: 0.63%\n",
      "Early stopping at epoch 199\n",
      "Rs: 120, hid: 8, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.89%, Val MAPE: 0.89%, Test MAPE: 0.88%\n",
      "Test MAPE by 'Next': M: 0.99%, D: nan%, H: 0.78%\n",
      "Early stopping at epoch 685\n",
      "Rs: 120, hid: 8, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.93%, Val MAPE: 1.01%, Test MAPE: 0.75%\n",
      "Test MAPE by 'Next': M: 0.83%, D: nan%, H: 0.66%\n",
      "Early stopping at epoch 317\n",
      "Rs: 120, hid: 16, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.79%, Val MAPE: 0.99%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: 1.31%, D: nan%, H: 0.85%\n",
      "Rs: 120, hid: 16, 2 layers, lr: 0.0001\n",
      " Train MAPE: 1.03%, Val MAPE: 1.24%, Test MAPE: 1.33%\n",
      "Test MAPE by 'Next': M: 1.32%, D: nan%, H: 1.34%\n",
      "Early stopping at epoch 302\n",
      "Rs: 120, hid: 16, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.71%, Val MAPE: 1.13%, Test MAPE: 0.91%\n",
      "Test MAPE by 'Next': M: 0.82%, D: nan%, H: 1.00%\n",
      "Early stopping at epoch 683\n",
      "Rs: 120, hid: 16, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.83%, Val MAPE: 1.02%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: 0.90%, D: nan%, H: 1.00%\n",
      "Early stopping at epoch 194\n",
      "Rs: 120, hid: 16, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.80%, Val MAPE: 1.10%, Test MAPE: 0.98%\n",
      "Test MAPE by 'Next': M: 1.05%, D: nan%, H: 0.90%\n",
      "Early stopping at epoch 549\n",
      "Rs: 120, hid: 16, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.84%, Val MAPE: 1.16%, Test MAPE: 0.99%\n",
      "Test MAPE by 'Next': M: 0.96%, D: nan%, H: 1.02%\n",
      "Early stopping at epoch 203\n",
      "Rs: 120, hid: 16, 5 layers, lr: 0.001\n",
      " Train MAPE: 1.14%, Val MAPE: 1.20%, Test MAPE: 1.22%\n",
      "Test MAPE by 'Next': M: 1.27%, D: nan%, H: 1.16%\n",
      "Early stopping at epoch 503\n",
      "Rs: 120, hid: 16, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.82%, Val MAPE: 1.20%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 1.10%, D: nan%, H: 0.97%\n",
      "Early stopping at epoch 74\n",
      "Rs: 120, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.86%, Val MAPE: 1.02%, Test MAPE: 0.90%\n",
      "Test MAPE by 'Next': M: 1.08%, D: nan%, H: 0.73%\n",
      "Early stopping at epoch 317\n",
      "Rs: 120, hid: 16, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.83%, Val MAPE: 1.03%, Test MAPE: 0.91%\n",
      "Test MAPE by 'Next': M: 1.05%, D: nan%, H: 0.78%\n",
      "Early stopping at epoch 169\n",
      "Rs: 120, hid: 32, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.79%, Val MAPE: 1.01%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: 0.91%, D: nan%, H: 1.12%\n",
      "Early stopping at epoch 643\n",
      "Rs: 120, hid: 32, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.69%, Val MAPE: 1.15%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: 1.08%, D: nan%, H: 0.95%\n",
      "Early stopping at epoch 181\n",
      "Rs: 120, hid: 32, 3 layers, lr: 0.001\n",
      " Train MAPE: 1.63%, Val MAPE: 1.83%, Test MAPE: 1.81%\n",
      "Test MAPE by 'Next': M: 1.32%, D: nan%, H: 2.29%\n",
      "Early stopping at epoch 311\n",
      "Rs: 120, hid: 32, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.73%, Val MAPE: 1.09%, Test MAPE: 1.09%\n",
      "Test MAPE by 'Next': M: 1.28%, D: nan%, H: 0.89%\n",
      "Early stopping at epoch 106\n",
      "Rs: 120, hid: 32, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.77%, Val MAPE: 0.98%, Test MAPE: 0.84%\n",
      "Test MAPE by 'Next': M: 0.93%, D: nan%, H: 0.75%\n",
      "Early stopping at epoch 250\n",
      "Rs: 120, hid: 32, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.58%, Val MAPE: 1.05%, Test MAPE: 0.86%\n",
      "Test MAPE by 'Next': M: 0.92%, D: nan%, H: 0.81%\n",
      "Early stopping at epoch 150\n",
      "Rs: 120, hid: 32, 5 layers, lr: 0.001\n",
      " Train MAPE: 1.18%, Val MAPE: 1.59%, Test MAPE: 1.29%\n",
      "Test MAPE by 'Next': M: 1.20%, D: nan%, H: 1.38%\n",
      "Early stopping at epoch 520\n",
      "Rs: 120, hid: 32, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.67%, Val MAPE: 1.04%, Test MAPE: 0.78%\n",
      "Test MAPE by 'Next': M: 0.89%, D: nan%, H: 0.68%\n",
      "Early stopping at epoch 97\n",
      "Rs: 120, hid: 32, 6 layers, lr: 0.001\n",
      " Train MAPE: 1.03%, Val MAPE: 1.11%, Test MAPE: 1.10%\n",
      "Test MAPE by 'Next': M: 1.05%, D: nan%, H: 1.15%\n",
      "Early stopping at epoch 235\n",
      "Rs: 120, hid: 32, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.63%, Val MAPE: 0.94%, Test MAPE: 0.85%\n",
      "Test MAPE by 'Next': M: 0.94%, D: nan%, H: 0.76%\n",
      "Early stopping at epoch 373\n",
      "Rs: 140, hid: 8, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.73%, Val MAPE: 1.08%, Test MAPE: 0.92%\n",
      "Test MAPE by 'Next': M: 1.06%, D: nan%, H: 0.78%\n",
      "Rs: 140, hid: 8, 2 layers, lr: 0.0001\n",
      " Train MAPE: 1.02%, Val MAPE: 1.36%, Test MAPE: 1.28%\n",
      "Test MAPE by 'Next': M: 1.55%, D: nan%, H: 1.01%\n",
      "Early stopping at epoch 348\n",
      "Rs: 140, hid: 8, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.91%, Val MAPE: 1.23%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 0.99%, D: nan%, H: 1.06%\n",
      "Rs: 140, hid: 8, 3 layers, lr: 0.0001\n",
      " Train MAPE: 1.44%, Val MAPE: 1.56%, Test MAPE: 1.55%\n",
      "Test MAPE by 'Next': M: 1.74%, D: nan%, H: 1.36%\n",
      "Early stopping at epoch 348\n",
      "Rs: 140, hid: 8, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.85%, Val MAPE: 1.12%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.08%, D: nan%, H: 1.03%\n",
      "Early stopping at epoch 738\n",
      "Rs: 140, hid: 8, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.87%, Val MAPE: 1.35%, Test MAPE: 1.13%\n",
      "Test MAPE by 'Next': M: 1.24%, D: nan%, H: 1.01%\n",
      "Early stopping at epoch 194\n",
      "Rs: 140, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.97%, Val MAPE: 1.15%, Test MAPE: 1.07%\n",
      "Test MAPE by 'Next': M: 1.23%, D: nan%, H: 0.90%\n",
      "Rs: 140, hid: 8, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.82%, Val MAPE: 1.19%, Test MAPE: 0.91%\n",
      "Test MAPE by 'Next': M: 1.04%, D: nan%, H: 0.78%\n",
      "Early stopping at epoch 250\n",
      "Rs: 140, hid: 8, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.91%, Val MAPE: 1.22%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: 1.11%, D: nan%, H: 0.92%\n",
      "Early stopping at epoch 746\n",
      "Rs: 140, hid: 8, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.78%, Val MAPE: 0.96%, Test MAPE: 0.84%\n",
      "Test MAPE by 'Next': M: 0.92%, D: nan%, H: 0.76%\n",
      "Early stopping at epoch 464\n",
      "Rs: 140, hid: 16, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.64%, Val MAPE: 0.95%, Test MAPE: 0.90%\n",
      "Test MAPE by 'Next': M: 1.05%, D: nan%, H: 0.75%\n",
      "Rs: 140, hid: 16, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.93%, Val MAPE: 1.39%, Test MAPE: 1.18%\n",
      "Test MAPE by 'Next': M: 1.52%, D: nan%, H: 0.84%\n",
      "Early stopping at epoch 153\n",
      "Rs: 140, hid: 16, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.67%, Val MAPE: 1.27%, Test MAPE: 0.91%\n",
      "Test MAPE by 'Next': M: 1.12%, D: nan%, H: 0.70%\n",
      "Rs: 140, hid: 16, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.62%, Val MAPE: 1.32%, Test MAPE: 1.00%\n",
      "Test MAPE by 'Next': M: 1.18%, D: nan%, H: 0.83%\n",
      "Early stopping at epoch 300\n",
      "Rs: 140, hid: 16, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.87%, Val MAPE: 1.40%, Test MAPE: 1.07%\n",
      "Test MAPE by 'Next': M: 1.16%, D: nan%, H: 0.98%\n",
      "Early stopping at epoch 591\n",
      "Rs: 140, hid: 16, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.83%, Val MAPE: 1.21%, Test MAPE: 1.14%\n",
      "Test MAPE by 'Next': M: 1.25%, D: nan%, H: 1.03%\n",
      "Early stopping at epoch 191\n",
      "Rs: 140, hid: 16, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.62%, Val MAPE: 1.10%, Test MAPE: 0.82%\n",
      "Test MAPE by 'Next': M: 0.98%, D: nan%, H: 0.65%\n",
      "Early stopping at epoch 432\n",
      "Rs: 140, hid: 16, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.72%, Val MAPE: 1.19%, Test MAPE: 0.86%\n",
      "Test MAPE by 'Next': M: 1.07%, D: nan%, H: 0.65%\n",
      "Early stopping at epoch 247\n",
      "Rs: 140, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.75%, Val MAPE: 0.98%, Test MAPE: 0.88%\n",
      "Test MAPE by 'Next': M: 0.99%, D: nan%, H: 0.78%\n",
      "Early stopping at epoch 834\n",
      "Rs: 140, hid: 16, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.69%, Val MAPE: 1.20%, Test MAPE: 0.84%\n",
      "Test MAPE by 'Next': M: 1.01%, D: nan%, H: 0.67%\n",
      "Early stopping at epoch 108\n",
      "Rs: 140, hid: 32, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.66%, Val MAPE: 1.08%, Test MAPE: 1.37%\n",
      "Test MAPE by 'Next': M: 1.61%, D: nan%, H: 1.13%\n",
      "Early stopping at epoch 575\n",
      "Rs: 140, hid: 32, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.42%, Val MAPE: 1.43%, Test MAPE: 1.20%\n",
      "Test MAPE by 'Next': M: 1.52%, D: nan%, H: 0.87%\n",
      "Early stopping at epoch 161\n",
      "Rs: 140, hid: 32, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.92%, Val MAPE: 1.39%, Test MAPE: 1.19%\n",
      "Test MAPE by 'Next': M: 1.42%, D: nan%, H: 0.97%\n",
      "Early stopping at epoch 396\n",
      "Rs: 140, hid: 32, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.53%, Val MAPE: 1.44%, Test MAPE: 1.17%\n",
      "Test MAPE by 'Next': M: 1.21%, D: nan%, H: 1.13%\n",
      "Early stopping at epoch 167\n",
      "Rs: 140, hid: 32, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.98%, Val MAPE: 1.68%, Test MAPE: 1.28%\n",
      "Test MAPE by 'Next': M: 1.26%, D: nan%, H: 1.30%\n",
      "Early stopping at epoch 297\n",
      "Rs: 140, hid: 32, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.62%, Val MAPE: 1.35%, Test MAPE: 0.99%\n",
      "Test MAPE by 'Next': M: 1.06%, D: nan%, H: 0.91%\n",
      "Early stopping at epoch 196\n",
      "Rs: 140, hid: 32, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.55%, Val MAPE: 1.20%, Test MAPE: 0.86%\n",
      "Test MAPE by 'Next': M: 0.99%, D: nan%, H: 0.73%\n",
      "Early stopping at epoch 425\n",
      "Rs: 140, hid: 32, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.58%, Val MAPE: 1.37%, Test MAPE: 0.89%\n",
      "Test MAPE by 'Next': M: 0.96%, D: nan%, H: 0.82%\n",
      "Early stopping at epoch 128\n",
      "Rs: 140, hid: 32, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.66%, Val MAPE: 1.42%, Test MAPE: 0.87%\n",
      "Test MAPE by 'Next': M: 0.95%, D: nan%, H: 0.79%\n",
      "Early stopping at epoch 314\n",
      "Rs: 140, hid: 32, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.65%, Val MAPE: 1.20%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: 1.01%, D: nan%, H: 0.86%\n",
      "Early stopping at epoch 232\n",
      "Rs: 160, hid: 8, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.85%, Val MAPE: 0.97%, Test MAPE: 0.96%\n",
      "Test MAPE by 'Next': M: 1.08%, D: nan%, H: 0.83%\n",
      "Early stopping at epoch 771\n",
      "Rs: 160, hid: 8, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.85%, Val MAPE: 0.94%, Test MAPE: 1.00%\n",
      "Test MAPE by 'Next': M: 0.93%, D: nan%, H: 1.07%\n",
      "Early stopping at epoch 165\n",
      "Rs: 160, hid: 8, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.76%, Val MAPE: 1.05%, Test MAPE: 1.10%\n",
      "Test MAPE by 'Next': M: 1.20%, D: nan%, H: 1.01%\n",
      "Early stopping at epoch 912\n",
      "Rs: 160, hid: 8, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.84%, Val MAPE: 0.92%, Test MAPE: 1.09%\n",
      "Test MAPE by 'Next': M: 1.29%, D: nan%, H: 0.90%\n",
      "Early stopping at epoch 248\n",
      "Rs: 160, hid: 8, 4 layers, lr: 0.001\n",
      " Train MAPE: 1.06%, Val MAPE: 1.12%, Test MAPE: 1.15%\n",
      "Test MAPE by 'Next': M: 1.13%, D: nan%, H: 1.18%\n",
      "Rs: 160, hid: 8, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.84%, Val MAPE: 0.92%, Test MAPE: 1.00%\n",
      "Test MAPE by 'Next': M: 1.18%, D: nan%, H: 0.82%\n",
      "Early stopping at epoch 380\n",
      "Rs: 160, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.81%, Val MAPE: 0.91%, Test MAPE: 0.97%\n",
      "Test MAPE by 'Next': M: 1.03%, D: nan%, H: 0.90%\n",
      "Rs: 160, hid: 8, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.86%, Val MAPE: 0.78%, Test MAPE: 1.12%\n",
      "Test MAPE by 'Next': M: 1.27%, D: nan%, H: 0.97%\n",
      "Early stopping at epoch 313\n",
      "Rs: 160, hid: 8, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.73%, Val MAPE: 0.85%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: 1.08%, D: nan%, H: 0.82%\n",
      "Rs: 160, hid: 8, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.86%, Val MAPE: 0.87%, Test MAPE: 1.15%\n",
      "Test MAPE by 'Next': M: 1.28%, D: nan%, H: 1.01%\n",
      "Early stopping at epoch 340\n",
      "Rs: 160, hid: 16, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.56%, Val MAPE: 1.04%, Test MAPE: 0.99%\n",
      "Test MAPE by 'Next': M: 1.20%, D: nan%, H: 0.79%\n",
      "Early stopping at epoch 619\n",
      "Rs: 160, hid: 16, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.74%, Val MAPE: 0.93%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: 1.24%, D: nan%, H: 0.92%\n",
      "Early stopping at epoch 118\n",
      "Rs: 160, hid: 16, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.63%, Val MAPE: 0.78%, Test MAPE: 1.07%\n",
      "Test MAPE by 'Next': M: 1.14%, D: nan%, H: 1.00%\n",
      "Early stopping at epoch 716\n",
      "Rs: 160, hid: 16, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.68%, Val MAPE: 0.88%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: 1.03%, D: nan%, H: 1.00%\n",
      "Early stopping at epoch 173\n",
      "Rs: 160, hid: 16, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.77%, Val MAPE: 1.11%, Test MAPE: 1.14%\n",
      "Test MAPE by 'Next': M: 1.24%, D: nan%, H: 1.04%\n",
      "Early stopping at epoch 439\n",
      "Rs: 160, hid: 16, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.81%, Val MAPE: 0.91%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 1.27%, D: nan%, H: 0.95%\n",
      "Early stopping at epoch 130\n",
      "Rs: 160, hid: 16, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.76%, Val MAPE: 0.87%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: 1.10%, D: nan%, H: 0.92%\n",
      "Early stopping at epoch 451\n",
      "Rs: 160, hid: 16, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.73%, Val MAPE: 0.72%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 1.20%, D: nan%, H: 1.02%\n",
      "Early stopping at epoch 127\n",
      "Rs: 160, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.65%, Val MAPE: 0.88%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: 1.19%, D: nan%, H: 0.90%\n",
      "Early stopping at epoch 456\n",
      "Rs: 160, hid: 16, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.79%, Val MAPE: 0.74%, Test MAPE: 1.07%\n",
      "Test MAPE by 'Next': M: 1.17%, D: nan%, H: 0.96%\n",
      "Early stopping at epoch 151\n",
      "Rs: 160, hid: 32, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.69%, Val MAPE: 1.18%, Test MAPE: 1.33%\n",
      "Test MAPE by 'Next': M: 1.64%, D: nan%, H: 1.01%\n",
      "Early stopping at epoch 695\n",
      "Rs: 160, hid: 32, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.50%, Val MAPE: 1.31%, Test MAPE: 1.41%\n",
      "Test MAPE by 'Next': M: 1.56%, D: nan%, H: 1.26%\n",
      "Early stopping at epoch 210\n",
      "Rs: 160, hid: 32, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.75%, Val MAPE: 1.37%, Test MAPE: 1.34%\n",
      "Test MAPE by 'Next': M: 1.75%, D: nan%, H: 0.92%\n",
      "Early stopping at epoch 484\n",
      "Rs: 160, hid: 32, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.55%, Val MAPE: 1.26%, Test MAPE: 1.23%\n",
      "Test MAPE by 'Next': M: 1.46%, D: nan%, H: 1.00%\n",
      "Early stopping at epoch 192\n",
      "Rs: 160, hid: 32, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.58%, Val MAPE: 1.15%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: 1.38%, D: nan%, H: 0.78%\n",
      "Early stopping at epoch 532\n",
      "Rs: 160, hid: 32, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.62%, Val MAPE: 1.23%, Test MAPE: 1.19%\n",
      "Test MAPE by 'Next': M: 1.35%, D: nan%, H: 1.03%\n",
      "Early stopping at epoch 159\n",
      "Rs: 160, hid: 32, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.58%, Val MAPE: 0.85%, Test MAPE: 1.06%\n",
      "Test MAPE by 'Next': M: 1.17%, D: nan%, H: 0.94%\n",
      "Early stopping at epoch 313\n",
      "Rs: 160, hid: 32, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.54%, Val MAPE: 1.15%, Test MAPE: 1.21%\n",
      "Test MAPE by 'Next': M: 1.47%, D: nan%, H: 0.95%\n",
      "Early stopping at epoch 130\n",
      "Rs: 160, hid: 32, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.68%, Val MAPE: 0.89%, Test MAPE: 1.00%\n",
      "Test MAPE by 'Next': M: 1.24%, D: nan%, H: 0.76%\n",
      "Early stopping at epoch 277\n",
      "Rs: 160, hid: 32, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.67%, Val MAPE: 1.15%, Test MAPE: 1.13%\n",
      "Test MAPE by 'Next': M: 1.30%, D: nan%, H: 0.96%\n",
      "Early stopping at epoch 374\n",
      "Rs: 180, hid: 8, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.79%, Val MAPE: 1.62%, Test MAPE: 1.28%\n",
      "Test MAPE by 'Next': M: 0.90%, D: nan%, H: 1.66%\n",
      "Rs: 180, hid: 8, 2 layers, lr: 0.0001\n",
      " Train MAPE: 1.04%, Val MAPE: 1.97%, Test MAPE: 1.76%\n",
      "Test MAPE by 'Next': M: 1.36%, D: nan%, H: 2.15%\n",
      "Early stopping at epoch 456\n",
      "Rs: 180, hid: 8, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.67%, Val MAPE: 0.87%, Test MAPE: 1.19%\n",
      "Test MAPE by 'Next': M: 0.99%, D: nan%, H: 1.39%\n",
      "Rs: 180, hid: 8, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.77%, Val MAPE: 1.56%, Test MAPE: 1.53%\n",
      "Test MAPE by 'Next': M: 1.08%, D: nan%, H: 1.98%\n",
      "Early stopping at epoch 191\n",
      "Rs: 180, hid: 8, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.69%, Val MAPE: 1.07%, Test MAPE: 1.15%\n",
      "Test MAPE by 'Next': M: 1.13%, D: nan%, H: 1.16%\n",
      "Rs: 180, hid: 8, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.85%, Val MAPE: 1.65%, Test MAPE: 1.15%\n",
      "Test MAPE by 'Next': M: 1.24%, D: nan%, H: 1.06%\n",
      "Early stopping at epoch 158\n",
      "Rs: 180, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.66%, Val MAPE: 0.95%, Test MAPE: 0.99%\n",
      "Test MAPE by 'Next': M: 1.07%, D: nan%, H: 0.91%\n",
      "Rs: 180, hid: 8, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.72%, Val MAPE: 0.92%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: 0.91%, D: nan%, H: 1.12%\n",
      "Early stopping at epoch 196\n",
      "Rs: 180, hid: 8, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.63%, Val MAPE: 0.84%, Test MAPE: 0.97%\n",
      "Test MAPE by 'Next': M: 1.05%, D: nan%, H: 0.90%\n",
      "Rs: 180, hid: 8, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.75%, Val MAPE: 1.04%, Test MAPE: 1.10%\n",
      "Test MAPE by 'Next': M: 0.94%, D: nan%, H: 1.27%\n",
      "Early stopping at epoch 227\n",
      "Rs: 180, hid: 16, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.68%, Val MAPE: 1.23%, Test MAPE: 1.26%\n",
      "Test MAPE by 'Next': M: 1.31%, D: nan%, H: 1.22%\n",
      "Rs: 180, hid: 16, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.86%, Val MAPE: 2.05%, Test MAPE: 1.70%\n",
      "Test MAPE by 'Next': M: 1.73%, D: nan%, H: 1.67%\n",
      "Early stopping at epoch 180\n",
      "Rs: 180, hid: 16, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.77%, Val MAPE: 1.59%, Test MAPE: 1.40%\n",
      "Test MAPE by 'Next': M: 1.17%, D: nan%, H: 1.63%\n",
      "Early stopping at epoch 976\n",
      "Rs: 180, hid: 16, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.69%, Val MAPE: 1.83%, Test MAPE: 1.26%\n",
      "Test MAPE by 'Next': M: 1.09%, D: nan%, H: 1.43%\n",
      "Early stopping at epoch 249\n",
      "Rs: 180, hid: 16, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.66%, Val MAPE: 1.35%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.09%, D: nan%, H: 1.02%\n",
      "Early stopping at epoch 842\n",
      "Rs: 180, hid: 16, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.73%, Val MAPE: 1.75%, Test MAPE: 1.40%\n",
      "Test MAPE by 'Next': M: 1.15%, D: nan%, H: 1.64%\n",
      "Early stopping at epoch 95\n",
      "Rs: 180, hid: 16, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.73%, Val MAPE: 1.55%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 1.05%, D: nan%, H: 1.17%\n",
      "Early stopping at epoch 467\n",
      "Rs: 180, hid: 16, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.79%, Val MAPE: 1.91%, Test MAPE: 1.10%\n",
      "Test MAPE by 'Next': M: 1.06%, D: nan%, H: 1.13%\n",
      "Early stopping at epoch 116\n",
      "Rs: 180, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.87%, Val MAPE: 1.68%, Test MAPE: 1.17%\n",
      "Test MAPE by 'Next': M: 1.14%, D: nan%, H: 1.20%\n",
      "Early stopping at epoch 678\n",
      "Rs: 180, hid: 16, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.70%, Val MAPE: 1.52%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 1.04%, D: nan%, H: 1.02%\n",
      "Early stopping at epoch 120\n",
      "Rs: 180, hid: 32, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.71%, Val MAPE: 1.76%, Test MAPE: 1.38%\n",
      "Test MAPE by 'Next': M: 1.12%, D: nan%, H: 1.63%\n",
      "Early stopping at epoch 427\n",
      "Rs: 180, hid: 32, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.51%, Val MAPE: 1.81%, Test MAPE: 1.52%\n",
      "Test MAPE by 'Next': M: 1.23%, D: nan%, H: 1.80%\n",
      "Early stopping at epoch 188\n",
      "Rs: 180, hid: 32, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.90%, Val MAPE: 1.72%, Test MAPE: 1.49%\n",
      "Test MAPE by 'Next': M: 1.55%, D: nan%, H: 1.43%\n",
      "Early stopping at epoch 644\n",
      "Rs: 180, hid: 32, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.43%, Val MAPE: 1.61%, Test MAPE: 1.21%\n",
      "Test MAPE by 'Next': M: 1.19%, D: nan%, H: 1.24%\n",
      "Early stopping at epoch 113\n",
      "Rs: 180, hid: 32, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.86%, Val MAPE: 1.50%, Test MAPE: 1.42%\n",
      "Test MAPE by 'Next': M: 1.47%, D: nan%, H: 1.37%\n",
      "Early stopping at epoch 418\n",
      "Rs: 180, hid: 32, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.47%, Val MAPE: 1.25%, Test MAPE: 1.10%\n",
      "Test MAPE by 'Next': M: 1.18%, D: nan%, H: 1.02%\n",
      "Early stopping at epoch 116\n",
      "Rs: 180, hid: 32, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.61%, Val MAPE: 1.13%, Test MAPE: 1.10%\n",
      "Test MAPE by 'Next': M: 1.18%, D: nan%, H: 1.01%\n",
      "Early stopping at epoch 353\n",
      "Rs: 180, hid: 32, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.52%, Val MAPE: 1.44%, Test MAPE: 1.13%\n",
      "Test MAPE by 'Next': M: 1.23%, D: nan%, H: 1.04%\n",
      "Early stopping at epoch 140\n",
      "Rs: 180, hid: 32, 6 layers, lr: 0.001\n",
      " Train MAPE: 1.48%, Val MAPE: 1.50%, Test MAPE: 1.57%\n",
      "Test MAPE by 'Next': M: 1.60%, D: nan%, H: 1.54%\n",
      "Early stopping at epoch 399\n",
      "Rs: 180, hid: 32, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.56%, Val MAPE: 1.44%, Test MAPE: 1.33%\n",
      "Test MAPE by 'Next': M: 1.20%, D: nan%, H: 1.46%\n"
     ]
    }
   ],
   "source": [
    "random_states = [100, 120, 140, 160, 180]\n",
    "bs = 12\n",
    "ep = 1000\n",
    "hids = [8, 16, 32]\n",
    "layers = [2, 3, 4, 5, 6]\n",
    "lrs = [1e-3, 1e-4]\n",
    "\n",
    "Source_Domain = ['M', 'H']\n",
    "Target_Domain = ['D']\n",
    "\n",
    "results_df = pd.DataFrame(columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE'])\n",
    "\n",
    "X, y = Get_Data(dat)\n",
    "\n",
    "X_sc, X_ta, y_sc, y_ta = Domain_Split(X, y, Target_Domain)\n",
    "\n",
    "for rs, hid, nl, lr in product(random_states, hids, layers, lrs):\n",
    "    setRandomSeed(rs)\n",
    "\n",
    "    X_tn, X_te, y_tn, y_te = Even_Split(X_sc, y_sc, Target_Domain, 1/3, rs)\n",
    "    X_tr, X_va, y_tr, y_va = Even_Split(X_tn, y_tn, Target_Domain, 1/6, rs)\n",
    "\n",
    "    next_map = {'M': 0, 'D': 1, 'H': 2}\n",
    "    get_next = lambda idx: torch.nn.functional.one_hot(torch.tensor([next_map[i] for i in idx.get_level_values(\"Next\")]), num_classes=3).float()\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "    X_tr_std = std_scaler.fit_transform(X_tr)\n",
    "    X_val_std = std_scaler.transform(X_va)\n",
    "    X_te_std = std_scaler.transform(X_te)\n",
    "    \n",
    "    X_train = torch.Tensor(X_tr_std)\n",
    "    X_val = torch.Tensor(X_val_std)\n",
    "    X_test = torch.Tensor(X_te_std)\n",
    "    \n",
    "    y_train = torch.Tensor(y_tr[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_val = torch.Tensor(y_va[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_test = torch.Tensor(y_te[\"Next_SOH\"].values).unsqueeze(1)\n",
    "\n",
    "    next_train = get_next(X_tr.index)\n",
    "    next_val = get_next(X_va.index)\n",
    "    next_test = get_next(X_te.index)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, next_train, y_train), batch_size=bs, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, next_val, y_val), batch_size=bs, shuffle = False)\n",
    "    test_loader = DataLoader(TensorDataset(X_test, next_test, y_test), batch_size=bs, shuffle = False)\n",
    "    \n",
    "    model = MLP(hidden_dim=hid, num_layers=nl)\n",
    "    trainer = Trainer(model, lr=lr, epoch = ep, random_seed = rs)\n",
    "    \n",
    "    trainer.train(train_loader, val_loader, test_loader)\n",
    "\n",
    "    info = [rs, hid, nl, lr]\n",
    "    results = plot_results(info, train_loader, val_loader, test_loader, plot = False)\n",
    "\n",
    "    temp_df = pd.DataFrame(info+list(results)).T\n",
    "    temp_df.columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']\n",
    "    results_df = pd.concat([results_df, temp_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4819d6c3-d539-4de0-9e83-ed6af617fa12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hid</th>\n",
       "      <th>nl</th>\n",
       "      <th>lr</th>\n",
       "      <th>Train MAPE</th>\n",
       "      <th>Val MAPE</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Next M MAPE</th>\n",
       "      <th>Next D MAPE</th>\n",
       "      <th>Next H MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.834748</td>\n",
       "      <td>0.979522</td>\n",
       "      <td>0.986964</td>\n",
       "      <td>1.072818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.901110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.853124</td>\n",
       "      <td>0.996687</td>\n",
       "      <td>1.017216</td>\n",
       "      <td>1.035304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.865224</td>\n",
       "      <td>1.027018</td>\n",
       "      <td>0.983186</td>\n",
       "      <td>1.025080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.941292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.687936</td>\n",
       "      <td>1.049135</td>\n",
       "      <td>1.060953</td>\n",
       "      <td>1.216367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.905539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.755743</td>\n",
       "      <td>1.054875</td>\n",
       "      <td>1.006056</td>\n",
       "      <td>1.104523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.907588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.772906</td>\n",
       "      <td>1.055658</td>\n",
       "      <td>1.002826</td>\n",
       "      <td>1.014774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.852690</td>\n",
       "      <td>1.059504</td>\n",
       "      <td>1.018639</td>\n",
       "      <td>1.035045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.002232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.791809</td>\n",
       "      <td>1.087322</td>\n",
       "      <td>1.019301</td>\n",
       "      <td>1.079714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.958888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.765546</td>\n",
       "      <td>1.094130</td>\n",
       "      <td>1.016626</td>\n",
       "      <td>1.062140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.971113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.745894</td>\n",
       "      <td>1.112470</td>\n",
       "      <td>1.119985</td>\n",
       "      <td>1.173161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.066810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.687933</td>\n",
       "      <td>1.114587</td>\n",
       "      <td>1.040083</td>\n",
       "      <td>1.026808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.053357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.016396</td>\n",
       "      <td>1.117120</td>\n",
       "      <td>1.131306</td>\n",
       "      <td>1.235096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.027515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.636648</td>\n",
       "      <td>1.128148</td>\n",
       "      <td>1.076982</td>\n",
       "      <td>1.105430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.048534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.853126</td>\n",
       "      <td>1.145045</td>\n",
       "      <td>1.020217</td>\n",
       "      <td>1.117205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.923229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.676932</td>\n",
       "      <td>1.170504</td>\n",
       "      <td>1.271277</td>\n",
       "      <td>1.364345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.178209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.746360</td>\n",
       "      <td>1.171953</td>\n",
       "      <td>1.091588</td>\n",
       "      <td>1.139729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.043447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.976444</td>\n",
       "      <td>1.180204</td>\n",
       "      <td>1.174803</td>\n",
       "      <td>1.172404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.177203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.562284</td>\n",
       "      <td>1.184138</td>\n",
       "      <td>1.034014</td>\n",
       "      <td>1.147324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.920704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.757148</td>\n",
       "      <td>1.185872</td>\n",
       "      <td>1.011474</td>\n",
       "      <td>1.071069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.951878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.575070</td>\n",
       "      <td>1.189043</td>\n",
       "      <td>1.076584</td>\n",
       "      <td>1.131777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.021392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.698806</td>\n",
       "      <td>1.194935</td>\n",
       "      <td>1.079667</td>\n",
       "      <td>1.039555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.119780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.771494</td>\n",
       "      <td>1.199423</td>\n",
       "      <td>1.191698</td>\n",
       "      <td>1.280299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.103096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.962944</td>\n",
       "      <td>1.201032</td>\n",
       "      <td>1.180516</td>\n",
       "      <td>1.229912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.131119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.114255</td>\n",
       "      <td>1.220139</td>\n",
       "      <td>1.222290</td>\n",
       "      <td>1.290331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.154248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.813969</td>\n",
       "      <td>1.237468</td>\n",
       "      <td>1.184123</td>\n",
       "      <td>1.149726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.218519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.875640</td>\n",
       "      <td>1.368590</td>\n",
       "      <td>1.301391</td>\n",
       "      <td>1.411111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.191671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.590318</td>\n",
       "      <td>1.376292</td>\n",
       "      <td>1.299879</td>\n",
       "      <td>1.338781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.260977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.010526</td>\n",
       "      <td>1.398541</td>\n",
       "      <td>1.362991</td>\n",
       "      <td>1.241064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.484917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.584601</td>\n",
       "      <td>1.417678</td>\n",
       "      <td>1.345496</td>\n",
       "      <td>1.372564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.318428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.939458</td>\n",
       "      <td>1.452654</td>\n",
       "      <td>1.493562</td>\n",
       "      <td>1.512234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.474890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     hid   nl      lr  Train MAPE  Val MAPE  Test MAPE  Next M MAPE  \\\n",
       "7    8.0  5.0  0.0010    0.834748  0.979522   0.986964     1.072818   \n",
       "6    8.0  5.0  0.0001    0.853124  0.996687   1.017216     1.035304   \n",
       "5    8.0  4.0  0.0010    0.865224  1.027018   0.983186     1.025080   \n",
       "11  16.0  2.0  0.0010    0.687936  1.049135   1.060953     1.216367   \n",
       "19  16.0  6.0  0.0010    0.755743  1.054875   1.006056     1.104523   \n",
       "1    8.0  2.0  0.0010    0.772906  1.055658   1.002826     1.014774   \n",
       "3    8.0  3.0  0.0010    0.852690  1.059504   1.018639     1.035045   \n",
       "17  16.0  5.0  0.0010    0.791809  1.087322   1.019301     1.079714   \n",
       "18  16.0  6.0  0.0001    0.765546  1.094130   1.016626     1.062140   \n",
       "27  32.0  5.0  0.0010    0.745894  1.112470   1.119985     1.173161   \n",
       "13  16.0  3.0  0.0010    0.687933  1.114587   1.040083     1.026808   \n",
       "9    8.0  6.0  0.0010    1.016396  1.117120   1.131306     1.235096   \n",
       "28  32.0  6.0  0.0001    0.636648  1.128148   1.076982     1.105430   \n",
       "4    8.0  4.0  0.0001    0.853126  1.145045   1.020217     1.117205   \n",
       "21  32.0  2.0  0.0010    0.676932  1.170504   1.271277     1.364345   \n",
       "15  16.0  4.0  0.0010    0.746360  1.171953   1.091588     1.139729   \n",
       "2    8.0  3.0  0.0001    0.976444  1.180204   1.174803     1.172404   \n",
       "26  32.0  5.0  0.0001    0.562284  1.184138   1.034014     1.147324   \n",
       "16  16.0  5.0  0.0001    0.757148  1.185872   1.011474     1.071069   \n",
       "24  32.0  4.0  0.0001    0.575070  1.189043   1.076584     1.131777   \n",
       "12  16.0  3.0  0.0001    0.698806  1.194935   1.079667     1.039555   \n",
       "25  32.0  4.0  0.0010    0.771494  1.199423   1.191698     1.280299   \n",
       "29  32.0  6.0  0.0010    0.962944  1.201032   1.180516     1.229912   \n",
       "8    8.0  6.0  0.0001    1.114255  1.220139   1.222290     1.290331   \n",
       "14  16.0  4.0  0.0001    0.813969  1.237468   1.184123     1.149726   \n",
       "10  16.0  2.0  0.0001    0.875640  1.368590   1.301391     1.411111   \n",
       "22  32.0  3.0  0.0001    0.590318  1.376292   1.299879     1.338781   \n",
       "0    8.0  2.0  0.0001    1.010526  1.398541   1.362991     1.241064   \n",
       "20  32.0  2.0  0.0001    0.584601  1.417678   1.345496     1.372564   \n",
       "23  32.0  3.0  0.0010    0.939458  1.452654   1.493562     1.512234   \n",
       "\n",
       "    Next D MAPE  Next H MAPE  \n",
       "7           NaN     0.901110  \n",
       "6           NaN     0.999128  \n",
       "5           NaN     0.941292  \n",
       "11          NaN     0.905539  \n",
       "19          NaN     0.907588  \n",
       "1           NaN     0.990878  \n",
       "3           NaN     1.002232  \n",
       "17          NaN     0.958888  \n",
       "18          NaN     0.971113  \n",
       "27          NaN     1.066810  \n",
       "13          NaN     1.053357  \n",
       "9           NaN     1.027515  \n",
       "28          NaN     1.048534  \n",
       "4           NaN     0.923229  \n",
       "21          NaN     1.178209  \n",
       "15          NaN     1.043447  \n",
       "2           NaN     1.177203  \n",
       "26          NaN     0.920704  \n",
       "16          NaN     0.951878  \n",
       "24          NaN     1.021392  \n",
       "12          NaN     1.119780  \n",
       "25          NaN     1.103096  \n",
       "29          NaN     1.131119  \n",
       "8           NaN     1.154248  \n",
       "14          NaN     1.218519  \n",
       "10          NaN     1.191671  \n",
       "22          NaN     1.260977  \n",
       "0           NaN     1.484917  \n",
       "20          NaN     1.318428  \n",
       "23          NaN     1.474890  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = results_df.groupby(['hid', 'nl', 'lr'])[['Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']].mean().reset_index()\n",
    "\n",
    "summary_df_sorted = summary_df.sort_values(by = 'Val MAPE', ascending = True)\n",
    "summary_df_sorted\n",
    "\n",
    "results_df.to_csv(f\"MLP_Domain_Source_{Source_Domain}_next_info.csv\")\n",
    "summary_df_sorted.to_csv(f\"MLP_Domain_Source_{Source_Domain}_next_info_sum.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82878289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hid    8.000\n",
       "nl     5.000\n",
       "lr     0.001\n",
       "Name: 7, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyper_parameter = summary_df_sorted.iloc[0][['hid', 'nl', 'lr']]\n",
    "best_hyper_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dbb98c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 282\n",
      "Early stopping at epoch 331\n",
      "Rs: 100, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.60%, Val MAPE: 1.07%, Test MAPE: 0.92%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.92%, H: nan%\n",
      "Rs: 100, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 1.09%, Val MAPE: 1.11%, Test MAPE: 1.43%\n",
      "Test MAPE by 'Next': M: 1.05%, D: nan%, H: 1.82%\n",
      "Early stopping at epoch 124\n",
      "Early stopping at epoch 300\n",
      "Rs: 120, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 1.50%, Val MAPE: 1.47%, Test MAPE: 1.42%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.42%, H: nan%\n",
      "Rs: 120, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.86%, Val MAPE: 0.92%, Test MAPE: 0.74%\n",
      "Test MAPE by 'Next': M: 0.92%, D: nan%, H: 0.56%\n",
      "Early stopping at epoch 194\n",
      "Early stopping at epoch 309\n",
      "Rs: 140, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.49%, Val MAPE: 1.33%, Test MAPE: 1.00%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.00%, H: nan%\n",
      "Rs: 140, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 1.06%, Val MAPE: 1.35%, Test MAPE: 1.10%\n",
      "Test MAPE by 'Next': M: 1.23%, D: nan%, H: 0.97%\n",
      "Early stopping at epoch 380\n",
      "Early stopping at epoch 919\n",
      "Rs: 160, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.67%, Val MAPE: 0.88%, Test MAPE: 0.89%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.89%, H: nan%\n",
      "Rs: 160, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 3.07%, Val MAPE: 3.17%, Test MAPE: 3.14%\n",
      "Test MAPE by 'Next': M: 2.83%, D: nan%, H: 3.44%\n",
      "Early stopping at epoch 158\n",
      "Early stopping at epoch 96\n",
      "Rs: 180, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.89%, Val MAPE: 1.13%, Test MAPE: 0.84%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.84%, H: nan%\n",
      "Rs: 180, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.66%, Val MAPE: 0.95%, Test MAPE: 0.99%\n",
      "Test MAPE by 'Next': M: 1.07%, D: nan%, H: 0.91%\n"
     ]
    }
   ],
   "source": [
    "hid = int(best_hyper_parameter['hid'])\n",
    "nl  = int(best_hyper_parameter['nl'])\n",
    "lr  = float(best_hyper_parameter['lr'])\n",
    "\n",
    "results_df_Ta = pd.DataFrame(columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE'])\n",
    "results_df_Sc = pd.DataFrame(columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE'])\n",
    "\n",
    "\n",
    "for rs in random_states:\n",
    "    setRandomSeed(rs)\n",
    "\n",
    "    X_tn, X_te, y_tn, y_te = Even_Split(X_sc, y_sc, Target_Domain, 1/3, rs)\n",
    "    X_tr, X_va, y_tr, y_va = Even_Split(X_tn, y_tn, Target_Domain, 1/6, rs)\n",
    "\n",
    "    next_map = {'M': 0, 'D': 1, 'H': 2}\n",
    "    get_next = lambda idx: torch.nn.functional.one_hot(torch.tensor([next_map[i] for i in idx.get_level_values(\"Next\")]), num_classes=3).float()\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "    X_tr_std = std_scaler.fit_transform(X_tr)\n",
    "    X_val_std = std_scaler.transform(X_va)\n",
    "    X_te_std = std_scaler.transform(X_te)\n",
    "    \n",
    "    X_train = torch.Tensor(X_tr_std)\n",
    "    X_val = torch.Tensor(X_val_std)\n",
    "    X_test = torch.Tensor(X_te_std)\n",
    "    \n",
    "    y_train = torch.Tensor(y_tr[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_val = torch.Tensor(y_va[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_test = torch.Tensor(y_te[\"Next_SOH\"].values).unsqueeze(1)\n",
    "\n",
    "    next_train = get_next(X_tr.index)\n",
    "    next_val = get_next(X_va.index)\n",
    "    next_test = get_next(X_te.index)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, next_train, y_train), batch_size=bs, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, next_val, y_val), batch_size=bs, shuffle = False)\n",
    "    test_loader = DataLoader(TensorDataset(X_test, next_test, y_test), batch_size=bs, shuffle = False)\n",
    "    \n",
    "    model = MLP(hidden_dim=hid, num_layers=nl)\n",
    "    trainer = Trainer(model, lr=lr, epoch = ep, random_seed = rs)\n",
    "    \n",
    "    trainer.train(train_loader, val_loader, test_loader)\n",
    "\n",
    "    info = [rs, hid, nl, lr]\n",
    "    #results = plot_results(info, train_loader, val_loader, test_loader, plot = False)\n",
    "\n",
    "    trained_model = trainer.model\n",
    "    \n",
    "    for p in trained_model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    first_linear = trained_model.model[0]\n",
    "\n",
    "    first_linear.weight.requires_grad = True\n",
    "    first_linear.bias.requires_grad   = True  \n",
    "\n",
    "    learn_idx = {\n",
    "        'M': -3,\n",
    "        'D': -2,\n",
    "        'H': -1\n",
    "    }\n",
    "\n",
    "    mask_w = torch.zeros_like(first_linear.weight)\n",
    "    for ta in Target_Domain:\n",
    "        mask_w[:, learn_idx[ta]] = 1.0\n",
    "\n",
    "    mask_b = torch.zeros_like(first_linear.bias)\n",
    "    for ta in Target_Domain:\n",
    "        mask_b[learn_idx[ta]] = 1.0\n",
    "\n",
    "    def grad_hook_weight(grad):\n",
    "        return grad * mask_w\n",
    "\n",
    "    def grad_hook_bias(grad):\n",
    "        return grad * mask_b\n",
    "\n",
    "    h1 = first_linear.weight.register_hook(grad_hook_weight)\n",
    "    h2 = first_linear.bias.register_hook(grad_hook_bias)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [p for p in trained_model.parameters() if p.requires_grad],\n",
    "        lr=lr,\n",
    "        weight_decay=0.0 \n",
    "    )\n",
    "    \n",
    "    X_ta_tn, X_ta_te, y_ta_tn, y_ta_te = Even_Split(X_ta, y_ta, Source_Domain, 8/9, rs)\n",
    "    X_ta_tr, X_ta_va, y_ta_tr, y_ta_va = Even_Split(X_ta_tn, y_ta_tn, Source_Domain, 1/6, rs)\n",
    "\n",
    "    X_ta_tr_std  = std_scaler.transform(X_ta_tr)\n",
    "    X_ta_val_std = std_scaler.transform(X_ta_va)\n",
    "    X_ta_te_std  = std_scaler.transform(X_ta_te)\n",
    "\n",
    "    X_ta_train = torch.Tensor(X_ta_tr_std)\n",
    "    X_ta_val   = torch.Tensor(X_ta_val_std)\n",
    "    X_ta_test  = torch.Tensor(X_ta_te_std)\n",
    "    \n",
    "    y_ta_train = torch.Tensor(y_ta_tr[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_ta_val   = torch.Tensor(y_ta_va[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_ta_test  = torch.Tensor(y_ta_te[\"Next_SOH\"].values).unsqueeze(1)\n",
    "\n",
    "    next_ta_train = get_next(X_ta_tr.index)\n",
    "    next_ta_val   = get_next(X_ta_va.index)\n",
    "    next_ta_test  = get_next(X_ta_te.index)\n",
    "\n",
    "    train_ta_loader = DataLoader(TensorDataset(X_ta_train, next_ta_train, y_ta_train), batch_size=bs, shuffle=True)\n",
    "    val_ta_loader   = DataLoader(TensorDataset(X_ta_val, next_ta_val, y_ta_val), batch_size=bs, shuffle = False)\n",
    "    test_ta_loader  = DataLoader(TensorDataset(X_ta_test, next_ta_test, y_ta_test), batch_size=bs, shuffle = False)\n",
    "\n",
    "    trainer = Trainer(trained_model, lr=lr, epoch = ep, random_seed = rs, optimizer = optimizer)\n",
    "    \n",
    "    trainer.train(train_ta_loader, val_ta_loader, test_ta_loader)\n",
    "\n",
    "    info = [rs, hid, nl, lr]\n",
    "\n",
    "    results_Ta = plot_results(info, train_ta_loader, val_ta_loader, test_ta_loader, plot = False)\n",
    "    results_Sc = plot_results(info, train_loader, val_loader, test_loader, plot = False)\n",
    "\n",
    "    temp_df_Ta = pd.DataFrame(info+list(results_Ta)).T\n",
    "    temp_df_Sc = pd.DataFrame(info+list(results_Sc)).T\n",
    "\n",
    "    temp_df_Ta.columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']\n",
    "    temp_df_Sc.columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']\n",
    "\n",
    "    results_df_Ta = pd.concat([results_df_Ta, temp_df_Ta])\n",
    "    results_df_Sc = pd.concat([results_df_Sc, temp_df_Sc])\n",
    "\n",
    "    h1.remove()\n",
    "    h2.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3531aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hid</th>\n",
       "      <th>nl</th>\n",
       "      <th>lr</th>\n",
       "      <th>Train MAPE</th>\n",
       "      <th>Val MAPE</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Next M MAPE</th>\n",
       "      <th>Next D MAPE</th>\n",
       "      <th>Next H MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.346761</td>\n",
       "      <td>1.499286</td>\n",
       "      <td>1.480272</td>\n",
       "      <td>1.41841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.542133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hid   nl     lr  Train MAPE  Val MAPE  Test MAPE  Next M MAPE  Next D MAPE  \\\n",
       "0  8.0  5.0  0.001    1.346761  1.499286   1.480272      1.41841          NaN   \n",
       "\n",
       "   Next H MAPE  \n",
       "0     1.542133  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hid</th>\n",
       "      <th>nl</th>\n",
       "      <th>lr</th>\n",
       "      <th>Train MAPE</th>\n",
       "      <th>Val MAPE</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Next M MAPE</th>\n",
       "      <th>Next D MAPE</th>\n",
       "      <th>Next H MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.829591</td>\n",
       "      <td>1.173783</td>\n",
       "      <td>1.016803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.016803</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hid   nl     lr  Train MAPE  Val MAPE  Test MAPE  Next M MAPE  Next D MAPE  \\\n",
       "0  8.0  5.0  0.001    0.829591  1.173783   1.016803          NaN     1.016803   \n",
       "\n",
       "   Next H MAPE  \n",
       "0          NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df_Ta = results_df_Ta.groupby(['hid', 'nl', 'lr'])[['Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']].mean().reset_index()\n",
    "summary_df_Sc = results_df_Sc.groupby(['hid', 'nl', 'lr'])[['Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']].mean().reset_index()\n",
    "\n",
    "summary_df_Sc\n",
    "summary_df_Ta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
