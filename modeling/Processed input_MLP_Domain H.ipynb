{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f777b66-b5ce-4b51-a260-0f95e8c9dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from numpy import hstack, vstack\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c268bd1-67cb-4cfb-842e-0bd9f4e75302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dkstj\\\\Desktop\\\\연구\\\\현대차 3차\\\\Rapid_fin\\\\deep learning modeling'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_directory(foldername, filename = None, back_num = 0):\n",
    "    cur = os.getcwd()\n",
    "    for i in range(back_num):\n",
    "        cur = os.path.abspath(os.path.join(cur, os.pardir))\n",
    "    for folder in foldername:\n",
    "        cur = os.path.join(cur, folder)\n",
    "    if not os.path.exists(cur):\n",
    "        os.makedirs(cur)\n",
    "        print(f'{cur} created')\n",
    "    if filename != None:\n",
    "        cur = os.path.join(cur, filename)\n",
    "    return cur\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e19cef-7f59-4f9c-a102-bce664fb00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_add = find_directory(foldername = [], filename = 'SOC_Point_Data.csv')\n",
    "dat = pd.read_csv(csv_add, index_col = (0,1,2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51190277-29e5-4a99-bb89-b99b751c7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Data(dat) :\n",
    "    \n",
    "    RPT_MODE = \"0.1C\"\n",
    "    SOC_Range = [9,10,11,12]\n",
    "\n",
    "    Time_Range = range(6, 15, 2)\n",
    "    SOC_Range = [str(i) for i in SOC_Range]\n",
    "    \n",
    "\n",
    "    Data = dat\n",
    "\n",
    "    X = Data.loc[RPT_MODE, \"0\" : \"16\"]\n",
    "    Y = Data.loc[RPT_MODE, [\"SOH\", \"Next_SOH\", \"Ratio_SOH\", \"Ratio_CYC\"]].groupby(level = [\"Next\", \"Path\", \"Number\"]).mean()\n",
    "    \n",
    "    y = pd.Series(Y[\"Next_SOH\"] - Y[\"SOH\"], name = \"Delta_SOH\")\n",
    "    \n",
    "    Y = pd.concat([Y, y], axis = 1)\n",
    "\n",
    "    X_seek = X.loc[X.index.get_level_values(\"Time\").isin(Time_Range), SOC_Range]\n",
    "\n",
    "\n",
    "    X_std = X_seek.groupby(level = [\"Next\", \"Path\", \"Number\"]).std()\n",
    "    \n",
    "    return X_std, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19cdfd1a-dfb7-4066-ab61-9ef975b8d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Even_Split(X, y, no_next, test_size, rs) :\n",
    "\n",
    "    Nexts = [n for n in ['M', 'D', 'H'] if n not in no_next]\n",
    "\n",
    "    XX = {n: X.xs(key = n, level = 'Next', drop_level = False) for n in Nexts}\n",
    "    yy = {n: y.xs(key = n, level = 'Next', drop_level = False) for n in Nexts}\n",
    "    \n",
    "    \n",
    "    XXX = {n: [] for n in Nexts}\n",
    "    yyy = {n: [] for n in Nexts}\n",
    "    \n",
    "    \n",
    "    for n in Nexts:\n",
    "        for path in range(1,5) :\n",
    "            X_path = XX[n].loc[XX[n].index.get_level_values(level = 'Path').str.len() == path]\n",
    "            y_path = yy[n].loc[yy[n].index.get_level_values(level = 'Path').str.len() == path]\n",
    "            \n",
    "            XXX[n].append(X_path)\n",
    "            yyy[n].append(y_path)\n",
    "            \n",
    "            \n",
    "    XX_tn = {n: [] for n in Nexts}\n",
    "    XX_te = {n: [] for n in Nexts}\n",
    "    \n",
    "    yy_tn = {n: [] for n in Nexts}\n",
    "    yy_te = {n: [] for n in Nexts}\n",
    "        \n",
    "    for n in Nexts :\n",
    "        for path in range(1,5) :\n",
    "            X_temp = XXX[n][path-1]\n",
    "            y_temp = yyy[n][path-1]\n",
    "            \n",
    "            X_tn, X_te, y_tn, y_te = train_test_split(X_temp, y_temp, test_size = test_size, random_state = rs)\n",
    "            \n",
    "            XX_tn[n].append(X_tn)\n",
    "            XX_te[n].append(X_te)\n",
    "            yy_tn[n].append(y_tn)\n",
    "            yy_te[n].append(y_te)\n",
    "                  \n",
    "    for n in Nexts :\n",
    "        XX_tn[n] = pd.concat(XX_tn[n])\n",
    "        XX_te[n] = pd.concat(XX_te[n])\n",
    "        yy_tn[n] = pd.concat(yy_tn[n])\n",
    "        yy_te[n] = pd.concat(yy_te[n])\n",
    "        \n",
    "        \n",
    "    X_tn = pd.concat(XX_tn.values())\n",
    "    X_te = pd.concat(XX_te.values())\n",
    "    \n",
    "    y_tn = pd.concat(yy_tn.values())\n",
    "    y_te = pd.concat(yy_te.values())\n",
    "    \n",
    "    return X_tn, X_te, y_tn, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982efbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Domain_Split(X, y, test_domain):\n",
    "    X_M = X.xs(key = 'M', level = 'Next', drop_level = False)\n",
    "    X_D = X.xs(key = 'D', level = 'Next', drop_level = False)\n",
    "    X_H = X.xs(key = 'H', level = 'Next', drop_level = False)\n",
    "    \n",
    "    XX = {\"M\" : X_M, \"D\" : X_D, \"H\" : X_H}\n",
    "    \n",
    "    y_M = y.xs(key = 'M', level = 'Next', drop_level = False)\n",
    "    y_D = y.xs(key = 'D', level = 'Next', drop_level = False)\n",
    "    y_H = y.xs(key = 'H', level = 'Next', drop_level = False)\n",
    "    \n",
    "    yy = {\"M\" : y_M, \"D\" : y_D, \"H\" : y_H}\n",
    "    \n",
    "    \n",
    "    X_tn = pd.concat([XX[n] for n in ['M', 'D', 'H'] if n not in test_domain])\n",
    "    X_te = pd.concat([XX[n] for n in ['M', 'D', 'H'] if n in test_domain])\n",
    "\n",
    "    y_tn = pd.concat([yy[n] for n in ['M', 'D', 'H'] if n not in test_domain])\n",
    "    y_te = pd.concat([yy[n] for n in ['M', 'D', 'H'] if n in test_domain])\n",
    "    \n",
    "    return X_tn, X_te, y_tn, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f240b499-f460-4d4d-a641-1427605d59ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_tensor(index_list):\n",
    "    next_mapping = {'M': 0, 'D': 1, 'H': 2}\n",
    "    next_index = [next_mapping[idx[0]] for idx in index_list] \n",
    "    next_tensor = torch.tensor(next_index)\n",
    "    one_hot = torch.nn.functional.one_hot(next_tensor, num_classes=3).float()\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f614def-b4a4-481d-835c-7798c2ac0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setRandomSeed(random_seed=0):\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ab81703-2c07-484c-910f-12d4e46abdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, num_layers=2, next_dim = 3):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        input_dim = 4 + next_dim\n",
    "        output_dim = 1\n",
    "\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, onehot):\n",
    "        x_concat = torch.cat([x, onehot], dim=1)\n",
    "        return self.model(x_concat)\n",
    "\n",
    "class MAPELoss(nn.Module):\n",
    "    def __init__(self, epsilon=1e-7):\n",
    "        super(MAPELoss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.mean(torch.abs((y_true - y_pred) / (y_true + self.epsilon))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a7a5600-ca48-42b9-a7d4-91ae59a8b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, lr=1e-3, weight_decay=0, epoch=1000, patience=50, random_seed = 0, optimizer = None):\n",
    "        self.random_seed = random_seed\n",
    "        #setRandomSeed(self.random_seed)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.cri2 = MAPELoss()\n",
    "        if optimizer is None:\n",
    "            self.optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        else:\n",
    "            self.optimizer = optimizer\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=200, gamma=0.8)\n",
    "        self.epoch = epoch\n",
    "        self.patience = patience\n",
    "\n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def train(self, train_loader, test_loader=None, val_loader=None):\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_state = None\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        for ep in range(1, self.epoch + 1):\n",
    "            self.model.train()\n",
    "            for x_batch, onehot, y_batch in train_loader:\n",
    "                x_batch, onehot, y_batch = x_batch.to(self.device), onehot.to(self.device), y_batch.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(x_batch, onehot)\n",
    "                loss = self.cri2(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            self.scheduler.step()\n",
    "\n",
    "            avg_train_loss = self.evaluate(train_loader)\n",
    "            test_loss = self.evaluate(test_loader) if test_loader else None\n",
    "            val_loss = self.evaluate(val_loader) if val_loader else None\n",
    "\n",
    "            self.train_loss.append(avg_train_loss)\n",
    "            self.test_loss.append(test_loss)\n",
    "            self.val_loss.append(val_loss)\n",
    "\n",
    "            if val_loader:\n",
    "                if val_loss < best_val_loss - 1e-4:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_model_state = self.model.state_dict()\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    if epochs_no_improve >= self.patience:\n",
    "                        print(f\"Early stopping at epoch {ep}\")\n",
    "                        break\n",
    "\n",
    "        if best_model_state:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        if data_loader is None:\n",
    "            return None\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, onehot, y_batch in data_loader:\n",
    "                x_batch, onehot, y_batch = x_batch.to(self.device), onehot.to(self.device), y_batch.to(self.device)\n",
    "                outputs = self.model(x_batch, onehot)\n",
    "                loss = self.cri2(outputs, y_batch)\n",
    "                total_loss += loss.item()\n",
    "        return total_loss / len(data_loader)\n",
    "\n",
    "    def predict(self, x, onehot):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = x.to(self.device)\n",
    "            onehot = onehot.to(self.device)\n",
    "            return self.model(x, onehot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9feefaab-7522-4dfb-8e3d-64e935acdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(info, train_loader, val_loader, test_loader, plot = True):\n",
    "    rs, hid, nl, lr = info\n",
    "    \n",
    "    y_true_train = []\n",
    "    y_pred_train = []\n",
    "    \n",
    "    y_true_val = []\n",
    "    y_pred_val = []\n",
    "    \n",
    "    y_true_test = []\n",
    "    y_pred_test = []\n",
    "\n",
    "    y_true_test_M = []\n",
    "    y_pred_test_M = []\n",
    "\n",
    "    y_true_test_D = []\n",
    "    y_pred_test_D = []\n",
    "\n",
    "    y_true_test_H = []\n",
    "    y_pred_test_H = []\n",
    "    \n",
    "    for x_batch, onehot, y_batch in train_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_train.append(y_batch)\n",
    "        y_pred_train.append(preds.cpu())\n",
    "    \n",
    "    for x_batch, onehot, y_batch in val_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_val.append(y_batch)\n",
    "        y_pred_val.append(preds.cpu())\n",
    "    \n",
    "    for x_batch, onehot, y_batch in test_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_test.append(y_batch)\n",
    "        y_pred_test.append(preds.cpu())\n",
    "    \n",
    "        onehot_np = onehot.cpu().numpy()\n",
    "        y_true_np = y_batch.cpu().numpy()\n",
    "        y_pred_np = preds.cpu().numpy()\n",
    "    \n",
    "        for i in range(len(onehot_np)):\n",
    "            if np.array_equal(onehot_np[i], [1, 0, 0]):  # 'M'\n",
    "                y_true_test_M.append(y_true_np[i])\n",
    "                y_pred_test_M.append(y_pred_np[i])\n",
    "            elif np.array_equal(onehot_np[i], [0, 1, 0]):  # 'D'\n",
    "                y_true_test_D.append(y_true_np[i])\n",
    "                y_pred_test_D.append(y_pred_np[i])\n",
    "            elif np.array_equal(onehot_np[i], [0, 0, 1]):  # 'H'\n",
    "                y_true_test_H.append(y_true_np[i])\n",
    "                y_pred_test_H.append(y_pred_np[i])\n",
    "    \n",
    "    y_true_train = torch.cat(y_true_train).numpy()\n",
    "    y_pred_train = torch.cat(y_pred_train).numpy()\n",
    "    \n",
    "    y_true_val = torch.cat(y_true_val).numpy()\n",
    "    y_pred_val = torch.cat(y_pred_val).numpy()\n",
    "    \n",
    "    y_true_test = torch.cat(y_true_test).numpy()\n",
    "    y_pred_test = torch.cat(y_pred_test).numpy()\n",
    "\n",
    "    y_true_test_M = np.array(y_true_test_M)\n",
    "    y_pred_test_M = np.array(y_pred_test_M)\n",
    "    \n",
    "    y_true_test_D = np.array(y_true_test_D)\n",
    "    y_pred_test_D = np.array(y_pred_test_D)\n",
    "    \n",
    "    y_true_test_H = np.array(y_true_test_H)\n",
    "    y_pred_test_H = np.array(y_pred_test_H)\n",
    "    \n",
    "    mape_M = mean_absolute_percentage_error(y_true_test_M, y_pred_test_M) * 100 if len(y_true_test_M) > 0 else np.nan\n",
    "    mape_D = mean_absolute_percentage_error(y_true_test_D, y_pred_test_D) * 100 if len(y_true_test_D) > 0 else np.nan\n",
    "    mape_H = mean_absolute_percentage_error(y_true_test_H, y_pred_test_H) * 100 if len(y_true_test_H) > 0 else np.nan\n",
    "    \n",
    "    train_mape = mean_absolute_percentage_error(y_true_train, y_pred_train) * 100\n",
    "    val_mape = mean_absolute_percentage_error(y_true_val, y_pred_val) * 100\n",
    "    test_mape = mean_absolute_percentage_error(y_true_test, y_pred_test) * 100\n",
    "    print(f\"Rs: {rs}, hid: {hid}, {nl} layers, lr: {lr}\\n Train MAPE: {train_mape:.2f}%, Val MAPE: {val_mape:.2f}%, Test MAPE: {test_mape:.2f}%\")\n",
    "    print(f\"Test MAPE by 'Next': M: {mape_M:.2f}%, D: {mape_D:.2f}%, H: {mape_H:.2f}%\")\n",
    "    if plot == True:\n",
    "        _ = plt.figure()\n",
    "        _ = plt.scatter(y_true_train, y_pred_train, label = 'Train')\n",
    "        _ = plt.scatter(y_true_val, y_pred_val, label = 'Val')\n",
    "        _ = plt.scatter(y_true_test, y_pred_test, label = 'Test')\n",
    "        min_val = min(y_true_train.min(), y_true_test.min())\n",
    "        max_val = max(y_true_train.max(), y_true_test.max())\n",
    "        _ = plt.plot([min_val, max_val], [min_val, max_val], 'k--', label='Ideal line')\n",
    "        _ = plt.xlabel('True SOH')\n",
    "        _ = plt.ylabel('Predicted SOH')\n",
    "        _ = plt.legend()\n",
    "        _ = plt.title(f'Random state: {rs}, hid: {hid}, {nl} layer, lr: {lr}')\n",
    "    return train_mape, val_mape, test_mape, mape_M, mape_D, mape_H\n",
    "\n",
    "def plot_loss(info, train_loss, val_loss, test_loss):\n",
    "    rs, hid, nl, lr = info\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(train_loss, label = 'Train loss')\n",
    "    _ = plt.plot(val_loss, label = 'Val loss')\n",
    "    _ = plt.plot(test_loss, label = 'Test loss')\n",
    "    _ = plt.ylim([0, 2])\n",
    "    _ = plt.xlabel('Epoch')\n",
    "    _ = plt.ylabel('Loss')\n",
    "    _ = plt.legend()\n",
    "    _ = plt.title(f'Random state: {rs}, hid: {hid}, {nl} layers, lr: {lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c6ff2bf-41cc-4b6a-9773-02ee2dbbf98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 169\n",
      "Rs: 100, hid: 8, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.83%, Val MAPE: 1.29%, Test MAPE: 1.12%\n",
      "Test MAPE by 'Next': M: 1.26%, D: 0.99%, H: nan%\n",
      "Rs: 100, hid: 8, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.97%, Val MAPE: 1.88%, Test MAPE: 1.14%\n",
      "Test MAPE by 'Next': M: 1.30%, D: 0.98%, H: nan%\n",
      "Early stopping at epoch 139\n",
      "Rs: 100, hid: 8, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.82%, Val MAPE: 1.30%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: 1.00%, D: 0.88%, H: nan%\n",
      "Rs: 100, hid: 8, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.87%, Val MAPE: 1.33%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: 1.00%, D: 0.89%, H: nan%\n",
      "Early stopping at epoch 252\n",
      "Rs: 100, hid: 8, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.83%, Val MAPE: 1.07%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: 1.09%, D: 0.78%, H: nan%\n",
      "Early stopping at epoch 900\n",
      "Rs: 100, hid: 8, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.95%, Val MAPE: 0.95%, Test MAPE: 0.93%\n",
      "Test MAPE by 'Next': M: 0.98%, D: 0.87%, H: nan%\n",
      "Early stopping at epoch 303\n",
      "Rs: 100, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.89%, Val MAPE: 1.61%, Test MAPE: 0.97%\n",
      "Test MAPE by 'Next': M: 1.07%, D: 0.86%, H: nan%\n",
      "Rs: 100, hid: 8, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.89%, Val MAPE: 1.69%, Test MAPE: 0.92%\n",
      "Test MAPE by 'Next': M: 0.96%, D: 0.89%, H: nan%\n",
      "Early stopping at epoch 211\n",
      "Rs: 100, hid: 8, 6 layers, lr: 0.001\n",
      " Train MAPE: 1.85%, Val MAPE: 1.94%, Test MAPE: 1.86%\n",
      "Test MAPE by 'Next': M: 1.94%, D: 1.79%, H: nan%\n",
      "Rs: 100, hid: 8, 6 layers, lr: 0.0001\n",
      " Train MAPE: 2.22%, Val MAPE: 2.53%, Test MAPE: 2.30%\n",
      "Test MAPE by 'Next': M: 2.41%, D: 2.20%, H: nan%\n",
      "Early stopping at epoch 186\n",
      "Rs: 100, hid: 16, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.87%, Val MAPE: 1.22%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: 1.02%, D: 1.02%, H: nan%\n",
      "Early stopping at epoch 858\n",
      "Rs: 100, hid: 16, 2 layers, lr: 0.0001\n",
      " Train MAPE: 1.01%, Val MAPE: 1.55%, Test MAPE: 1.26%\n",
      "Test MAPE by 'Next': M: 1.36%, D: 1.16%, H: nan%\n",
      "Early stopping at epoch 171\n",
      "Rs: 100, hid: 16, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.89%, Val MAPE: 1.31%, Test MAPE: 1.24%\n",
      "Test MAPE by 'Next': M: 1.29%, D: 1.18%, H: nan%\n",
      "Early stopping at epoch 647\n",
      "Rs: 100, hid: 16, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.74%, Val MAPE: 1.20%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 1.03%, D: 1.18%, H: nan%\n",
      "Early stopping at epoch 221\n",
      "Rs: 100, hid: 16, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.80%, Val MAPE: 0.96%, Test MAPE: 1.00%\n",
      "Test MAPE by 'Next': M: 1.11%, D: 0.89%, H: nan%\n",
      "Early stopping at epoch 842\n",
      "Rs: 100, hid: 16, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.98%, Val MAPE: 1.60%, Test MAPE: 1.18%\n",
      "Test MAPE by 'Next': M: 1.16%, D: 1.20%, H: nan%\n",
      "Early stopping at epoch 199\n",
      "Rs: 100, hid: 16, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.68%, Val MAPE: 0.96%, Test MAPE: 0.89%\n",
      "Test MAPE by 'Next': M: 0.99%, D: 0.78%, H: nan%\n",
      "Early stopping at epoch 545\n",
      "Rs: 100, hid: 16, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.83%, Val MAPE: 0.94%, Test MAPE: 0.98%\n",
      "Test MAPE by 'Next': M: 1.11%, D: 0.85%, H: nan%\n",
      "Early stopping at epoch 119\n",
      "Rs: 100, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.86%, Val MAPE: 1.14%, Test MAPE: 1.06%\n",
      "Test MAPE by 'Next': M: 1.16%, D: 0.96%, H: nan%\n",
      "Early stopping at epoch 525\n",
      "Rs: 100, hid: 16, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.85%, Val MAPE: 1.21%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: 1.06%, D: 0.99%, H: nan%\n",
      "Early stopping at epoch 163\n",
      "Rs: 100, hid: 32, 2 layers, lr: 0.001\n",
      " Train MAPE: 1.09%, Val MAPE: 2.43%, Test MAPE: 1.66%\n",
      "Test MAPE by 'Next': M: 2.03%, D: 1.29%, H: nan%\n",
      "Early stopping at epoch 669\n",
      "Rs: 100, hid: 32, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.73%, Val MAPE: 2.40%, Test MAPE: 1.55%\n",
      "Test MAPE by 'Next': M: 1.82%, D: 1.28%, H: nan%\n",
      "Early stopping at epoch 130\n",
      "Rs: 100, hid: 32, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.85%, Val MAPE: 1.91%, Test MAPE: 1.46%\n",
      "Test MAPE by 'Next': M: 1.74%, D: 1.19%, H: nan%\n",
      "Early stopping at epoch 927\n",
      "Rs: 100, hid: 32, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.62%, Val MAPE: 2.42%, Test MAPE: 1.61%\n",
      "Test MAPE by 'Next': M: 1.72%, D: 1.49%, H: nan%\n",
      "Early stopping at epoch 90\n",
      "Rs: 100, hid: 32, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.63%, Val MAPE: 1.11%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: 1.40%, D: 0.76%, H: nan%\n",
      "Early stopping at epoch 344\n",
      "Rs: 100, hid: 32, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.71%, Val MAPE: 2.11%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.23%, D: 0.87%, H: nan%\n",
      "Early stopping at epoch 225\n",
      "Rs: 100, hid: 32, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.68%, Val MAPE: 1.38%, Test MAPE: 1.14%\n",
      "Test MAPE by 'Next': M: 1.28%, D: 1.00%, H: nan%\n",
      "Early stopping at epoch 394\n",
      "Rs: 100, hid: 32, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.72%, Val MAPE: 1.97%, Test MAPE: 1.15%\n",
      "Test MAPE by 'Next': M: 1.35%, D: 0.96%, H: nan%\n",
      "Early stopping at epoch 117\n",
      "Rs: 100, hid: 32, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.69%, Val MAPE: 0.92%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: 1.22%, D: 0.82%, H: nan%\n",
      "Early stopping at epoch 314\n",
      "Rs: 100, hid: 32, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.75%, Val MAPE: 1.80%, Test MAPE: 1.06%\n",
      "Test MAPE by 'Next': M: 1.20%, D: 0.93%, H: nan%\n",
      "Early stopping at epoch 237\n",
      "Rs: 120, hid: 8, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.87%, Val MAPE: 1.02%, Test MAPE: 0.96%\n",
      "Test MAPE by 'Next': M: 1.04%, D: 0.88%, H: nan%\n",
      "Rs: 120, hid: 8, 2 layers, lr: 0.0001\n",
      " Train MAPE: 1.01%, Val MAPE: 1.12%, Test MAPE: 1.21%\n",
      "Test MAPE by 'Next': M: 1.45%, D: 0.97%, H: nan%\n",
      "Early stopping at epoch 159\n",
      "Rs: 120, hid: 8, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.89%, Val MAPE: 0.90%, Test MAPE: 0.78%\n",
      "Test MAPE by 'Next': M: 0.73%, D: 0.84%, H: nan%\n",
      "Rs: 120, hid: 8, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.94%, Val MAPE: 0.98%, Test MAPE: 0.81%\n",
      "Test MAPE by 'Next': M: 0.76%, D: 0.87%, H: nan%\n",
      "Early stopping at epoch 139\n",
      "Rs: 120, hid: 8, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.89%, Val MAPE: 0.90%, Test MAPE: 0.83%\n",
      "Test MAPE by 'Next': M: 0.91%, D: 0.75%, H: nan%\n",
      "Rs: 120, hid: 8, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.94%, Val MAPE: 0.92%, Test MAPE: 0.77%\n",
      "Test MAPE by 'Next': M: 0.78%, D: 0.76%, H: nan%\n",
      "Early stopping at epoch 127\n",
      "Rs: 120, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 1.00%, Val MAPE: 0.83%, Test MAPE: 0.80%\n",
      "Test MAPE by 'Next': M: 0.82%, D: 0.77%, H: nan%\n",
      "Early stopping at epoch 443\n",
      "Rs: 120, hid: 8, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.99%, Val MAPE: 0.84%, Test MAPE: 0.76%\n",
      "Test MAPE by 'Next': M: 0.83%, D: 0.68%, H: nan%\n",
      "Early stopping at epoch 172\n",
      "Rs: 120, hid: 8, 6 layers, lr: 0.001\n",
      " Train MAPE: 1.10%, Val MAPE: 0.94%, Test MAPE: 0.92%\n",
      "Test MAPE by 'Next': M: 0.95%, D: 0.90%, H: nan%\n",
      "Rs: 120, hid: 8, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.98%, Val MAPE: 1.01%, Test MAPE: 0.76%\n",
      "Test MAPE by 'Next': M: 0.88%, D: 0.64%, H: nan%\n",
      "Early stopping at epoch 278\n",
      "Rs: 120, hid: 16, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.93%, Val MAPE: 1.08%, Test MAPE: 0.97%\n",
      "Test MAPE by 'Next': M: 1.13%, D: 0.80%, H: nan%\n",
      "Rs: 120, hid: 16, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.94%, Val MAPE: 1.11%, Test MAPE: 1.00%\n",
      "Test MAPE by 'Next': M: 1.20%, D: 0.80%, H: nan%\n",
      "Early stopping at epoch 144\n",
      "Rs: 120, hid: 16, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.81%, Val MAPE: 1.13%, Test MAPE: 0.85%\n",
      "Test MAPE by 'Next': M: 0.79%, D: 0.91%, H: nan%\n",
      "Early stopping at epoch 606\n",
      "Rs: 120, hid: 16, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.86%, Val MAPE: 1.05%, Test MAPE: 0.84%\n",
      "Test MAPE by 'Next': M: 0.82%, D: 0.86%, H: nan%\n",
      "Early stopping at epoch 225\n",
      "Rs: 120, hid: 16, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.82%, Val MAPE: 0.89%, Test MAPE: 0.74%\n",
      "Test MAPE by 'Next': M: 0.79%, D: 0.68%, H: nan%\n",
      "Early stopping at epoch 472\n",
      "Rs: 120, hid: 16, 4 layers, lr: 0.0001\n",
      " Train MAPE: 1.00%, Val MAPE: 1.08%, Test MAPE: 0.93%\n",
      "Test MAPE by 'Next': M: 1.10%, D: 0.76%, H: nan%\n",
      "Early stopping at epoch 143\n",
      "Rs: 120, hid: 16, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.87%, Val MAPE: 1.04%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: 1.02%, D: 0.88%, H: nan%\n",
      "Early stopping at epoch 376\n",
      "Rs: 120, hid: 16, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.97%, Val MAPE: 1.34%, Test MAPE: 1.25%\n",
      "Test MAPE by 'Next': M: 1.29%, D: 1.21%, H: nan%\n",
      "Early stopping at epoch 141\n",
      "Rs: 120, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.87%, Val MAPE: 0.95%, Test MAPE: 0.86%\n",
      "Test MAPE by 'Next': M: 0.96%, D: 0.77%, H: nan%\n",
      "Rs: 120, hid: 16, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.91%, Val MAPE: 1.05%, Test MAPE: 0.86%\n",
      "Test MAPE by 'Next': M: 1.01%, D: 0.72%, H: nan%\n",
      "Early stopping at epoch 178\n",
      "Rs: 120, hid: 32, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.76%, Val MAPE: 1.11%, Test MAPE: 0.97%\n",
      "Test MAPE by 'Next': M: 0.89%, D: 1.05%, H: nan%\n",
      "Early stopping at epoch 243\n",
      "Rs: 120, hid: 32, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.85%, Val MAPE: 1.19%, Test MAPE: 1.09%\n",
      "Test MAPE by 'Next': M: 1.17%, D: 1.00%, H: nan%\n",
      "Early stopping at epoch 169\n",
      "Rs: 120, hid: 32, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.72%, Val MAPE: 1.12%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: 0.95%, D: 0.96%, H: nan%\n",
      "Early stopping at epoch 426\n",
      "Rs: 120, hid: 32, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.83%, Val MAPE: 1.24%, Test MAPE: 1.10%\n",
      "Test MAPE by 'Next': M: 1.28%, D: 0.92%, H: nan%\n",
      "Early stopping at epoch 168\n",
      "Rs: 120, hid: 32, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.76%, Val MAPE: 0.95%, Test MAPE: 0.81%\n",
      "Test MAPE by 'Next': M: 0.97%, D: 0.65%, H: nan%\n",
      "Early stopping at epoch 310\n",
      "Rs: 120, hid: 32, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.73%, Val MAPE: 0.92%, Test MAPE: 0.92%\n",
      "Test MAPE by 'Next': M: 0.95%, D: 0.90%, H: nan%\n",
      "Early stopping at epoch 188\n",
      "Rs: 120, hid: 32, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.76%, Val MAPE: 0.95%, Test MAPE: 0.82%\n",
      "Test MAPE by 'Next': M: 0.89%, D: 0.74%, H: nan%\n",
      "Early stopping at epoch 192\n",
      "Rs: 120, hid: 32, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.87%, Val MAPE: 0.95%, Test MAPE: 0.88%\n",
      "Test MAPE by 'Next': M: 0.98%, D: 0.78%, H: nan%\n",
      "Early stopping at epoch 86\n",
      "Rs: 120, hid: 32, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.84%, Val MAPE: 0.88%, Test MAPE: 0.84%\n",
      "Test MAPE by 'Next': M: 0.92%, D: 0.77%, H: nan%\n",
      "Early stopping at epoch 329\n",
      "Rs: 120, hid: 32, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.79%, Val MAPE: 1.05%, Test MAPE: 0.90%\n",
      "Test MAPE by 'Next': M: 0.93%, D: 0.87%, H: nan%\n",
      "Early stopping at epoch 272\n",
      "Rs: 140, hid: 8, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.69%, Val MAPE: 1.43%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 1.09%, D: 0.97%, H: nan%\n",
      "Rs: 140, hid: 8, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.99%, Val MAPE: 1.25%, Test MAPE: 1.28%\n",
      "Test MAPE by 'Next': M: 1.49%, D: 1.07%, H: nan%\n",
      "Early stopping at epoch 257\n",
      "Rs: 140, hid: 8, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.81%, Val MAPE: 1.34%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: 0.98%, D: 1.11%, H: nan%\n",
      "Rs: 140, hid: 8, 3 layers, lr: 0.0001\n",
      " Train MAPE: 1.08%, Val MAPE: 1.75%, Test MAPE: 1.39%\n",
      "Test MAPE by 'Next': M: 1.38%, D: 1.39%, H: nan%\n",
      "Early stopping at epoch 188\n",
      "Rs: 140, hid: 8, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.67%, Val MAPE: 1.51%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: 1.05%, D: 1.02%, H: nan%\n",
      "Early stopping at epoch 908\n",
      "Rs: 140, hid: 8, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.71%, Val MAPE: 1.58%, Test MAPE: 0.99%\n",
      "Test MAPE by 'Next': M: 1.07%, D: 0.92%, H: nan%\n",
      "Early stopping at epoch 220\n",
      "Rs: 140, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.76%, Val MAPE: 1.32%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: 1.02%, D: 0.86%, H: nan%\n",
      "Rs: 140, hid: 8, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.73%, Val MAPE: 1.55%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: 1.02%, D: 0.86%, H: nan%\n",
      "Early stopping at epoch 340\n",
      "Rs: 140, hid: 8, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.86%, Val MAPE: 1.42%, Test MAPE: 0.99%\n",
      "Test MAPE by 'Next': M: 1.02%, D: 0.96%, H: nan%\n",
      "Early stopping at epoch 636\n",
      "Rs: 140, hid: 8, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.81%, Val MAPE: 1.23%, Test MAPE: 0.89%\n",
      "Test MAPE by 'Next': M: 0.93%, D: 0.85%, H: nan%\n",
      "Early stopping at epoch 168\n",
      "Rs: 140, hid: 16, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.84%, Val MAPE: 1.34%, Test MAPE: 1.51%\n",
      "Test MAPE by 'Next': M: 1.35%, D: 1.66%, H: nan%\n",
      "Early stopping at epoch 727\n",
      "Rs: 140, hid: 16, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.94%, Val MAPE: 1.30%, Test MAPE: 1.54%\n",
      "Test MAPE by 'Next': M: 1.47%, D: 1.61%, H: nan%\n",
      "Early stopping at epoch 206\n",
      "Rs: 140, hid: 16, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.64%, Val MAPE: 1.42%, Test MAPE: 1.22%\n",
      "Test MAPE by 'Next': M: 1.11%, D: 1.33%, H: nan%\n",
      "Early stopping at epoch 835\n",
      "Rs: 140, hid: 16, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.61%, Val MAPE: 1.50%, Test MAPE: 1.14%\n",
      "Test MAPE by 'Next': M: 1.09%, D: 1.18%, H: nan%\n",
      "Early stopping at epoch 155\n",
      "Rs: 140, hid: 16, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.71%, Val MAPE: 1.05%, Test MAPE: 1.33%\n",
      "Test MAPE by 'Next': M: 1.05%, D: 1.61%, H: nan%\n",
      "Rs: 140, hid: 16, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.65%, Val MAPE: 1.34%, Test MAPE: 1.37%\n",
      "Test MAPE by 'Next': M: 1.11%, D: 1.63%, H: nan%\n",
      "Early stopping at epoch 108\n",
      "Rs: 140, hid: 16, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.66%, Val MAPE: 1.30%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: 1.04%, D: 0.97%, H: nan%\n",
      "Rs: 140, hid: 16, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.63%, Val MAPE: 1.31%, Test MAPE: 1.00%\n",
      "Test MAPE by 'Next': M: 1.01%, D: 0.99%, H: nan%\n",
      "Early stopping at epoch 179\n",
      "Rs: 140, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.85%, Val MAPE: 1.34%, Test MAPE: 1.12%\n",
      "Test MAPE by 'Next': M: 1.10%, D: 1.14%, H: nan%\n",
      "Rs: 140, hid: 16, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.66%, Val MAPE: 1.32%, Test MAPE: 0.97%\n",
      "Test MAPE by 'Next': M: 1.05%, D: 0.89%, H: nan%\n",
      "Early stopping at epoch 182\n",
      "Rs: 140, hid: 32, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.58%, Val MAPE: 1.54%, Test MAPE: 1.18%\n",
      "Test MAPE by 'Next': M: 1.37%, D: 0.99%, H: nan%\n",
      "Early stopping at epoch 425\n",
      "Rs: 140, hid: 32, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.61%, Val MAPE: 1.78%, Test MAPE: 1.25%\n",
      "Test MAPE by 'Next': M: 1.37%, D: 1.13%, H: nan%\n",
      "Early stopping at epoch 107\n",
      "Rs: 140, hid: 32, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.62%, Val MAPE: 1.74%, Test MAPE: 1.27%\n",
      "Test MAPE by 'Next': M: 1.18%, D: 1.36%, H: nan%\n",
      "Early stopping at epoch 471\n",
      "Rs: 140, hid: 32, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.60%, Val MAPE: 1.74%, Test MAPE: 1.21%\n",
      "Test MAPE by 'Next': M: 1.16%, D: 1.26%, H: nan%\n",
      "Early stopping at epoch 85\n",
      "Rs: 140, hid: 32, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.76%, Val MAPE: 1.92%, Test MAPE: 1.51%\n",
      "Test MAPE by 'Next': M: 1.45%, D: 1.56%, H: nan%\n",
      "Early stopping at epoch 514\n",
      "Rs: 140, hid: 32, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.52%, Val MAPE: 1.64%, Test MAPE: 1.19%\n",
      "Test MAPE by 'Next': M: 1.02%, D: 1.37%, H: nan%\n",
      "Early stopping at epoch 132\n",
      "Rs: 140, hid: 32, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.85%, Val MAPE: 1.52%, Test MAPE: 1.24%\n",
      "Test MAPE by 'Next': M: 1.22%, D: 1.27%, H: nan%\n",
      "Early stopping at epoch 471\n",
      "Rs: 140, hid: 32, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.60%, Val MAPE: 1.49%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 1.08%, D: 1.02%, H: nan%\n",
      "Early stopping at epoch 215\n",
      "Rs: 140, hid: 32, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.70%, Val MAPE: 1.30%, Test MAPE: 1.10%\n",
      "Test MAPE by 'Next': M: 1.17%, D: 1.02%, H: nan%\n",
      "Early stopping at epoch 373\n",
      "Rs: 140, hid: 32, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.73%, Val MAPE: 1.50%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: 0.95%, D: 1.12%, H: nan%\n",
      "Early stopping at epoch 105\n",
      "Rs: 160, hid: 8, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.87%, Val MAPE: 1.14%, Test MAPE: 0.97%\n",
      "Test MAPE by 'Next': M: 1.16%, D: 0.79%, H: nan%\n",
      "Early stopping at epoch 800\n",
      "Rs: 160, hid: 8, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.90%, Val MAPE: 1.10%, Test MAPE: 0.91%\n",
      "Test MAPE by 'Next': M: 1.12%, D: 0.69%, H: nan%\n",
      "Early stopping at epoch 307\n",
      "Rs: 160, hid: 8, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.83%, Val MAPE: 1.01%, Test MAPE: 0.93%\n",
      "Test MAPE by 'Next': M: 1.18%, D: 0.69%, H: nan%\n",
      "Rs: 160, hid: 8, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.94%, Val MAPE: 1.18%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: 1.38%, D: 0.77%, H: nan%\n",
      "Early stopping at epoch 330\n",
      "Rs: 160, hid: 8, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.97%, Val MAPE: 1.08%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: 1.27%, D: 0.88%, H: nan%\n",
      "Rs: 160, hid: 8, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.88%, Val MAPE: 0.99%, Test MAPE: 0.96%\n",
      "Test MAPE by 'Next': M: 1.20%, D: 0.71%, H: nan%\n",
      "Early stopping at epoch 196\n",
      "Rs: 160, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.93%, Val MAPE: 1.09%, Test MAPE: 1.06%\n",
      "Test MAPE by 'Next': M: 1.30%, D: 0.82%, H: nan%\n",
      "Early stopping at epoch 878\n",
      "Rs: 160, hid: 8, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.92%, Val MAPE: 0.98%, Test MAPE: 1.09%\n",
      "Test MAPE by 'Next': M: 1.40%, D: 0.78%, H: nan%\n",
      "Early stopping at epoch 129\n",
      "Rs: 160, hid: 8, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.80%, Val MAPE: 0.93%, Test MAPE: 0.91%\n",
      "Test MAPE by 'Next': M: 1.09%, D: 0.72%, H: nan%\n",
      "Early stopping at epoch 703\n",
      "Rs: 160, hid: 8, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.87%, Val MAPE: 0.91%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: 1.21%, D: 0.69%, H: nan%\n",
      "Early stopping at epoch 198\n",
      "Rs: 160, hid: 16, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.65%, Val MAPE: 1.12%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: 1.15%, D: 0.75%, H: nan%\n",
      "Early stopping at epoch 470\n",
      "Rs: 160, hid: 16, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.80%, Val MAPE: 1.25%, Test MAPE: 1.26%\n",
      "Test MAPE by 'Next': M: 1.57%, D: 0.96%, H: nan%\n",
      "Early stopping at epoch 231\n",
      "Rs: 160, hid: 16, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.61%, Val MAPE: 1.01%, Test MAPE: 0.98%\n",
      "Test MAPE by 'Next': M: 1.16%, D: 0.81%, H: nan%\n",
      "Rs: 160, hid: 16, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.69%, Val MAPE: 0.94%, Test MAPE: 1.12%\n",
      "Test MAPE by 'Next': M: 1.30%, D: 0.94%, H: nan%\n",
      "Early stopping at epoch 144\n",
      "Rs: 160, hid: 16, 4 layers, lr: 0.001\n",
      " Train MAPE: 1.09%, Val MAPE: 1.17%, Test MAPE: 1.15%\n",
      "Test MAPE by 'Next': M: 1.15%, D: 1.14%, H: nan%\n",
      "Early stopping at epoch 572\n",
      "Rs: 160, hid: 16, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.72%, Val MAPE: 1.04%, Test MAPE: 1.15%\n",
      "Test MAPE by 'Next': M: 1.42%, D: 0.88%, H: nan%\n",
      "Early stopping at epoch 177\n",
      "Rs: 160, hid: 16, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.80%, Val MAPE: 1.06%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: 1.29%, D: 0.79%, H: nan%\n",
      "Early stopping at epoch 842\n",
      "Rs: 160, hid: 16, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.69%, Val MAPE: 1.00%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: 1.27%, D: 0.74%, H: nan%\n",
      "Early stopping at epoch 170\n",
      "Rs: 160, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.68%, Val MAPE: 0.95%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: 1.22%, D: 0.68%, H: nan%\n",
      "Early stopping at epoch 446\n",
      "Rs: 160, hid: 16, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.81%, Val MAPE: 0.90%, Test MAPE: 0.99%\n",
      "Test MAPE by 'Next': M: 1.19%, D: 0.78%, H: nan%\n",
      "Early stopping at epoch 234\n",
      "Rs: 160, hid: 32, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.93%, Val MAPE: 1.38%, Test MAPE: 1.18%\n",
      "Test MAPE by 'Next': M: 1.56%, D: 0.79%, H: nan%\n",
      "Early stopping at epoch 630\n",
      "Rs: 160, hid: 32, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.65%, Val MAPE: 1.16%, Test MAPE: 1.30%\n",
      "Test MAPE by 'Next': M: 1.53%, D: 1.08%, H: nan%\n",
      "Early stopping at epoch 127\n",
      "Rs: 160, hid: 32, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.90%, Val MAPE: 1.40%, Test MAPE: 1.29%\n",
      "Test MAPE by 'Next': M: 1.70%, D: 0.88%, H: nan%\n",
      "Early stopping at epoch 493\n",
      "Rs: 160, hid: 32, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.71%, Val MAPE: 1.31%, Test MAPE: 1.35%\n",
      "Test MAPE by 'Next': M: 1.64%, D: 1.07%, H: nan%\n",
      "Early stopping at epoch 92\n",
      "Rs: 160, hid: 32, 4 layers, lr: 0.001\n",
      " Train MAPE: 1.21%, Val MAPE: 1.36%, Test MAPE: 1.29%\n",
      "Test MAPE by 'Next': M: 1.40%, D: 1.18%, H: nan%\n",
      "Early stopping at epoch 516\n",
      "Rs: 160, hid: 32, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.60%, Val MAPE: 1.11%, Test MAPE: 1.19%\n",
      "Test MAPE by 'Next': M: 1.48%, D: 0.90%, H: nan%\n",
      "Early stopping at epoch 137\n",
      "Rs: 160, hid: 32, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.56%, Val MAPE: 1.12%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: 1.25%, D: 0.66%, H: nan%\n",
      "Early stopping at epoch 269\n",
      "Rs: 160, hid: 32, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.68%, Val MAPE: 1.13%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 1.42%, D: 0.81%, H: nan%\n",
      "Early stopping at epoch 122\n",
      "Rs: 160, hid: 32, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.63%, Val MAPE: 1.04%, Test MAPE: 0.93%\n",
      "Test MAPE by 'Next': M: 1.16%, D: 0.70%, H: nan%\n",
      "Early stopping at epoch 245\n",
      "Rs: 160, hid: 32, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.83%, Val MAPE: 1.13%, Test MAPE: 1.12%\n",
      "Test MAPE by 'Next': M: 1.33%, D: 0.92%, H: nan%\n",
      "Early stopping at epoch 443\n",
      "Rs: 180, hid: 8, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.86%, Val MAPE: 0.95%, Test MAPE: 1.35%\n",
      "Test MAPE by 'Next': M: 1.14%, D: 1.57%, H: nan%\n",
      "Rs: 180, hid: 8, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.95%, Val MAPE: 1.32%, Test MAPE: 1.67%\n",
      "Test MAPE by 'Next': M: 1.20%, D: 2.14%, H: nan%\n",
      "Early stopping at epoch 220\n",
      "Rs: 180, hid: 8, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.84%, Val MAPE: 1.13%, Test MAPE: 1.13%\n",
      "Test MAPE by 'Next': M: 1.03%, D: 1.22%, H: nan%\n",
      "Early stopping at epoch 847\n",
      "Rs: 180, hid: 8, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.85%, Val MAPE: 1.04%, Test MAPE: 1.43%\n",
      "Test MAPE by 'Next': M: 1.16%, D: 1.71%, H: nan%\n",
      "Early stopping at epoch 274\n",
      "Rs: 180, hid: 8, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.84%, Val MAPE: 0.93%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: 1.15%, D: 1.02%, H: nan%\n",
      "Early stopping at epoch 751\n",
      "Rs: 180, hid: 8, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.90%, Val MAPE: 1.09%, Test MAPE: 1.19%\n",
      "Test MAPE by 'Next': M: 1.10%, D: 1.28%, H: nan%\n",
      "Early stopping at epoch 336\n",
      "Rs: 180, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.77%, Val MAPE: 0.86%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: 1.00%, D: 0.88%, H: nan%\n",
      "Early stopping at epoch 580\n",
      "Rs: 180, hid: 8, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.91%, Val MAPE: 0.92%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: 0.91%, D: 1.20%, H: nan%\n",
      "Early stopping at epoch 122\n",
      "Rs: 180, hid: 8, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.85%, Val MAPE: 0.99%, Test MAPE: 1.06%\n",
      "Test MAPE by 'Next': M: 0.89%, D: 1.23%, H: nan%\n",
      "Early stopping at epoch 827\n",
      "Rs: 180, hid: 8, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.88%, Val MAPE: 0.91%, Test MAPE: 1.15%\n",
      "Test MAPE by 'Next': M: 0.93%, D: 1.38%, H: nan%\n",
      "Early stopping at epoch 365\n",
      "Rs: 180, hid: 16, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.90%, Val MAPE: 1.41%, Test MAPE: 1.35%\n",
      "Test MAPE by 'Next': M: 1.30%, D: 1.40%, H: nan%\n",
      "Rs: 180, hid: 16, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.77%, Val MAPE: 1.46%, Test MAPE: 1.65%\n",
      "Test MAPE by 'Next': M: 1.50%, D: 1.81%, H: nan%\n",
      "Early stopping at epoch 272\n",
      "Rs: 180, hid: 16, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.96%, Val MAPE: 1.21%, Test MAPE: 1.32%\n",
      "Test MAPE by 'Next': M: 1.44%, D: 1.20%, H: nan%\n",
      "Early stopping at epoch 832\n",
      "Rs: 180, hid: 16, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.85%, Val MAPE: 1.55%, Test MAPE: 1.65%\n",
      "Test MAPE by 'Next': M: 1.19%, D: 2.11%, H: nan%\n",
      "Early stopping at epoch 202\n",
      "Rs: 180, hid: 16, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.77%, Val MAPE: 1.35%, Test MAPE: 1.18%\n",
      "Test MAPE by 'Next': M: 1.15%, D: 1.20%, H: nan%\n",
      "Rs: 180, hid: 16, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.81%, Val MAPE: 1.34%, Test MAPE: 1.32%\n",
      "Test MAPE by 'Next': M: 0.99%, D: 1.65%, H: nan%\n",
      "Early stopping at epoch 151\n",
      "Rs: 180, hid: 16, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.62%, Val MAPE: 1.12%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 0.92%, D: 1.13%, H: nan%\n",
      "Early stopping at epoch 742\n",
      "Rs: 180, hid: 16, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.79%, Val MAPE: 1.22%, Test MAPE: 1.21%\n",
      "Test MAPE by 'Next': M: 1.11%, D: 1.31%, H: nan%\n",
      "Early stopping at epoch 145\n",
      "Rs: 180, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.73%, Val MAPE: 1.02%, Test MAPE: 0.99%\n",
      "Test MAPE by 'Next': M: 1.04%, D: 0.93%, H: nan%\n",
      "Early stopping at epoch 454\n",
      "Rs: 180, hid: 16, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.85%, Val MAPE: 1.03%, Test MAPE: 0.97%\n",
      "Test MAPE by 'Next': M: 0.94%, D: 1.00%, H: nan%\n",
      "Early stopping at epoch 164\n",
      "Rs: 180, hid: 32, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.60%, Val MAPE: 1.94%, Test MAPE: 1.26%\n",
      "Test MAPE by 'Next': M: 1.16%, D: 1.36%, H: nan%\n",
      "Early stopping at epoch 610\n",
      "Rs: 180, hid: 32, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.65%, Val MAPE: 2.02%, Test MAPE: 1.60%\n",
      "Test MAPE by 'Next': M: 1.12%, D: 2.07%, H: nan%\n",
      "Early stopping at epoch 179\n",
      "Rs: 180, hid: 32, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.73%, Val MAPE: 1.88%, Test MAPE: 1.06%\n",
      "Test MAPE by 'Next': M: 0.96%, D: 1.16%, H: nan%\n",
      "Early stopping at epoch 635\n",
      "Rs: 180, hid: 32, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.66%, Val MAPE: 2.10%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 0.85%, D: 1.37%, H: nan%\n",
      "Early stopping at epoch 173\n",
      "Rs: 180, hid: 32, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.83%, Val MAPE: 1.70%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 1.08%, D: 1.14%, H: nan%\n",
      "Early stopping at epoch 798\n",
      "Rs: 180, hid: 32, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.53%, Val MAPE: 1.40%, Test MAPE: 1.09%\n",
      "Test MAPE by 'Next': M: 1.01%, D: 1.16%, H: nan%\n",
      "Early stopping at epoch 142\n",
      "Rs: 180, hid: 32, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.67%, Val MAPE: 1.28%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: 1.16%, D: 0.89%, H: nan%\n",
      "Early stopping at epoch 402\n",
      "Rs: 180, hid: 32, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.62%, Val MAPE: 1.47%, Test MAPE: 1.15%\n",
      "Test MAPE by 'Next': M: 1.10%, D: 1.19%, H: nan%\n",
      "Early stopping at epoch 307\n",
      "Rs: 180, hid: 32, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.58%, Val MAPE: 1.37%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: 1.12%, D: 0.95%, H: nan%\n",
      "Early stopping at epoch 265\n",
      "Rs: 180, hid: 32, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.79%, Val MAPE: 1.63%, Test MAPE: 1.34%\n",
      "Test MAPE by 'Next': M: 1.12%, D: 1.55%, H: nan%\n"
     ]
    }
   ],
   "source": [
    "random_states = [100, 120, 140, 160, 180]\n",
    "bs = 12\n",
    "ep = 1000\n",
    "hids = [8, 16, 32]\n",
    "layers = [2, 3, 4, 5, 6]\n",
    "lrs = [1e-3, 1e-4]\n",
    "\n",
    "Source_Domain = ['M', 'D']\n",
    "Target_Domain = ['H']\n",
    "\n",
    "results_df = pd.DataFrame(columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE'])\n",
    "\n",
    "X, y = Get_Data(dat)\n",
    "\n",
    "X_sc, X_ta, y_sc, y_ta = Domain_Split(X, y, Target_Domain)\n",
    "\n",
    "for rs, hid, nl, lr in product(random_states, hids, layers, lrs):\n",
    "    setRandomSeed(rs)\n",
    "\n",
    "    X_tn, X_te, y_tn, y_te = Even_Split(X_sc, y_sc, Target_Domain, 1/3, rs)\n",
    "    X_tr, X_va, y_tr, y_va = Even_Split(X_tn, y_tn, Target_Domain, 1/6, rs)\n",
    "\n",
    "    next_map = {'M': 0, 'D': 1, 'H': 2}\n",
    "    get_next = lambda idx: torch.nn.functional.one_hot(torch.tensor([next_map[i] for i in idx.get_level_values(\"Next\")]), num_classes=3).float()\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "    X_tr_std = std_scaler.fit_transform(X_tr)\n",
    "    X_val_std = std_scaler.transform(X_va)\n",
    "    X_te_std = std_scaler.transform(X_te)\n",
    "    \n",
    "    X_train = torch.Tensor(X_tr_std)\n",
    "    X_val = torch.Tensor(X_val_std)\n",
    "    X_test = torch.Tensor(X_te_std)\n",
    "    \n",
    "    y_train = torch.Tensor(y_tr[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_val = torch.Tensor(y_va[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_test = torch.Tensor(y_te[\"Next_SOH\"].values).unsqueeze(1)\n",
    "\n",
    "    next_train = get_next(X_tr.index)\n",
    "    next_val = get_next(X_va.index)\n",
    "    next_test = get_next(X_te.index)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, next_train, y_train), batch_size=bs, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, next_val, y_val), batch_size=bs, shuffle = False)\n",
    "    test_loader = DataLoader(TensorDataset(X_test, next_test, y_test), batch_size=bs, shuffle = False)\n",
    "    \n",
    "    model = MLP(hidden_dim=hid, num_layers=nl)\n",
    "    trainer = Trainer(model, lr=lr, epoch = ep, random_seed = rs)\n",
    "    \n",
    "    trainer.train(train_loader, val_loader, test_loader)\n",
    "\n",
    "    info = [rs, hid, nl, lr]\n",
    "    results = plot_results(info, train_loader, val_loader, test_loader, plot = False)\n",
    "\n",
    "    temp_df = pd.DataFrame(info+list(results)).T\n",
    "    temp_df.columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']\n",
    "    results_df = pd.concat([results_df, temp_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4819d6c3-d539-4de0-9e83-ed6af617fa12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hid</th>\n",
       "      <th>nl</th>\n",
       "      <th>lr</th>\n",
       "      <th>Train MAPE</th>\n",
       "      <th>Val MAPE</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Next M MAPE</th>\n",
       "      <th>Next D MAPE</th>\n",
       "      <th>Next H MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.799535</td>\n",
       "      <td>1.082305</td>\n",
       "      <td>0.996068</td>\n",
       "      <td>1.095968</td>\n",
       "      <td>0.896167</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.836289</td>\n",
       "      <td>1.083133</td>\n",
       "      <td>1.078009</td>\n",
       "      <td>1.050702</td>\n",
       "      <td>1.105316</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.727617</td>\n",
       "      <td>1.095781</td>\n",
       "      <td>0.981829</td>\n",
       "      <td>1.053785</td>\n",
       "      <td>0.909873</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.839873</td>\n",
       "      <td>1.098264</td>\n",
       "      <td>0.991939</td>\n",
       "      <td>1.094071</td>\n",
       "      <td>0.889808</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.816766</td>\n",
       "      <td>1.100497</td>\n",
       "      <td>0.961926</td>\n",
       "      <td>1.049704</td>\n",
       "      <td>0.874148</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.690562</td>\n",
       "      <td>1.100696</td>\n",
       "      <td>0.984735</td>\n",
       "      <td>1.117535</td>\n",
       "      <td>0.851935</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.875137</td>\n",
       "      <td>1.106683</td>\n",
       "      <td>0.967657</td>\n",
       "      <td>1.026832</td>\n",
       "      <td>0.908483</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.834860</td>\n",
       "      <td>1.135345</td>\n",
       "      <td>0.964673</td>\n",
       "      <td>0.984136</td>\n",
       "      <td>0.945210</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.872826</td>\n",
       "      <td>1.142041</td>\n",
       "      <td>0.939879</td>\n",
       "      <td>1.040966</td>\n",
       "      <td>0.838793</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.782291</td>\n",
       "      <td>1.160541</td>\n",
       "      <td>1.090119</td>\n",
       "      <td>1.158153</td>\n",
       "      <td>1.022086</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.827067</td>\n",
       "      <td>1.166207</td>\n",
       "      <td>1.087173</td>\n",
       "      <td>1.137077</td>\n",
       "      <td>1.037269</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.887089</td>\n",
       "      <td>1.193958</td>\n",
       "      <td>0.951276</td>\n",
       "      <td>1.021275</td>\n",
       "      <td>0.881277</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.782108</td>\n",
       "      <td>1.216478</td>\n",
       "      <td>1.121530</td>\n",
       "      <td>1.158366</td>\n",
       "      <td>1.084694</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.840867</td>\n",
       "      <td>1.233514</td>\n",
       "      <td>1.157418</td>\n",
       "      <td>1.189343</td>\n",
       "      <td>1.125494</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.093050</td>\n",
       "      <td>1.244121</td>\n",
       "      <td>1.147400</td>\n",
       "      <td>1.176291</td>\n",
       "      <td>1.118509</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.706425</td>\n",
       "      <td>1.249339</td>\n",
       "      <td>1.037062</td>\n",
       "      <td>1.159789</td>\n",
       "      <td>0.914336</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.748570</td>\n",
       "      <td>1.250706</td>\n",
       "      <td>1.171425</td>\n",
       "      <td>1.087108</td>\n",
       "      <td>1.255742</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.935759</td>\n",
       "      <td>1.257017</td>\n",
       "      <td>1.131017</td>\n",
       "      <td>1.135888</td>\n",
       "      <td>1.126146</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.831428</td>\n",
       "      <td>1.280873</td>\n",
       "      <td>1.190347</td>\n",
       "      <td>1.155286</td>\n",
       "      <td>1.225408</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.150961</td>\n",
       "      <td>1.315767</td>\n",
       "      <td>1.211875</td>\n",
       "      <td>1.270750</td>\n",
       "      <td>1.152999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.964075</td>\n",
       "      <td>1.331961</td>\n",
       "      <td>1.240651</td>\n",
       "      <td>1.310793</td>\n",
       "      <td>1.170510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.892150</td>\n",
       "      <td>1.335779</td>\n",
       "      <td>1.342372</td>\n",
       "      <td>1.416898</td>\n",
       "      <td>1.267847</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.698859</td>\n",
       "      <td>1.401882</td>\n",
       "      <td>1.067889</td>\n",
       "      <td>1.185747</td>\n",
       "      <td>0.950030</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.836315</td>\n",
       "      <td>1.406733</td>\n",
       "      <td>1.160136</td>\n",
       "      <td>1.260518</td>\n",
       "      <td>1.059754</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.779332</td>\n",
       "      <td>1.422832</td>\n",
       "      <td>1.090901</td>\n",
       "      <td>1.103958</td>\n",
       "      <td>1.077844</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.616915</td>\n",
       "      <td>1.438194</td>\n",
       "      <td>1.088512</td>\n",
       "      <td>1.137149</td>\n",
       "      <td>1.039875</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.764707</td>\n",
       "      <td>1.608349</td>\n",
       "      <td>1.207588</td>\n",
       "      <td>1.304193</td>\n",
       "      <td>1.110984</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.790183</td>\n",
       "      <td>1.679179</td>\n",
       "      <td>1.250266</td>\n",
       "      <td>1.402907</td>\n",
       "      <td>1.097625</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.697776</td>\n",
       "      <td>1.710372</td>\n",
       "      <td>1.356449</td>\n",
       "      <td>1.402368</td>\n",
       "      <td>1.310530</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.683016</td>\n",
       "      <td>1.764317</td>\n",
       "      <td>1.277494</td>\n",
       "      <td>1.332314</td>\n",
       "      <td>1.222673</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     hid   nl      lr  Train MAPE  Val MAPE  Test MAPE  Next M MAPE  \\\n",
       "19  16.0  6.0  0.0010    0.799535  1.082305   0.996068     1.095968   \n",
       "15  16.0  4.0  0.0010    0.836289  1.083133   1.078009     1.050702   \n",
       "17  16.0  5.0  0.0010    0.727617  1.095781   0.981829     1.053785   \n",
       "5    8.0  4.0  0.0010    0.839873  1.098264   0.991939     1.094071   \n",
       "18  16.0  6.0  0.0001    0.816766  1.100497   0.961926     1.049704   \n",
       "29  32.0  6.0  0.0010    0.690562  1.100696   0.984735     1.117535   \n",
       "4    8.0  4.0  0.0001    0.875137  1.106683   0.967657     1.026832   \n",
       "3    8.0  3.0  0.0010    0.834860  1.135345   0.964673     0.984136   \n",
       "7    8.0  5.0  0.0010    0.872826  1.142041   0.939879     1.040966   \n",
       "16  16.0  5.0  0.0001    0.782291  1.160541   1.090119     1.158153   \n",
       "1    8.0  2.0  0.0010    0.827067  1.166207   1.087173     1.137077   \n",
       "6    8.0  5.0  0.0001    0.887089  1.193958   0.951276     1.021275   \n",
       "13  16.0  3.0  0.0010    0.782108  1.216478   1.121530     1.158366   \n",
       "11  16.0  2.0  0.0010    0.840867  1.233514   1.157418     1.189343   \n",
       "9    8.0  6.0  0.0010    1.093050  1.244121   1.147400     1.176291   \n",
       "27  32.0  5.0  0.0010    0.706425  1.249339   1.037062     1.159789   \n",
       "12  16.0  3.0  0.0001    0.748570  1.250706   1.171425     1.087108   \n",
       "2    8.0  3.0  0.0001    0.935759  1.257017   1.131017     1.135888   \n",
       "14  16.0  4.0  0.0001    0.831428  1.280873   1.190347     1.155286   \n",
       "8    8.0  6.0  0.0001    1.150961  1.315767   1.211875     1.270750   \n",
       "0    8.0  2.0  0.0001    0.964075  1.331961   1.240651     1.310793   \n",
       "10  16.0  2.0  0.0001    0.892150  1.335779   1.342372     1.416898   \n",
       "26  32.0  5.0  0.0001    0.698859  1.401882   1.067889     1.185747   \n",
       "25  32.0  4.0  0.0010    0.836315  1.406733   1.160136     1.260518   \n",
       "28  32.0  6.0  0.0001    0.779332  1.422832   1.090901     1.103958   \n",
       "24  32.0  4.0  0.0001    0.616915  1.438194   1.088512     1.137149   \n",
       "23  32.0  3.0  0.0010    0.764707  1.608349   1.207588     1.304193   \n",
       "21  32.0  2.0  0.0010    0.790183  1.679179   1.250266     1.402907   \n",
       "20  32.0  2.0  0.0001    0.697776  1.710372   1.356449     1.402368   \n",
       "22  32.0  3.0  0.0001    0.683016  1.764317   1.277494     1.332314   \n",
       "\n",
       "    Next D MAPE  Next H MAPE  \n",
       "19     0.896167          NaN  \n",
       "15     1.105316          NaN  \n",
       "17     0.909873          NaN  \n",
       "5      0.889808          NaN  \n",
       "18     0.874148          NaN  \n",
       "29     0.851935          NaN  \n",
       "4      0.908483          NaN  \n",
       "3      0.945210          NaN  \n",
       "7      0.838793          NaN  \n",
       "16     1.022086          NaN  \n",
       "1      1.037269          NaN  \n",
       "6      0.881277          NaN  \n",
       "13     1.084694          NaN  \n",
       "11     1.125494          NaN  \n",
       "9      1.118509          NaN  \n",
       "27     0.914336          NaN  \n",
       "12     1.255742          NaN  \n",
       "2      1.126146          NaN  \n",
       "14     1.225408          NaN  \n",
       "8      1.152999          NaN  \n",
       "0      1.170510          NaN  \n",
       "10     1.267847          NaN  \n",
       "26     0.950030          NaN  \n",
       "25     1.059754          NaN  \n",
       "28     1.077844          NaN  \n",
       "24     1.039875          NaN  \n",
       "23     1.110984          NaN  \n",
       "21     1.097625          NaN  \n",
       "20     1.310530          NaN  \n",
       "22     1.222673          NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = results_df.groupby(['hid', 'nl', 'lr'])[['Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']].mean().reset_index()\n",
    "\n",
    "summary_df_sorted = summary_df.sort_values(by = 'Val MAPE', ascending = True)\n",
    "summary_df_sorted\n",
    "\n",
    "results_df.to_csv(f\"MLP_Domain_Source_{Source_Domain}_next_info.csv\")\n",
    "summary_df_sorted.to_csv(f\"MLP_Domain_Source_{Source_Domain}_next_info_sum.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82878289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hid    16.000\n",
       "nl      6.000\n",
       "lr      0.001\n",
       "Name: 19, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyper_parameter = summary_df_sorted.iloc[0][['hid', 'nl', 'lr']]\n",
    "best_hyper_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dbb98c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 119\n",
      "Rs: 100, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.59%, Val MAPE: 0.76%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: nan%, D: nan%, H: 1.05%\n",
      "Rs: 100, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.89%, Val MAPE: 1.11%, Test MAPE: 1.12%\n",
      "Test MAPE by 'Next': M: 1.20%, D: 1.03%, H: nan%\n",
      "Early stopping at epoch 141\n",
      "Early stopping at epoch 546\n",
      "Rs: 120, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.35%, Val MAPE: 0.45%, Test MAPE: 0.89%\n",
      "Test MAPE by 'Next': M: nan%, D: nan%, H: 0.89%\n",
      "Rs: 120, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.88%, Val MAPE: 0.96%, Test MAPE: 0.87%\n",
      "Test MAPE by 'Next': M: 0.97%, D: 0.77%, H: nan%\n",
      "Early stopping at epoch 179\n",
      "Early stopping at epoch 318\n",
      "Rs: 140, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.47%, Val MAPE: 0.67%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: nan%, D: nan%, H: 1.03%\n",
      "Rs: 140, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.74%, Val MAPE: 1.09%, Test MAPE: 1.06%\n",
      "Test MAPE by 'Next': M: 1.07%, D: 1.06%, H: nan%\n",
      "Early stopping at epoch 170\n",
      "Early stopping at epoch 268\n",
      "Rs: 160, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.74%, Val MAPE: 1.16%, Test MAPE: 0.82%\n",
      "Test MAPE by 'Next': M: nan%, D: nan%, H: 0.82%\n",
      "Rs: 160, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.69%, Val MAPE: 0.95%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: 1.23%, D: 0.67%, H: nan%\n",
      "Early stopping at epoch 145\n",
      "Early stopping at epoch 83\n",
      "Rs: 180, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 1.03%, Val MAPE: 1.45%, Test MAPE: 1.21%\n",
      "Test MAPE by 'Next': M: nan%, D: nan%, H: 1.21%\n",
      "Rs: 180, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.77%, Val MAPE: 1.05%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: 1.08%, D: 0.95%, H: nan%\n"
     ]
    }
   ],
   "source": [
    "hid = int(best_hyper_parameter['hid'])\n",
    "nl  = int(best_hyper_parameter['nl'])\n",
    "lr  = float(best_hyper_parameter['lr'])\n",
    "\n",
    "results_df_Ta = pd.DataFrame(columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE'])\n",
    "results_df_Sc = pd.DataFrame(columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE'])\n",
    "\n",
    "\n",
    "for rs in random_states:\n",
    "    setRandomSeed(rs)\n",
    "\n",
    "    X_tn, X_te, y_tn, y_te = Even_Split(X_sc, y_sc, Target_Domain, 1/3, rs)\n",
    "    X_tr, X_va, y_tr, y_va = Even_Split(X_tn, y_tn, Target_Domain, 1/6, rs)\n",
    "\n",
    "    next_map = {'M': 0, 'D': 1, 'H': 2}\n",
    "    get_next = lambda idx: torch.nn.functional.one_hot(torch.tensor([next_map[i] for i in idx.get_level_values(\"Next\")]), num_classes=3).float()\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "    X_tr_std = std_scaler.fit_transform(X_tr)\n",
    "    X_val_std = std_scaler.transform(X_va)\n",
    "    X_te_std = std_scaler.transform(X_te)\n",
    "    \n",
    "    X_train = torch.Tensor(X_tr_std)\n",
    "    X_val = torch.Tensor(X_val_std)\n",
    "    X_test = torch.Tensor(X_te_std)\n",
    "    \n",
    "    y_train = torch.Tensor(y_tr[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_val = torch.Tensor(y_va[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_test = torch.Tensor(y_te[\"Next_SOH\"].values).unsqueeze(1)\n",
    "\n",
    "    next_train = get_next(X_tr.index)\n",
    "    next_val = get_next(X_va.index)\n",
    "    next_test = get_next(X_te.index)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, next_train, y_train), batch_size=bs, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, next_val, y_val), batch_size=bs, shuffle = False)\n",
    "    test_loader = DataLoader(TensorDataset(X_test, next_test, y_test), batch_size=bs, shuffle = False)\n",
    "    \n",
    "    model = MLP(hidden_dim=hid, num_layers=nl)\n",
    "    trainer = Trainer(model, lr=lr, epoch = ep, random_seed = rs)\n",
    "    \n",
    "    trainer.train(train_loader, val_loader, test_loader)\n",
    "\n",
    "    info = [rs, hid, nl, lr]\n",
    "    #results = plot_results(info, train_loader, val_loader, test_loader, plot = False)\n",
    "\n",
    "    trained_model = trainer.model\n",
    "    \n",
    "    for p in trained_model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    first_linear = trained_model.model[0]\n",
    "\n",
    "    first_linear.weight.requires_grad = True\n",
    "    first_linear.bias.requires_grad   = True  \n",
    "\n",
    "    learn_idx = {\n",
    "        'M': -3,\n",
    "        'D': -2,\n",
    "        'H': -1\n",
    "    }\n",
    "\n",
    "    mask_w = torch.zeros_like(first_linear.weight)\n",
    "    for ta in Target_Domain:\n",
    "        mask_w[:, learn_idx[ta]] = 1.0\n",
    "\n",
    "    mask_b = torch.zeros_like(first_linear.bias)\n",
    "    for ta in Target_Domain:\n",
    "        mask_b[learn_idx[ta]] = 1.0\n",
    "\n",
    "    def grad_hook_weight(grad):\n",
    "        return grad * mask_w\n",
    "\n",
    "    def grad_hook_bias(grad):\n",
    "        return grad * mask_b\n",
    "\n",
    "    h1 = first_linear.weight.register_hook(grad_hook_weight)\n",
    "    h2 = first_linear.bias.register_hook(grad_hook_bias)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [p for p in trained_model.parameters() if p.requires_grad],\n",
    "        lr=lr,\n",
    "        weight_decay=0.0 \n",
    "    )\n",
    "    \n",
    "    X_ta_tn, X_ta_te, y_ta_tn, y_ta_te = Even_Split(X_ta, y_ta, Source_Domain, 8/9, rs)\n",
    "    X_ta_tr, X_ta_va, y_ta_tr, y_ta_va = Even_Split(X_ta_tn, y_ta_tn, Source_Domain, 1/6, rs)\n",
    "\n",
    "    X_ta_tr_std  = std_scaler.transform(X_ta_tr)\n",
    "    X_ta_val_std = std_scaler.transform(X_ta_va)\n",
    "    X_ta_te_std  = std_scaler.transform(X_ta_te)\n",
    "\n",
    "    X_ta_train = torch.Tensor(X_ta_tr_std)\n",
    "    X_ta_val   = torch.Tensor(X_ta_val_std)\n",
    "    X_ta_test  = torch.Tensor(X_ta_te_std)\n",
    "    \n",
    "    y_ta_train = torch.Tensor(y_ta_tr[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_ta_val   = torch.Tensor(y_ta_va[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_ta_test  = torch.Tensor(y_ta_te[\"Next_SOH\"].values).unsqueeze(1)\n",
    "\n",
    "    next_ta_train = get_next(X_ta_tr.index)\n",
    "    next_ta_val   = get_next(X_ta_va.index)\n",
    "    next_ta_test  = get_next(X_ta_te.index)\n",
    "\n",
    "    train_ta_loader = DataLoader(TensorDataset(X_ta_train, next_ta_train, y_ta_train), batch_size=bs, shuffle=True)\n",
    "    val_ta_loader   = DataLoader(TensorDataset(X_ta_val, next_ta_val, y_ta_val), batch_size=bs, shuffle = False)\n",
    "    test_ta_loader  = DataLoader(TensorDataset(X_ta_test, next_ta_test, y_ta_test), batch_size=bs, shuffle = False)\n",
    "\n",
    "    trainer = Trainer(trained_model, lr=lr, epoch = ep, random_seed = rs, optimizer = optimizer)\n",
    "    \n",
    "    trainer.train(train_ta_loader, val_ta_loader, test_ta_loader)\n",
    "\n",
    "    info = [rs, hid, nl, lr]\n",
    "\n",
    "    results_Ta = plot_results(info, train_ta_loader, val_ta_loader, test_ta_loader, plot = False)\n",
    "    results_Sc = plot_results(info, train_loader, val_loader, test_loader, plot = False)\n",
    "\n",
    "    temp_df_Ta = pd.DataFrame(info+list(results_Ta)).T\n",
    "    temp_df_Sc = pd.DataFrame(info+list(results_Sc)).T\n",
    "\n",
    "    temp_df_Ta.columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']\n",
    "    temp_df_Sc.columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']\n",
    "\n",
    "    results_df_Ta = pd.concat([results_df_Ta, temp_df_Ta])\n",
    "    results_df_Sc = pd.concat([results_df_Sc, temp_df_Sc])\n",
    "\n",
    "    h1.remove()\n",
    "    h2.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3531aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hid</th>\n",
       "      <th>nl</th>\n",
       "      <th>lr</th>\n",
       "      <th>Train MAPE</th>\n",
       "      <th>Val MAPE</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Next M MAPE</th>\n",
       "      <th>Next D MAPE</th>\n",
       "      <th>Next H MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.791226</td>\n",
       "      <td>1.032762</td>\n",
       "      <td>1.002903</td>\n",
       "      <td>1.109206</td>\n",
       "      <td>0.896601</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hid   nl     lr  Train MAPE  Val MAPE  Test MAPE  Next M MAPE  \\\n",
       "0  16.0  6.0  0.001    0.791226  1.032762   1.002903     1.109206   \n",
       "\n",
       "   Next D MAPE  Next H MAPE  \n",
       "0     0.896601          NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hid</th>\n",
       "      <th>nl</th>\n",
       "      <th>lr</th>\n",
       "      <th>Train MAPE</th>\n",
       "      <th>Val MAPE</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Next M MAPE</th>\n",
       "      <th>Next D MAPE</th>\n",
       "      <th>Next H MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.63757</td>\n",
       "      <td>0.897319</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hid   nl     lr  Train MAPE  Val MAPE  Test MAPE  Next M MAPE  \\\n",
       "0  16.0  6.0  0.001     0.63757  0.897319   0.999066          NaN   \n",
       "\n",
       "   Next D MAPE  Next H MAPE  \n",
       "0          NaN     0.999066  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df_Ta = results_df_Ta.groupby(['hid', 'nl', 'lr'])[['Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']].mean().reset_index()\n",
    "summary_df_Sc = results_df_Sc.groupby(['hid', 'nl', 'lr'])[['Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']].mean().reset_index()\n",
    "\n",
    "summary_df_Sc\n",
    "summary_df_Ta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
