{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f777b66-b5ce-4b51-a260-0f95e8c9dc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ansh\\AppData\\Local\\anaconda3\\envs\\BMS\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from numpy import hstack, vstack\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c268bd1-67cb-4cfb-842e-0bd9f4e75302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Ansh\\\\Desktop\\\\MEST\\\\HMG3\\\\Revision\\\\Rapid_fin\\\\deep learning modeling'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_directory(foldername, filename = None, back_num = 0):\n",
    "    cur = os.getcwd()\n",
    "    for i in range(back_num):\n",
    "        cur = os.path.abspath(os.path.join(cur, os.pardir))\n",
    "    for folder in foldername:\n",
    "        cur = os.path.join(cur, folder)\n",
    "    if not os.path.exists(cur):\n",
    "        os.makedirs(cur)\n",
    "        print(f'{cur} created')\n",
    "    if filename != None:\n",
    "        cur = os.path.join(cur, filename)\n",
    "    return cur\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e19cef-7f59-4f9c-a102-bce664fb00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_add = find_directory(foldername = [], filename = 'SOC_Point_Data.csv')\n",
    "dat_piov = pd.read_csv(csv_add, index_col = (0,1,2,3,4))\n",
    "dat_dcir = pd.read_csv('SOC_Point_DCIR_Data.csv', index_col = (0,1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51190277-29e5-4a99-bb89-b99b751c7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Data(dat) :\n",
    "    \n",
    "    RPT_MODE = \"0.1C\"\n",
    "    SOC_Range = [9,10,11,12]\n",
    "\n",
    "    Time_Range = range(6, 15, 2)\n",
    "    SOC_Range = [str(i) for i in SOC_Range]\n",
    "    \n",
    "\n",
    "    Data = dat\n",
    "\n",
    "    X = Data.loc[RPT_MODE, \"0\" : \"16\"]\n",
    "    Y = Data.loc[RPT_MODE, [\"SOH\", \"Next_SOH\", \"Ratio_SOH\", \"Ratio_CYC\"]].groupby(level = [\"Next\", \"Path\", \"Number\"]).mean()\n",
    "    \n",
    "    y = pd.Series(Y[\"Next_SOH\"] - Y[\"SOH\"], name = \"Delta_SOH\")\n",
    "    \n",
    "    Y = pd.concat([Y, y], axis = 1)\n",
    "\n",
    "    X_seek = X.loc[X.index.get_level_values(\"Time\").isin(Time_Range), SOC_Range]\n",
    "\n",
    "\n",
    "    X_std = X_seek.groupby(level = [\"Next\", \"Path\", \"Number\"]).std()\n",
    "    \n",
    "    return X_std, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f468718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Data2(dat) :\n",
    "    \n",
    "    RPT_MODE = \"0.1C\"\n",
    "    SOC_Range = [9,10,11,12]\n",
    "\n",
    "    SOC_Range = [str(i) for i in SOC_Range]\n",
    "    \n",
    "    Data = dat\n",
    "\n",
    "    X = Data.loc[RPT_MODE, \"0\" : \"16\"]\n",
    "    Y = Data.loc[RPT_MODE, [\"SOH\", \"Next_SOH\", \"Ratio_SOH\", \"Ratio_CYC\"]].groupby(level = [\"Next\", \"Path\", \"Number\"]).mean()\n",
    "    \n",
    "    y = pd.Series(Y[\"Next_SOH\"] - Y[\"SOH\"], name = \"Delta_SOH\")\n",
    "    \n",
    "    Y = pd.concat([Y, y], axis = 1)\n",
    "\n",
    "    X_seek = X.loc[:, SOC_Range]\n",
    "    \n",
    "    return X_seek, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19cdfd1a-dfb7-4066-ab61-9ef975b8d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Even_Split(X, y, test_size, rs) :\n",
    "\n",
    "    X_M = X.xs(key = 'M', level = 'Next', drop_level = False)\n",
    "    X_D = X.xs(key = 'D', level = 'Next', drop_level = False)\n",
    "    X_H = X.xs(key = 'H', level = 'Next', drop_level = False)\n",
    "    \n",
    "    XX = {\"M\" : X_M, \"D\" : X_D, \"H\" : X_H}\n",
    "    \n",
    "    y_M = y.xs(key = 'M', level = 'Next', drop_level = False)\n",
    "    y_D = y.xs(key = 'D', level = 'Next', drop_level = False)\n",
    "    y_H = y.xs(key = 'H', level = 'Next', drop_level = False)\n",
    "    \n",
    "    yy = {\"M\" : y_M, \"D\" : y_D, \"H\" : y_H}\n",
    "    \n",
    "    \n",
    "    XXX = {\"M\" : [], \"D\" : [], \"H\" : []}\n",
    "    \n",
    "    yyy = {\"M\" : [], \"D\" : [], \"H\" : []}\n",
    "    \n",
    "    \n",
    "    for n in [\"M\", \"D\", \"H\"] :\n",
    "        for path in range(1,5) :\n",
    "            X_path = XX[n].loc[XX[n].index.get_level_values(level = 'Path').str.len() == path]\n",
    "            y_path = yy[n].loc[yy[n].index.get_level_values(level = 'Path').str.len() == path]\n",
    "            \n",
    "            XXX[n].append(X_path)\n",
    "            yyy[n].append(y_path)\n",
    "            \n",
    "            \n",
    "    XX_tn = {\"M\" : [], \"D\" : [], \"H\" : []}\n",
    "    XX_te = {\"M\" : [], \"D\" : [], \"H\" : []}\n",
    "    \n",
    "    yy_tn = {\"M\" : [], \"D\" : [], \"H\" : []}\n",
    "    yy_te = {\"M\" : [], \"D\" : [], \"H\" : []}\n",
    "        \n",
    "    for n in [\"M\", \"D\", \"H\"] :\n",
    "        for path in range(1,5) :\n",
    "            X_temp = XXX[n][path-1]\n",
    "            y_temp = yyy[n][path-1]\n",
    "            \n",
    "            X_tn, X_te, y_tn, y_te = train_test_split(X_temp, y_temp, test_size = test_size, random_state = rs)\n",
    "            \n",
    "            XX_tn[n].append(X_tn)\n",
    "            XX_te[n].append(X_te)\n",
    "            yy_tn[n].append(y_tn)\n",
    "            yy_te[n].append(y_te)\n",
    "                  \n",
    "    for n in [\"M\", \"D\", \"H\"] :\n",
    "        XX_tn[n] = pd.concat(XX_tn[n])\n",
    "        XX_te[n] = pd.concat(XX_te[n])\n",
    "        yy_tn[n] = pd.concat(yy_tn[n])\n",
    "        yy_te[n] = pd.concat(yy_te[n])\n",
    "        \n",
    "        \n",
    "    X_tn = pd.concat(XX_tn.values())\n",
    "    X_te = pd.concat(XX_te.values())\n",
    "    \n",
    "    y_tn = pd.concat(yy_tn.values())\n",
    "    y_te = pd.concat(yy_te.values())\n",
    "    \n",
    "    return X_tn, X_te, y_tn, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f240b499-f460-4d4d-a641-1427605d59ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_tensor(index_list):\n",
    "    next_mapping = {'M': 0, 'D': 1, 'H': 2}\n",
    "    next_index = [next_mapping[idx[0]] for idx in index_list] \n",
    "    next_tensor = torch.tensor(next_index)\n",
    "    one_hot = torch.nn.functional.one_hot(next_tensor, num_classes=3).float()\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f614def-b4a4-481d-835c-7798c2ac0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setRandomSeed(random_seed=0):\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96bcfdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred, eps=1e-7):\n",
    "    y_true = np.asarray(y_true, float)\n",
    "    y_pred = np.asarray(y_pred, float)\n",
    "    mask = np.abs(y_true) > eps\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "def mape_by_next(y_true, y_pred, next_labels):\n",
    "    out = {}\n",
    "    for k in ['M', 'D', 'H']:\n",
    "        m = (next_labels == k)\n",
    "        out[k] = mape(y_true[m], y_pred[m])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c6ff2bf-41cc-4b6a-9773-02ee2dbbf98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(\n",
    "    columns = ['rs', 'kernel', 'C', 'gamma', 'epsilon',\n",
    "               'Train MAPE', 'Val MAPE', 'Test MAPE',\n",
    "               'Next M MAPE', 'Next D MAPE', 'Next H MAPE']\n",
    ")\n",
    "\n",
    "random_states = [100, 120, 140, 160, 180]\n",
    "kernels = ['rbf', 'linear']\n",
    "Cs = [0.1, 0.5, 1, 5, 10, 100]\n",
    "gammas = ['scale', 0.01, 0.1]\n",
    "epsilons = [0.05, 0.1, 0.2]\n",
    "\n",
    "X_PIOV, y = Get_Data(dat_piov)\n",
    "X_DCIR, y = Get_Data2(dat_dcir)\n",
    "\n",
    "\n",
    "X_DCIR = X_DCIR.reindex(X_PIOV.index)\n",
    "\n",
    "X_DCIR_max = X_DCIR.max(axis=1)\n",
    "X_DCIR_max.name = 'DCIR'\n",
    "\n",
    "y = y.reindex(X_PIOV.index)\n",
    "\n",
    "X = pd.concat([X_PIOV, X_DCIR_max], axis = 1)\n",
    "\n",
    "next_map = {'M': 0, 'D': 1, 'H': 2}\n",
    "def get_next(idx):\n",
    "    labels = np.array([next_map[i] for i in idx.get_level_values(\"Next\")])\n",
    "    onehot = np.eye(3, dtype=float)[labels]\n",
    "    return onehot\n",
    "\n",
    "for rs, kernel, C, gamma, eps in product(random_states, kernels, Cs, gammas, epsilons):\n",
    "    setRandomSeed(rs)\n",
    "\n",
    "    X_tn, X_te, y_tn, y_te = Even_Split(X, y, 1/3, rs)\n",
    "    X_tr, X_va, y_tr, y_va = Even_Split(X_tn, y_tn, 1/6, rs)\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "    X_tr_std  = std_scaler.fit_transform(X_tr)\n",
    "    X_val_std = std_scaler.transform(X_va)\n",
    "    X_te_std  = std_scaler.transform(X_te)\n",
    "\n",
    "    next_train = get_next(X_tr.index)\n",
    "    next_val   = get_next(X_va.index)\n",
    "    next_test  = get_next(X_te.index)\n",
    "\n",
    "    X_train = np.concatenate([X_tr_std, next_train], axis=1)\n",
    "    X_val   = np.concatenate([X_val_std, next_val], axis=1)\n",
    "    X_test  = np.concatenate([X_te_std, next_test], axis=1)\n",
    "\n",
    "    y_train_raw = y_tr[\"Next_SOH\"].values.reshape(-1, 1)\n",
    "    y_val_raw   = y_va[\"Next_SOH\"].values.reshape(-1, 1)\n",
    "    y_test_raw  = y_te[\"Next_SOH\"].values.reshape(-1, 1)\n",
    "\n",
    "    y_scaler = StandardScaler()\n",
    "    y_train = y_scaler.fit_transform(y_train_raw).ravel()\n",
    "    y_val   = y_scaler.transform(y_val_raw).ravel()\n",
    "    y_test  = y_scaler.transform(y_test_raw).ravel()\n",
    "\n",
    "\n",
    "    svr = SVR(kernel=kernel, C=C, gamma=gamma, epsilon=eps, cache_size=2000)\n",
    "\n",
    "    _ = svr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_tr = y_scaler.inverse_transform(svr.predict(X_train).reshape(-1,1)).ravel()\n",
    "    y_pred_va = y_scaler.inverse_transform(svr.predict(X_val).reshape(-1,1)).ravel()\n",
    "    y_pred_te = y_scaler.inverse_transform(svr.predict(X_test).reshape(-1,1)).ravel()\n",
    "\n",
    "    train_mape = mape(y_train_raw.ravel(), y_pred_tr)\n",
    "    val_mape   = mape(y_val_raw.ravel(), y_pred_va)\n",
    "    test_mape  = mape(y_test_raw.ravel(), y_pred_te)\n",
    "\n",
    "    next_test_labels = X_te.index.get_level_values(\"Next\").to_numpy()\n",
    "    by_next = mape_by_next(y_test_raw.ravel(), y_pred_te, next_test_labels)\n",
    "\n",
    "    row = [rs, kernel, C, gamma, eps,\n",
    "           train_mape, val_mape, test_mape,\n",
    "           by_next['M'], by_next['D'], by_next['H']]\n",
    "\n",
    "    results_df = pd.concat(\n",
    "        [results_df, pd.DataFrame([row], columns=results_df.columns)],\n",
    "        ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4819d6c3-d539-4de0-9e83-ed6af617fa12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>Train MAPE</th>\n",
       "      <th>Val MAPE</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Next M MAPE</th>\n",
       "      <th>Next D MAPE</th>\n",
       "      <th>Next H MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.865229</td>\n",
       "      <td>0.920573</td>\n",
       "      <td>0.895593</td>\n",
       "      <td>0.985511</td>\n",
       "      <td>0.821578</td>\n",
       "      <td>0.879689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.868862</td>\n",
       "      <td>0.912235</td>\n",
       "      <td>0.883079</td>\n",
       "      <td>0.971579</td>\n",
       "      <td>0.809400</td>\n",
       "      <td>0.868258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.871139</td>\n",
       "      <td>0.914279</td>\n",
       "      <td>0.877951</td>\n",
       "      <td>0.962591</td>\n",
       "      <td>0.803912</td>\n",
       "      <td>0.867349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.865229</td>\n",
       "      <td>0.920573</td>\n",
       "      <td>0.895593</td>\n",
       "      <td>0.985511</td>\n",
       "      <td>0.821578</td>\n",
       "      <td>0.879689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.868862</td>\n",
       "      <td>0.912235</td>\n",
       "      <td>0.883079</td>\n",
       "      <td>0.971579</td>\n",
       "      <td>0.809400</td>\n",
       "      <td>0.868258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.498488</td>\n",
       "      <td>0.902003</td>\n",
       "      <td>0.906661</td>\n",
       "      <td>1.136023</td>\n",
       "      <td>0.741339</td>\n",
       "      <td>0.842620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.555893</td>\n",
       "      <td>0.867655</td>\n",
       "      <td>0.897455</td>\n",
       "      <td>1.131706</td>\n",
       "      <td>0.720584</td>\n",
       "      <td>0.840075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.365732</td>\n",
       "      <td>0.960396</td>\n",
       "      <td>0.966888</td>\n",
       "      <td>1.191154</td>\n",
       "      <td>0.838298</td>\n",
       "      <td>0.871212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.407059</td>\n",
       "      <td>0.950273</td>\n",
       "      <td>0.958502</td>\n",
       "      <td>1.173581</td>\n",
       "      <td>0.827576</td>\n",
       "      <td>0.874349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.493712</td>\n",
       "      <td>0.925968</td>\n",
       "      <td>0.961516</td>\n",
       "      <td>1.165417</td>\n",
       "      <td>0.840680</td>\n",
       "      <td>0.878449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     kernel      C  gamma  epsilon  Train MAPE  Val MAPE  Test MAPE  \\\n",
       "0    linear    0.1   0.01     0.05    0.865229  0.920573   0.895593   \n",
       "1    linear    0.1   0.01     0.10    0.868862  0.912235   0.883079   \n",
       "2    linear    0.1   0.01     0.20    0.871139  0.914279   0.877951   \n",
       "3    linear    0.1    0.1     0.05    0.865229  0.920573   0.895593   \n",
       "4    linear    0.1    0.1     0.10    0.868862  0.912235   0.883079   \n",
       "..      ...    ...    ...      ...         ...       ...        ...   \n",
       "103     rbf  100.0    0.1     0.10    0.498488  0.902003   0.906661   \n",
       "104     rbf  100.0    0.1     0.20    0.555893  0.867655   0.897455   \n",
       "105     rbf  100.0  scale     0.05    0.365732  0.960396   0.966888   \n",
       "106     rbf  100.0  scale     0.10    0.407059  0.950273   0.958502   \n",
       "107     rbf  100.0  scale     0.20    0.493712  0.925968   0.961516   \n",
       "\n",
       "     Next M MAPE  Next D MAPE  Next H MAPE  \n",
       "0       0.985511     0.821578     0.879689  \n",
       "1       0.971579     0.809400     0.868258  \n",
       "2       0.962591     0.803912     0.867349  \n",
       "3       0.985511     0.821578     0.879689  \n",
       "4       0.971579     0.809400     0.868258  \n",
       "..           ...          ...          ...  \n",
       "103     1.136023     0.741339     0.842620  \n",
       "104     1.131706     0.720584     0.840075  \n",
       "105     1.191154     0.838298     0.871212  \n",
       "106     1.173581     0.827576     0.874349  \n",
       "107     1.165417     0.840680     0.878449  \n",
       "\n",
       "[108 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = results_df.groupby(['kernel', 'C', 'gamma', 'epsilon'])[['Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']].mean().reset_index()\n",
    "summary_df\n",
    "summary_df.to_csv('SVM_COM_DCIR_next_info_sum.csv')\n",
    "results_df.to_csv('SVM_COM_DCIR_next_info.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
