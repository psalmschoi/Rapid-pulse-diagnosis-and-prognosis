{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f777b66-b5ce-4b51-a260-0f95e8c9dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from numpy import hstack, vstack\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c268bd1-67cb-4cfb-842e-0bd9f4e75302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dkstj\\\\Desktop\\\\연구\\\\현대차 3차\\\\Rapid_fin\\\\deep learning modeling'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_directory(foldername, filename = None, back_num = 0):\n",
    "    cur = os.getcwd()\n",
    "    for i in range(back_num):\n",
    "        cur = os.path.abspath(os.path.join(cur, os.pardir))\n",
    "    for folder in foldername:\n",
    "        cur = os.path.join(cur, folder)\n",
    "    if not os.path.exists(cur):\n",
    "        os.makedirs(cur)\n",
    "        print(f'{cur} created')\n",
    "    if filename != None:\n",
    "        cur = os.path.join(cur, filename)\n",
    "    return cur\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58e19cef-7f59-4f9c-a102-bce664fb00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_add = find_directory(foldername = [], filename = 'SOC_Point_Data.csv')\n",
    "dat = pd.read_csv(csv_add, index_col = (0,1,2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51190277-29e5-4a99-bb89-b99b751c7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Data(dat) :\n",
    "    \n",
    "    RPT_MODE = \"0.1C\"\n",
    "    SOC_Range = [9,10,11,12]\n",
    "\n",
    "    Time_Range = range(6, 15, 2)\n",
    "    SOC_Range = [str(i) for i in SOC_Range]\n",
    "    \n",
    "\n",
    "    Data = dat\n",
    "\n",
    "    X = Data.loc[RPT_MODE, \"0\" : \"16\"]\n",
    "    Y = Data.loc[RPT_MODE, [\"SOH\", \"Next_SOH\", \"Ratio_SOH\", \"Ratio_CYC\"]].groupby(level = [\"Next\", \"Path\", \"Number\"]).mean()\n",
    "    \n",
    "    y = pd.Series(Y[\"Next_SOH\"] - Y[\"SOH\"], name = \"Delta_SOH\")\n",
    "    \n",
    "    Y = pd.concat([Y, y], axis = 1)\n",
    "\n",
    "    X_seek = X.loc[X.index.get_level_values(\"Time\").isin(Time_Range), SOC_Range]\n",
    "\n",
    "\n",
    "    X_std = X_seek.groupby(level = [\"Next\", \"Path\", \"Number\"]).std()\n",
    "    \n",
    "    return X_std, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19cdfd1a-dfb7-4066-ab61-9ef975b8d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Even_Split(X, y, no_next, test_size, rs) :\n",
    "\n",
    "    Nexts = [n for n in ['M', 'D', 'H'] if n not in no_next]\n",
    "\n",
    "    XX = {n: X.xs(key = n, level = 'Next', drop_level = False) for n in Nexts}\n",
    "    yy = {n: y.xs(key = n, level = 'Next', drop_level = False) for n in Nexts}\n",
    "    \n",
    "    \n",
    "    XXX = {n: [] for n in Nexts}\n",
    "    yyy = {n: [] for n in Nexts}\n",
    "    \n",
    "    \n",
    "    for n in Nexts:\n",
    "        for path in range(1,5) :\n",
    "            X_path = XX[n].loc[XX[n].index.get_level_values(level = 'Path').str.len() == path]\n",
    "            y_path = yy[n].loc[yy[n].index.get_level_values(level = 'Path').str.len() == path]\n",
    "            \n",
    "            XXX[n].append(X_path)\n",
    "            yyy[n].append(y_path)\n",
    "            \n",
    "            \n",
    "    XX_tn = {n: [] for n in Nexts}\n",
    "    XX_te = {n: [] for n in Nexts}\n",
    "    \n",
    "    yy_tn = {n: [] for n in Nexts}\n",
    "    yy_te = {n: [] for n in Nexts}\n",
    "        \n",
    "    for n in Nexts :\n",
    "        for path in range(1,5) :\n",
    "            X_temp = XXX[n][path-1]\n",
    "            y_temp = yyy[n][path-1]\n",
    "            \n",
    "            X_tn, X_te, y_tn, y_te = train_test_split(X_temp, y_temp, test_size = test_size, random_state = rs)\n",
    "            \n",
    "            XX_tn[n].append(X_tn)\n",
    "            XX_te[n].append(X_te)\n",
    "            yy_tn[n].append(y_tn)\n",
    "            yy_te[n].append(y_te)\n",
    "                  \n",
    "    for n in Nexts :\n",
    "        XX_tn[n] = pd.concat(XX_tn[n])\n",
    "        XX_te[n] = pd.concat(XX_te[n])\n",
    "        yy_tn[n] = pd.concat(yy_tn[n])\n",
    "        yy_te[n] = pd.concat(yy_te[n])\n",
    "        \n",
    "        \n",
    "    X_tn = pd.concat(XX_tn.values())\n",
    "    X_te = pd.concat(XX_te.values())\n",
    "    \n",
    "    y_tn = pd.concat(yy_tn.values())\n",
    "    y_te = pd.concat(yy_te.values())\n",
    "    \n",
    "    return X_tn, X_te, y_tn, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "982efbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Domain_Split(X, y, test_domain):\n",
    "    X_M = X.xs(key = 'M', level = 'Next', drop_level = False)\n",
    "    X_D = X.xs(key = 'D', level = 'Next', drop_level = False)\n",
    "    X_H = X.xs(key = 'H', level = 'Next', drop_level = False)\n",
    "    \n",
    "    XX = {\"M\" : X_M, \"D\" : X_D, \"H\" : X_H}\n",
    "    \n",
    "    y_M = y.xs(key = 'M', level = 'Next', drop_level = False)\n",
    "    y_D = y.xs(key = 'D', level = 'Next', drop_level = False)\n",
    "    y_H = y.xs(key = 'H', level = 'Next', drop_level = False)\n",
    "    \n",
    "    yy = {\"M\" : y_M, \"D\" : y_D, \"H\" : y_H}\n",
    "    \n",
    "    \n",
    "    X_tn = pd.concat([XX[n] for n in ['M', 'D', 'H'] if n not in test_domain])\n",
    "    X_te = pd.concat([XX[n] for n in ['M', 'D', 'H'] if n in test_domain])\n",
    "\n",
    "    y_tn = pd.concat([yy[n] for n in ['M', 'D', 'H'] if n not in test_domain])\n",
    "    y_te = pd.concat([yy[n] for n in ['M', 'D', 'H'] if n in test_domain])\n",
    "    \n",
    "    return X_tn, X_te, y_tn, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f240b499-f460-4d4d-a641-1427605d59ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_tensor(index_list):\n",
    "    next_mapping = {'M': 0, 'D': 1, 'H': 2}\n",
    "    next_index = [next_mapping[idx[0]] for idx in index_list] \n",
    "    next_tensor = torch.tensor(next_index)\n",
    "    one_hot = torch.nn.functional.one_hot(next_tensor, num_classes=3).float()\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f614def-b4a4-481d-835c-7798c2ac0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setRandomSeed(random_seed=0):\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ab81703-2c07-484c-910f-12d4e46abdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, num_layers=2, next_dim = 3):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        input_dim = 4 + next_dim\n",
    "        output_dim = 1\n",
    "\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, onehot):\n",
    "        x_concat = torch.cat([x, onehot], dim=1)\n",
    "        return self.model(x_concat)\n",
    "\n",
    "class MAPELoss(nn.Module):\n",
    "    def __init__(self, epsilon=1e-7):\n",
    "        super(MAPELoss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.mean(torch.abs((y_true - y_pred) / (y_true + self.epsilon))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a7a5600-ca48-42b9-a7d4-91ae59a8b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, lr=1e-3, weight_decay=0, epoch=1000, patience=50, random_seed = 0, optimizer = None):\n",
    "        self.random_seed = random_seed\n",
    "        #setRandomSeed(self.random_seed)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.cri2 = MAPELoss()\n",
    "        if optimizer is None:\n",
    "            self.optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        else:\n",
    "            self.optimizer = optimizer\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=200, gamma=0.8)\n",
    "        self.epoch = epoch\n",
    "        self.patience = patience\n",
    "\n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def train(self, train_loader, test_loader=None, val_loader=None):\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_state = None\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        for ep in range(1, self.epoch + 1):\n",
    "            self.model.train()\n",
    "            for x_batch, onehot, y_batch in train_loader:\n",
    "                x_batch, onehot, y_batch = x_batch.to(self.device), onehot.to(self.device), y_batch.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(x_batch, onehot)\n",
    "                loss = self.cri2(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            self.scheduler.step()\n",
    "\n",
    "            avg_train_loss = self.evaluate(train_loader)\n",
    "            test_loss = self.evaluate(test_loader) if test_loader else None\n",
    "            val_loss = self.evaluate(val_loader) if val_loader else None\n",
    "\n",
    "            self.train_loss.append(avg_train_loss)\n",
    "            self.test_loss.append(test_loss)\n",
    "            self.val_loss.append(val_loss)\n",
    "\n",
    "            if val_loader:\n",
    "                if val_loss < best_val_loss - 1e-4:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_model_state = self.model.state_dict()\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    if epochs_no_improve >= self.patience:\n",
    "                        print(f\"Early stopping at epoch {ep}\")\n",
    "                        break\n",
    "\n",
    "        if best_model_state:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        if data_loader is None:\n",
    "            return None\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, onehot, y_batch in data_loader:\n",
    "                x_batch, onehot, y_batch = x_batch.to(self.device), onehot.to(self.device), y_batch.to(self.device)\n",
    "                outputs = self.model(x_batch, onehot)\n",
    "                loss = self.cri2(outputs, y_batch)\n",
    "                total_loss += loss.item()\n",
    "        return total_loss / len(data_loader)\n",
    "\n",
    "    def predict(self, x, onehot):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = x.to(self.device)\n",
    "            onehot = onehot.to(self.device)\n",
    "            return self.model(x, onehot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9feefaab-7522-4dfb-8e3d-64e935acdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(info, train_loader, val_loader, test_loader, plot = True):\n",
    "    rs, hid, nl, lr = info\n",
    "    \n",
    "    y_true_train = []\n",
    "    y_pred_train = []\n",
    "    \n",
    "    y_true_val = []\n",
    "    y_pred_val = []\n",
    "    \n",
    "    y_true_test = []\n",
    "    y_pred_test = []\n",
    "\n",
    "    y_true_test_M = []\n",
    "    y_pred_test_M = []\n",
    "\n",
    "    y_true_test_D = []\n",
    "    y_pred_test_D = []\n",
    "\n",
    "    y_true_test_H = []\n",
    "    y_pred_test_H = []\n",
    "    \n",
    "    for x_batch, onehot, y_batch in train_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_train.append(y_batch)\n",
    "        y_pred_train.append(preds.cpu())\n",
    "    \n",
    "    for x_batch, onehot, y_batch in val_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_val.append(y_batch)\n",
    "        y_pred_val.append(preds.cpu())\n",
    "    \n",
    "    for x_batch, onehot, y_batch in test_loader:\n",
    "        preds = trainer.predict(x_batch, onehot)\n",
    "        y_true_test.append(y_batch)\n",
    "        y_pred_test.append(preds.cpu())\n",
    "    \n",
    "        onehot_np = onehot.cpu().numpy()\n",
    "        y_true_np = y_batch.cpu().numpy()\n",
    "        y_pred_np = preds.cpu().numpy()\n",
    "    \n",
    "        for i in range(len(onehot_np)):\n",
    "            if np.array_equal(onehot_np[i], [1, 0, 0]):  # 'M'\n",
    "                y_true_test_M.append(y_true_np[i])\n",
    "                y_pred_test_M.append(y_pred_np[i])\n",
    "            elif np.array_equal(onehot_np[i], [0, 1, 0]):  # 'D'\n",
    "                y_true_test_D.append(y_true_np[i])\n",
    "                y_pred_test_D.append(y_pred_np[i])\n",
    "            elif np.array_equal(onehot_np[i], [0, 0, 1]):  # 'H'\n",
    "                y_true_test_H.append(y_true_np[i])\n",
    "                y_pred_test_H.append(y_pred_np[i])\n",
    "    \n",
    "    y_true_train = torch.cat(y_true_train).numpy()\n",
    "    y_pred_train = torch.cat(y_pred_train).numpy()\n",
    "    \n",
    "    y_true_val = torch.cat(y_true_val).numpy()\n",
    "    y_pred_val = torch.cat(y_pred_val).numpy()\n",
    "    \n",
    "    y_true_test = torch.cat(y_true_test).numpy()\n",
    "    y_pred_test = torch.cat(y_pred_test).numpy()\n",
    "\n",
    "    y_true_test_M = np.array(y_true_test_M)\n",
    "    y_pred_test_M = np.array(y_pred_test_M)\n",
    "    \n",
    "    y_true_test_D = np.array(y_true_test_D)\n",
    "    y_pred_test_D = np.array(y_pred_test_D)\n",
    "    \n",
    "    y_true_test_H = np.array(y_true_test_H)\n",
    "    y_pred_test_H = np.array(y_pred_test_H)\n",
    "    \n",
    "    mape_M = mean_absolute_percentage_error(y_true_test_M, y_pred_test_M) * 100 if len(y_true_test_M) > 0 else np.nan\n",
    "    mape_D = mean_absolute_percentage_error(y_true_test_D, y_pred_test_D) * 100 if len(y_true_test_D) > 0 else np.nan\n",
    "    mape_H = mean_absolute_percentage_error(y_true_test_H, y_pred_test_H) * 100 if len(y_true_test_H) > 0 else np.nan\n",
    "    \n",
    "    train_mape = mean_absolute_percentage_error(y_true_train, y_pred_train) * 100\n",
    "    val_mape = mean_absolute_percentage_error(y_true_val, y_pred_val) * 100\n",
    "    test_mape = mean_absolute_percentage_error(y_true_test, y_pred_test) * 100\n",
    "    print(f\"Rs: {rs}, hid: {hid}, {nl} layers, lr: {lr}\\n Train MAPE: {train_mape:.2f}%, Val MAPE: {val_mape:.2f}%, Test MAPE: {test_mape:.2f}%\")\n",
    "    print(f\"Test MAPE by 'Next': M: {mape_M:.2f}%, D: {mape_D:.2f}%, H: {mape_H:.2f}%\")\n",
    "    if plot == True:\n",
    "        _ = plt.figure()\n",
    "        _ = plt.scatter(y_true_train, y_pred_train, label = 'Train')\n",
    "        _ = plt.scatter(y_true_val, y_pred_val, label = 'Val')\n",
    "        _ = plt.scatter(y_true_test, y_pred_test, label = 'Test')\n",
    "        min_val = min(y_true_train.min(), y_true_test.min())\n",
    "        max_val = max(y_true_train.max(), y_true_test.max())\n",
    "        _ = plt.plot([min_val, max_val], [min_val, max_val], 'k--', label='Ideal line')\n",
    "        _ = plt.xlabel('True SOH')\n",
    "        _ = plt.ylabel('Predicted SOH')\n",
    "        _ = plt.legend()\n",
    "        _ = plt.title(f'Random state: {rs}, hid: {hid}, {nl} layer, lr: {lr}')\n",
    "    return train_mape, val_mape, test_mape, mape_M, mape_D, mape_H\n",
    "\n",
    "def plot_loss(info, train_loss, val_loss, test_loss):\n",
    "    rs, hid, nl, lr = info\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(train_loss, label = 'Train loss')\n",
    "    _ = plt.plot(val_loss, label = 'Val loss')\n",
    "    _ = plt.plot(test_loss, label = 'Test loss')\n",
    "    _ = plt.ylim([0, 2])\n",
    "    _ = plt.xlabel('Epoch')\n",
    "    _ = plt.ylabel('Loss')\n",
    "    _ = plt.legend()\n",
    "    _ = plt.title(f'Random state: {rs}, hid: {hid}, {nl} layers, lr: {lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c6ff2bf-41cc-4b6a-9773-02ee2dbbf98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 142\n",
      "Rs: 100, hid: 8, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.66%, Val MAPE: 0.97%, Test MAPE: 1.09%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.80%, H: 1.37%\n",
      "Rs: 100, hid: 8, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.73%, Val MAPE: 1.50%, Test MAPE: 1.27%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.77%, H: 1.77%\n",
      "Early stopping at epoch 228\n",
      "Rs: 100, hid: 8, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.61%, Val MAPE: 0.73%, Test MAPE: 0.84%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.72%, H: 0.97%\n",
      "Rs: 100, hid: 8, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.70%, Val MAPE: 1.02%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.81%, H: 1.08%\n",
      "Early stopping at epoch 167\n",
      "Rs: 100, hid: 8, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.78%, Val MAPE: 0.84%, Test MAPE: 0.97%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.01%, H: 0.93%\n",
      "Rs: 100, hid: 8, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.61%, Val MAPE: 0.93%, Test MAPE: 1.26%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.93%, H: 1.59%\n",
      "Early stopping at epoch 257\n",
      "Rs: 100, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.59%, Val MAPE: 0.83%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.82%, H: 1.22%\n",
      "Early stopping at epoch 983\n",
      "Rs: 100, hid: 8, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.65%, Val MAPE: 0.91%, Test MAPE: 1.00%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.78%, H: 1.23%\n",
      "Early stopping at epoch 121\n",
      "Rs: 100, hid: 8, 6 layers, lr: 0.001\n",
      " Train MAPE: 1.71%, Val MAPE: 1.94%, Test MAPE: 1.77%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.81%, H: 1.74%\n",
      "Rs: 100, hid: 8, 6 layers, lr: 0.0001\n",
      " Train MAPE: 2.01%, Val MAPE: 2.32%, Test MAPE: 2.10%\n",
      "Test MAPE by 'Next': M: nan%, D: 2.20%, H: 2.00%\n",
      "Early stopping at epoch 225\n",
      "Rs: 100, hid: 16, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.85%, Val MAPE: 1.06%, Test MAPE: 1.29%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.91%, H: 1.67%\n",
      "Early stopping at epoch 904\n",
      "Rs: 100, hid: 16, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.73%, Val MAPE: 1.24%, Test MAPE: 1.07%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.05%, H: 1.09%\n",
      "Early stopping at epoch 211\n",
      "Rs: 100, hid: 16, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.49%, Val MAPE: 0.97%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.96%, H: 1.10%\n",
      "Early stopping at epoch 662\n",
      "Rs: 100, hid: 16, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.56%, Val MAPE: 0.71%, Test MAPE: 1.23%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.00%, H: 1.46%\n",
      "Early stopping at epoch 227\n",
      "Rs: 100, hid: 16, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.56%, Val MAPE: 0.78%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.90%, H: 1.00%\n",
      "Rs: 100, hid: 16, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.65%, Val MAPE: 0.96%, Test MAPE: 1.20%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.99%, H: 1.41%\n",
      "Early stopping at epoch 116\n",
      "Rs: 100, hid: 16, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.67%, Val MAPE: 1.00%, Test MAPE: 0.82%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.90%, H: 0.74%\n",
      "Early stopping at epoch 656\n",
      "Rs: 100, hid: 16, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.52%, Val MAPE: 0.93%, Test MAPE: 0.85%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.81%, H: 0.90%\n",
      "Early stopping at epoch 215\n",
      "Rs: 100, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.74%, Val MAPE: 1.07%, Test MAPE: 0.91%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.12%, H: 0.69%\n",
      "Rs: 100, hid: 16, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.61%, Val MAPE: 0.83%, Test MAPE: 0.90%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.75%, H: 1.04%\n",
      "Early stopping at epoch 191\n",
      "Rs: 100, hid: 32, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.73%, Val MAPE: 1.17%, Test MAPE: 1.26%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.95%, H: 1.56%\n",
      "Early stopping at epoch 671\n",
      "Rs: 100, hid: 32, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.56%, Val MAPE: 2.10%, Test MAPE: 1.19%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.22%, H: 1.16%\n",
      "Early stopping at epoch 191\n",
      "Rs: 100, hid: 32, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.75%, Val MAPE: 1.35%, Test MAPE: 1.18%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.12%, H: 1.24%\n",
      "Early stopping at epoch 648\n",
      "Rs: 100, hid: 32, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.72%, Val MAPE: 1.96%, Test MAPE: 1.76%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.20%, H: 2.32%\n",
      "Early stopping at epoch 139\n",
      "Rs: 100, hid: 32, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.60%, Val MAPE: 1.30%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.91%, H: 1.15%\n",
      "Early stopping at epoch 243\n",
      "Rs: 100, hid: 32, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.56%, Val MAPE: 1.10%, Test MAPE: 0.99%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.01%, H: 0.97%\n",
      "Early stopping at epoch 164\n",
      "Rs: 100, hid: 32, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.55%, Val MAPE: 1.07%, Test MAPE: 0.92%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.86%, H: 0.98%\n",
      "Early stopping at epoch 234\n",
      "Rs: 100, hid: 32, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.66%, Val MAPE: 1.19%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.08%, H: 0.94%\n",
      "Early stopping at epoch 212\n",
      "Rs: 100, hid: 32, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.50%, Val MAPE: 0.97%, Test MAPE: 0.78%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.81%, H: 0.74%\n",
      "Early stopping at epoch 368\n",
      "Rs: 100, hid: 32, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.62%, Val MAPE: 0.96%, Test MAPE: 0.90%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.88%, H: 0.93%\n",
      "Early stopping at epoch 266\n",
      "Rs: 120, hid: 8, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.67%, Val MAPE: 0.68%, Test MAPE: 0.80%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.79%, H: 0.81%\n",
      "Rs: 120, hid: 8, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.84%, Val MAPE: 0.72%, Test MAPE: 0.87%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.86%, H: 0.88%\n",
      "Early stopping at epoch 186\n",
      "Rs: 120, hid: 8, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.67%, Val MAPE: 0.64%, Test MAPE: 0.71%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.81%, H: 0.60%\n",
      "Rs: 120, hid: 8, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.79%, Val MAPE: 0.60%, Test MAPE: 0.71%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.75%, H: 0.68%\n",
      "Early stopping at epoch 217\n",
      "Rs: 120, hid: 8, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.72%, Val MAPE: 0.72%, Test MAPE: 0.74%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.64%, H: 0.84%\n",
      "Rs: 120, hid: 8, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.83%, Val MAPE: 0.84%, Test MAPE: 0.78%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.65%, H: 0.91%\n",
      "Early stopping at epoch 180\n",
      "Rs: 120, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.63%, Val MAPE: 0.62%, Test MAPE: 0.70%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.75%, H: 0.65%\n",
      "Early stopping at epoch 538\n",
      "Rs: 120, hid: 8, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.87%, Val MAPE: 0.77%, Test MAPE: 0.67%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.73%, H: 0.62%\n",
      "Early stopping at epoch 217\n",
      "Rs: 120, hid: 8, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.83%, Val MAPE: 0.59%, Test MAPE: 0.82%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.69%, H: 0.95%\n",
      "Rs: 120, hid: 8, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.82%, Val MAPE: 0.65%, Test MAPE: 0.82%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.73%, H: 0.90%\n",
      "Early stopping at epoch 117\n",
      "Rs: 120, hid: 16, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.73%, Val MAPE: 0.85%, Test MAPE: 0.85%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.78%, H: 0.92%\n",
      "Early stopping at epoch 947\n",
      "Rs: 120, hid: 16, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.64%, Val MAPE: 0.81%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.91%, H: 0.97%\n",
      "Early stopping at epoch 120\n",
      "Rs: 120, hid: 16, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.67%, Val MAPE: 0.85%, Test MAPE: 1.05%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.08%, H: 1.03%\n",
      "Early stopping at epoch 680\n",
      "Rs: 120, hid: 16, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.55%, Val MAPE: 0.83%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.96%, H: 0.94%\n",
      "Early stopping at epoch 170\n",
      "Rs: 120, hid: 16, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.65%, Val MAPE: 0.69%, Test MAPE: 0.71%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.66%, H: 0.76%\n",
      "Early stopping at epoch 420\n",
      "Rs: 120, hid: 16, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.67%, Val MAPE: 0.73%, Test MAPE: 0.88%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.95%, H: 0.82%\n",
      "Early stopping at epoch 127\n",
      "Rs: 120, hid: 16, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.69%, Val MAPE: 0.82%, Test MAPE: 0.76%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.75%, H: 0.77%\n",
      "Early stopping at epoch 896\n",
      "Rs: 120, hid: 16, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.60%, Val MAPE: 0.71%, Test MAPE: 0.84%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.84%, H: 0.84%\n",
      "Early stopping at epoch 98\n",
      "Rs: 120, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.82%, Val MAPE: 0.76%, Test MAPE: 0.92%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.86%, H: 0.98%\n",
      "Early stopping at epoch 343\n",
      "Rs: 120, hid: 16, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.68%, Val MAPE: 0.66%, Test MAPE: 0.73%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.72%, H: 0.75%\n",
      "Early stopping at epoch 157\n",
      "Rs: 120, hid: 32, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.61%, Val MAPE: 1.10%, Test MAPE: 0.87%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.86%, H: 0.88%\n",
      "Early stopping at epoch 331\n",
      "Rs: 120, hid: 32, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.70%, Val MAPE: 1.05%, Test MAPE: 0.98%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.05%, H: 0.91%\n",
      "Early stopping at epoch 196\n",
      "Rs: 120, hid: 32, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.70%, Val MAPE: 0.83%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.86%, H: 1.02%\n",
      "Early stopping at epoch 411\n",
      "Rs: 120, hid: 32, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.58%, Val MAPE: 0.84%, Test MAPE: 0.79%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.82%, H: 0.75%\n",
      "Early stopping at epoch 183\n",
      "Rs: 120, hid: 32, 4 layers, lr: 0.001\n",
      " Train MAPE: 1.06%, Val MAPE: 1.09%, Test MAPE: 1.13%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.13%, H: 1.13%\n",
      "Early stopping at epoch 305\n",
      "Rs: 120, hid: 32, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.52%, Val MAPE: 0.79%, Test MAPE: 0.71%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.75%, H: 0.67%\n",
      "Early stopping at epoch 170\n",
      "Rs: 120, hid: 32, 5 layers, lr: 0.001\n",
      " Train MAPE: 1.08%, Val MAPE: 1.16%, Test MAPE: 1.13%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.31%, H: 0.95%\n",
      "Early stopping at epoch 445\n",
      "Rs: 120, hid: 32, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.66%, Val MAPE: 0.77%, Test MAPE: 0.88%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.79%, H: 0.96%\n",
      "Early stopping at epoch 133\n",
      "Rs: 120, hid: 32, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.57%, Val MAPE: 0.72%, Test MAPE: 0.82%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.85%, H: 0.79%\n",
      "Early stopping at epoch 281\n",
      "Rs: 120, hid: 32, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.65%, Val MAPE: 0.96%, Test MAPE: 0.78%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.82%, H: 0.74%\n",
      "Early stopping at epoch 305\n",
      "Rs: 140, hid: 8, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.61%, Val MAPE: 0.76%, Test MAPE: 0.81%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.86%, H: 0.77%\n",
      "Early stopping at epoch 998\n",
      "Rs: 140, hid: 8, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.67%, Val MAPE: 0.69%, Test MAPE: 0.99%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.93%, H: 1.06%\n",
      "Early stopping at epoch 145\n",
      "Rs: 140, hid: 8, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.74%, Val MAPE: 0.65%, Test MAPE: 0.89%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.92%, H: 0.86%\n",
      "Rs: 140, hid: 8, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.89%, Val MAPE: 0.71%, Test MAPE: 1.09%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.11%, H: 1.06%\n",
      "Early stopping at epoch 134\n",
      "Rs: 140, hid: 8, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.62%, Val MAPE: 0.78%, Test MAPE: 0.90%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.03%, H: 0.77%\n",
      "Rs: 140, hid: 8, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.68%, Val MAPE: 0.72%, Test MAPE: 0.82%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.88%, H: 0.75%\n",
      "Early stopping at epoch 209\n",
      "Rs: 140, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.63%, Val MAPE: 0.86%, Test MAPE: 0.83%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.98%, H: 0.68%\n",
      "Early stopping at epoch 565\n",
      "Rs: 140, hid: 8, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.76%, Val MAPE: 0.79%, Test MAPE: 0.96%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.02%, H: 0.89%\n",
      "Early stopping at epoch 143\n",
      "Rs: 140, hid: 8, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.81%, Val MAPE: 0.82%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.10%, H: 0.93%\n",
      "Early stopping at epoch 616\n",
      "Rs: 140, hid: 8, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.70%, Val MAPE: 0.66%, Test MAPE: 0.81%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.91%, H: 0.70%\n",
      "Early stopping at epoch 236\n",
      "Rs: 140, hid: 16, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.56%, Val MAPE: 1.08%, Test MAPE: 0.85%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.92%, H: 0.78%\n",
      "Early stopping at epoch 650\n",
      "Rs: 140, hid: 16, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.70%, Val MAPE: 1.29%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.00%, H: 1.03%\n",
      "Early stopping at epoch 128\n",
      "Rs: 140, hid: 16, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.81%, Val MAPE: 1.05%, Test MAPE: 1.07%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.18%, H: 0.96%\n",
      "Early stopping at epoch 727\n",
      "Rs: 140, hid: 16, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.55%, Val MAPE: 1.08%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.09%, H: 0.78%\n",
      "Early stopping at epoch 171\n",
      "Rs: 140, hid: 16, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.85%, Val MAPE: 1.12%, Test MAPE: 1.07%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.04%, H: 1.11%\n",
      "Early stopping at epoch 928\n",
      "Rs: 140, hid: 16, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.53%, Val MAPE: 1.12%, Test MAPE: 0.94%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.07%, H: 0.80%\n",
      "Early stopping at epoch 129\n",
      "Rs: 140, hid: 16, 5 layers, lr: 0.001\n",
      " Train MAPE: 1.03%, Val MAPE: 0.91%, Test MAPE: 1.09%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.15%, H: 1.03%\n",
      "Early stopping at epoch 734\n",
      "Rs: 140, hid: 16, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.53%, Val MAPE: 0.65%, Test MAPE: 0.79%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.88%, H: 0.70%\n",
      "Early stopping at epoch 262\n",
      "Rs: 140, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.62%, Val MAPE: 0.83%, Test MAPE: 0.81%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.86%, H: 0.76%\n",
      "Early stopping at epoch 544\n",
      "Rs: 140, hid: 16, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.72%, Val MAPE: 0.96%, Test MAPE: 0.96%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.91%, H: 1.00%\n",
      "Early stopping at epoch 167\n",
      "Rs: 140, hid: 32, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.64%, Val MAPE: 0.96%, Test MAPE: 1.33%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.17%, H: 1.50%\n",
      "Early stopping at epoch 629\n",
      "Rs: 140, hid: 32, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.46%, Val MAPE: 0.84%, Test MAPE: 1.19%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.06%, H: 1.32%\n",
      "Early stopping at epoch 124\n",
      "Rs: 140, hid: 32, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.68%, Val MAPE: 0.85%, Test MAPE: 1.01%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.10%, H: 0.92%\n",
      "Early stopping at epoch 685\n",
      "Rs: 140, hid: 32, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.41%, Val MAPE: 0.62%, Test MAPE: 1.04%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.95%, H: 1.14%\n",
      "Early stopping at epoch 102\n",
      "Rs: 140, hid: 32, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.74%, Val MAPE: 0.87%, Test MAPE: 0.97%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.92%, H: 1.02%\n",
      "Early stopping at epoch 268\n",
      "Rs: 140, hid: 32, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.52%, Val MAPE: 0.78%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.22%, H: 0.93%\n",
      "Early stopping at epoch 125\n",
      "Rs: 140, hid: 32, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.55%, Val MAPE: 0.85%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.08%, H: 0.82%\n",
      "Early stopping at epoch 357\n",
      "Rs: 140, hid: 32, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.52%, Val MAPE: 0.54%, Test MAPE: 0.98%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.00%, H: 0.97%\n",
      "Early stopping at epoch 86\n",
      "Rs: 140, hid: 32, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.79%, Val MAPE: 0.79%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.06%, H: 0.84%\n",
      "Early stopping at epoch 524\n",
      "Rs: 140, hid: 32, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.52%, Val MAPE: 0.62%, Test MAPE: 0.80%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.77%, H: 0.82%\n",
      "Early stopping at epoch 204\n",
      "Rs: 160, hid: 8, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.80%, Val MAPE: 0.80%, Test MAPE: 0.84%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.71%, H: 0.97%\n",
      "Rs: 160, hid: 8, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.80%, Val MAPE: 1.17%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.70%, H: 1.36%\n",
      "Early stopping at epoch 200\n",
      "Rs: 160, hid: 8, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.71%, Val MAPE: 0.79%, Test MAPE: 0.82%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.65%, H: 0.99%\n",
      "Rs: 160, hid: 8, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.75%, Val MAPE: 0.72%, Test MAPE: 0.81%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.67%, H: 0.95%\n",
      "Early stopping at epoch 439\n",
      "Rs: 160, hid: 8, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.67%, Val MAPE: 0.73%, Test MAPE: 0.76%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.75%, H: 0.76%\n",
      "Rs: 160, hid: 8, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.77%, Val MAPE: 0.54%, Test MAPE: 0.92%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.78%, H: 1.07%\n",
      "Early stopping at epoch 169\n",
      "Rs: 160, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.77%, Val MAPE: 0.65%, Test MAPE: 0.88%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.69%, H: 1.07%\n",
      "Rs: 160, hid: 8, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.75%, Val MAPE: 0.67%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.75%, H: 1.14%\n",
      "Early stopping at epoch 157\n",
      "Rs: 160, hid: 8, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.72%, Val MAPE: 0.68%, Test MAPE: 0.87%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.71%, H: 1.02%\n",
      "Rs: 160, hid: 8, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.74%, Val MAPE: 0.63%, Test MAPE: 0.86%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.70%, H: 1.02%\n",
      "Early stopping at epoch 277\n",
      "Rs: 160, hid: 16, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.60%, Val MAPE: 1.13%, Test MAPE: 0.88%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.77%, H: 0.98%\n",
      "Rs: 160, hid: 16, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.60%, Val MAPE: 0.88%, Test MAPE: 0.88%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.74%, H: 1.02%\n",
      "Early stopping at epoch 242\n",
      "Rs: 160, hid: 16, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.50%, Val MAPE: 0.60%, Test MAPE: 0.85%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.83%, H: 0.87%\n",
      "Early stopping at epoch 938\n",
      "Rs: 160, hid: 16, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.54%, Val MAPE: 0.70%, Test MAPE: 0.92%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.00%, H: 0.84%\n",
      "Early stopping at epoch 260\n",
      "Rs: 160, hid: 16, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.75%, Val MAPE: 0.68%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.96%, H: 1.08%\n",
      "Rs: 160, hid: 16, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.61%, Val MAPE: 0.76%, Test MAPE: 0.92%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.92%, H: 0.92%\n",
      "Early stopping at epoch 113\n",
      "Rs: 160, hid: 16, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.98%, Val MAPE: 1.22%, Test MAPE: 0.97%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.05%, H: 0.89%\n",
      "Early stopping at epoch 807\n",
      "Rs: 160, hid: 16, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.54%, Val MAPE: 0.67%, Test MAPE: 0.74%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.64%, H: 0.83%\n",
      "Early stopping at epoch 159\n",
      "Rs: 160, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 1.11%, Val MAPE: 1.10%, Test MAPE: 1.08%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.16%, H: 1.01%\n",
      "Early stopping at epoch 786\n",
      "Rs: 160, hid: 16, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.64%, Val MAPE: 0.64%, Test MAPE: 0.80%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.81%, H: 0.80%\n",
      "Early stopping at epoch 150\n",
      "Rs: 160, hid: 32, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.50%, Val MAPE: 1.08%, Test MAPE: 0.98%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.83%, H: 1.14%\n",
      "Early stopping at epoch 856\n",
      "Rs: 160, hid: 32, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.46%, Val MAPE: 1.29%, Test MAPE: 0.95%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.99%, H: 0.92%\n",
      "Early stopping at epoch 161\n",
      "Rs: 160, hid: 32, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.84%, Val MAPE: 1.23%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.97%, H: 1.08%\n",
      "Early stopping at epoch 366\n",
      "Rs: 160, hid: 32, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.55%, Val MAPE: 1.25%, Test MAPE: 0.90%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.89%, H: 0.91%\n",
      "Early stopping at epoch 233\n",
      "Rs: 160, hid: 32, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.52%, Val MAPE: 0.99%, Test MAPE: 0.87%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.88%, H: 0.86%\n",
      "Early stopping at epoch 515\n",
      "Rs: 160, hid: 32, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.44%, Val MAPE: 0.90%, Test MAPE: 0.90%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.93%, H: 0.86%\n",
      "Early stopping at epoch 124\n",
      "Rs: 160, hid: 32, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.52%, Val MAPE: 0.82%, Test MAPE: 0.81%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.81%, H: 0.80%\n",
      "Early stopping at epoch 353\n",
      "Rs: 160, hid: 32, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.48%, Val MAPE: 0.75%, Test MAPE: 0.80%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.81%, H: 0.78%\n",
      "Early stopping at epoch 168\n",
      "Rs: 160, hid: 32, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.49%, Val MAPE: 0.80%, Test MAPE: 0.74%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.72%, H: 0.77%\n",
      "Early stopping at epoch 508\n",
      "Rs: 160, hid: 32, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.48%, Val MAPE: 0.84%, Test MAPE: 0.73%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.64%, H: 0.81%\n",
      "Early stopping at epoch 231\n",
      "Rs: 180, hid: 8, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.64%, Val MAPE: 1.41%, Test MAPE: 1.52%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.78%, H: 1.26%\n",
      "Rs: 180, hid: 8, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.87%, Val MAPE: 2.23%, Test MAPE: 1.93%\n",
      "Test MAPE by 'Next': M: nan%, D: 2.47%, H: 1.39%\n",
      "Early stopping at epoch 103\n",
      "Rs: 180, hid: 8, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.63%, Val MAPE: 1.22%, Test MAPE: 2.07%\n",
      "Test MAPE by 'Next': M: nan%, D: 2.00%, H: 2.14%\n",
      "Early stopping at epoch 821\n",
      "Rs: 180, hid: 8, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.63%, Val MAPE: 1.71%, Test MAPE: 1.95%\n",
      "Test MAPE by 'Next': M: nan%, D: 2.20%, H: 1.69%\n",
      "Early stopping at epoch 142\n",
      "Rs: 180, hid: 8, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.62%, Val MAPE: 1.20%, Test MAPE: 1.62%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.53%, H: 1.72%\n",
      "Early stopping at epoch 729\n",
      "Rs: 180, hid: 8, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.67%, Val MAPE: 1.27%, Test MAPE: 1.50%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.47%, H: 1.52%\n",
      "Early stopping at epoch 251\n",
      "Rs: 180, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.58%, Val MAPE: 0.86%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.07%, H: 0.99%\n",
      "Rs: 180, hid: 8, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.60%, Val MAPE: 0.90%, Test MAPE: 1.14%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.10%, H: 1.19%\n",
      "Early stopping at epoch 197\n",
      "Rs: 180, hid: 8, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.54%, Val MAPE: 0.87%, Test MAPE: 1.27%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.35%, H: 1.19%\n",
      "Early stopping at epoch 795\n",
      "Rs: 180, hid: 8, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.64%, Val MAPE: 1.18%, Test MAPE: 1.53%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.50%, H: 1.55%\n",
      "Early stopping at epoch 297\n",
      "Rs: 180, hid: 16, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.50%, Val MAPE: 1.40%, Test MAPE: 2.24%\n",
      "Test MAPE by 'Next': M: nan%, D: 2.38%, H: 2.11%\n",
      "Rs: 180, hid: 16, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.70%, Val MAPE: 1.90%, Test MAPE: 2.88%\n",
      "Test MAPE by 'Next': M: nan%, D: 2.98%, H: 2.79%\n",
      "Early stopping at epoch 234\n",
      "Rs: 180, hid: 16, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.58%, Val MAPE: 1.07%, Test MAPE: 1.48%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.67%, H: 1.28%\n",
      "Rs: 180, hid: 16, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.54%, Val MAPE: 1.37%, Test MAPE: 1.61%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.70%, H: 1.51%\n",
      "Early stopping at epoch 309\n",
      "Rs: 180, hid: 16, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.49%, Val MAPE: 1.06%, Test MAPE: 1.02%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.10%, H: 0.94%\n",
      "Rs: 180, hid: 16, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.63%, Val MAPE: 1.33%, Test MAPE: 1.65%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.61%, H: 1.70%\n",
      "Early stopping at epoch 212\n",
      "Rs: 180, hid: 16, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.69%, Val MAPE: 0.92%, Test MAPE: 1.24%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.34%, H: 1.15%\n",
      "Early stopping at epoch 921\n",
      "Rs: 180, hid: 16, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.52%, Val MAPE: 1.16%, Test MAPE: 1.39%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.61%, H: 1.16%\n",
      "Early stopping at epoch 434\n",
      "Rs: 180, hid: 16, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.48%, Val MAPE: 1.00%, Test MAPE: 0.89%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.87%, H: 0.92%\n",
      "Early stopping at epoch 890\n",
      "Rs: 180, hid: 16, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.55%, Val MAPE: 1.08%, Test MAPE: 0.89%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.87%, H: 0.90%\n",
      "Early stopping at epoch 389\n",
      "Rs: 180, hid: 32, 2 layers, lr: 0.001\n",
      " Train MAPE: 0.47%, Val MAPE: 1.17%, Test MAPE: 1.75%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.97%, H: 1.52%\n",
      "Early stopping at epoch 427\n",
      "Rs: 180, hid: 32, 2 layers, lr: 0.0001\n",
      " Train MAPE: 0.56%, Val MAPE: 1.43%, Test MAPE: 2.31%\n",
      "Test MAPE by 'Next': M: nan%, D: 2.45%, H: 2.17%\n",
      "Early stopping at epoch 150\n",
      "Rs: 180, hid: 32, 3 layers, lr: 0.001\n",
      " Train MAPE: 0.58%, Val MAPE: 1.30%, Test MAPE: 2.03%\n",
      "Test MAPE by 'Next': M: nan%, D: 2.12%, H: 1.93%\n",
      "Early stopping at epoch 637\n",
      "Rs: 180, hid: 32, 3 layers, lr: 0.0001\n",
      " Train MAPE: 0.41%, Val MAPE: 1.34%, Test MAPE: 2.15%\n",
      "Test MAPE by 'Next': M: nan%, D: 2.40%, H: 1.90%\n",
      "Early stopping at epoch 132\n",
      "Rs: 180, hid: 32, 4 layers, lr: 0.001\n",
      " Train MAPE: 0.51%, Val MAPE: 1.08%, Test MAPE: 1.27%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.50%, H: 1.03%\n",
      "Early stopping at epoch 456\n",
      "Rs: 180, hid: 32, 4 layers, lr: 0.0001\n",
      " Train MAPE: 0.62%, Val MAPE: 1.43%, Test MAPE: 1.29%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.37%, H: 1.21%\n",
      "Early stopping at epoch 198\n",
      "Rs: 180, hid: 32, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.44%, Val MAPE: 0.87%, Test MAPE: 0.92%\n",
      "Test MAPE by 'Next': M: nan%, D: 0.97%, H: 0.87%\n",
      "Early stopping at epoch 442\n",
      "Rs: 180, hid: 32, 5 layers, lr: 0.0001\n",
      " Train MAPE: 0.42%, Val MAPE: 1.29%, Test MAPE: 1.41%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.51%, H: 1.31%\n",
      "Early stopping at epoch 436\n",
      "Rs: 180, hid: 32, 6 layers, lr: 0.001\n",
      " Train MAPE: 0.29%, Val MAPE: 0.99%, Test MAPE: 0.98%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.04%, H: 0.92%\n",
      "Early stopping at epoch 462\n",
      "Rs: 180, hid: 32, 6 layers, lr: 0.0001\n",
      " Train MAPE: 0.56%, Val MAPE: 1.69%, Test MAPE: 1.88%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.88%, H: 1.89%\n"
     ]
    }
   ],
   "source": [
    "random_states = [100, 120, 140, 160, 180]\n",
    "bs = 12\n",
    "ep = 1000\n",
    "hids = [8, 16, 32]\n",
    "layers = [2, 3, 4, 5, 6]\n",
    "lrs = [1e-3, 1e-4]\n",
    "\n",
    "Source_Domain = ['D', 'H']\n",
    "Target_Domain = ['M']\n",
    "\n",
    "results_df = pd.DataFrame(columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE'])\n",
    "\n",
    "X, y = Get_Data(dat)\n",
    "\n",
    "X_sc, X_ta, y_sc, y_ta = Domain_Split(X, y, Target_Domain)\n",
    "\n",
    "for rs, hid, nl, lr in product(random_states, hids, layers, lrs):\n",
    "    setRandomSeed(rs)\n",
    "\n",
    "    X_tn, X_te, y_tn, y_te = Even_Split(X_sc, y_sc, Target_Domain, 1/3, rs)\n",
    "    X_tr, X_va, y_tr, y_va = Even_Split(X_tn, y_tn, Target_Domain, 1/6, rs)\n",
    "\n",
    "    next_map = {'M': 0, 'D': 1, 'H': 2}\n",
    "    get_next = lambda idx: torch.nn.functional.one_hot(torch.tensor([next_map[i] for i in idx.get_level_values(\"Next\")]), num_classes=3).float()\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "    X_tr_std = std_scaler.fit_transform(X_tr)\n",
    "    X_val_std = std_scaler.transform(X_va)\n",
    "    X_te_std = std_scaler.transform(X_te)\n",
    "    \n",
    "    X_train = torch.Tensor(X_tr_std)\n",
    "    X_val = torch.Tensor(X_val_std)\n",
    "    X_test = torch.Tensor(X_te_std)\n",
    "    \n",
    "    y_train = torch.Tensor(y_tr[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_val = torch.Tensor(y_va[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_test = torch.Tensor(y_te[\"Next_SOH\"].values).unsqueeze(1)\n",
    "\n",
    "    next_train = get_next(X_tr.index)\n",
    "    next_val = get_next(X_va.index)\n",
    "    next_test = get_next(X_te.index)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, next_train, y_train), batch_size=bs, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, next_val, y_val), batch_size=bs, shuffle = False)\n",
    "    test_loader = DataLoader(TensorDataset(X_test, next_test, y_test), batch_size=bs, shuffle = False)\n",
    "    \n",
    "    model = MLP(hidden_dim=hid, num_layers=nl)\n",
    "    trainer = Trainer(model, lr=lr, epoch = ep, random_seed = rs)\n",
    "    \n",
    "    trainer.train(train_loader, val_loader, test_loader)\n",
    "\n",
    "    info = [rs, hid, nl, lr]\n",
    "    results = plot_results(info, train_loader, val_loader, test_loader, plot = False)\n",
    "\n",
    "    temp_df = pd.DataFrame(info+list(results)).T\n",
    "    temp_df.columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']\n",
    "    results_df = pd.concat([results_df, temp_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4819d6c3-d539-4de0-9e83-ed6af617fa12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hid</th>\n",
       "      <th>nl</th>\n",
       "      <th>lr</th>\n",
       "      <th>Train MAPE</th>\n",
       "      <th>Val MAPE</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Next M MAPE</th>\n",
       "      <th>Next D MAPE</th>\n",
       "      <th>Next H MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.638593</td>\n",
       "      <td>0.765966</td>\n",
       "      <td>0.891031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.862189</td>\n",
       "      <td>0.919873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.673940</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>1.065181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.017652</td>\n",
       "      <td>1.112709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.724763</td>\n",
       "      <td>0.807115</td>\n",
       "      <td>0.944921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875983</td>\n",
       "      <td>1.013859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.542213</td>\n",
       "      <td>0.822736</td>\n",
       "      <td>0.919734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.954309</td>\n",
       "      <td>0.885159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.639304</td>\n",
       "      <td>0.835669</td>\n",
       "      <td>0.856863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814597</td>\n",
       "      <td>0.899128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.681245</td>\n",
       "      <td>0.854044</td>\n",
       "      <td>0.997318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>1.002832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.529125</td>\n",
       "      <td>0.855680</td>\n",
       "      <td>0.852480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.895139</td>\n",
       "      <td>0.809822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.713490</td>\n",
       "      <td>0.858679</td>\n",
       "      <td>1.055518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.943632</td>\n",
       "      <td>1.167404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.660869</td>\n",
       "      <td>0.863296</td>\n",
       "      <td>0.955679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.932096</td>\n",
       "      <td>0.979262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.548536</td>\n",
       "      <td>0.908169</td>\n",
       "      <td>1.015917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039692</td>\n",
       "      <td>0.992143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.607991</td>\n",
       "      <td>0.908847</td>\n",
       "      <td>1.096299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.144945</td>\n",
       "      <td>1.047653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.677056</td>\n",
       "      <td>0.922679</td>\n",
       "      <td>1.012049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987970</td>\n",
       "      <td>1.036128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.546946</td>\n",
       "      <td>0.938841</td>\n",
       "      <td>1.129173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.151355</td>\n",
       "      <td>1.106991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.753355</td>\n",
       "      <td>0.950601</td>\n",
       "      <td>0.923406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.973960</td>\n",
       "      <td>0.872852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.751009</td>\n",
       "      <td>0.954845</td>\n",
       "      <td>1.100719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.108026</td>\n",
       "      <td>1.093412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.629408</td>\n",
       "      <td>0.955789</td>\n",
       "      <td>0.945569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006391</td>\n",
       "      <td>0.884748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.812439</td>\n",
       "      <td>0.974948</td>\n",
       "      <td>0.975753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039035</td>\n",
       "      <td>0.912471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.616284</td>\n",
       "      <td>0.979806</td>\n",
       "      <td>1.117929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.108278</td>\n",
       "      <td>1.127580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.920162</td>\n",
       "      <td>0.981579</td>\n",
       "      <td>1.148193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.130899</td>\n",
       "      <td>1.165488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.532103</td>\n",
       "      <td>1.000070</td>\n",
       "      <td>0.992611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.056910</td>\n",
       "      <td>0.928311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.566942</td>\n",
       "      <td>1.014970</td>\n",
       "      <td>1.017937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998156</td>\n",
       "      <td>1.037717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.687438</td>\n",
       "      <td>1.065906</td>\n",
       "      <td>1.051641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.067299</td>\n",
       "      <td>1.035983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.980821</td>\n",
       "      <td>1.088308</td>\n",
       "      <td>1.222644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.209971</td>\n",
       "      <td>1.235317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.589705</td>\n",
       "      <td>1.095669</td>\n",
       "      <td>1.238214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.156695</td>\n",
       "      <td>1.319732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.648019</td>\n",
       "      <td>1.103528</td>\n",
       "      <td>1.222258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.151534</td>\n",
       "      <td>1.292982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.709497</td>\n",
       "      <td>1.109473</td>\n",
       "      <td>1.236458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.234833</td>\n",
       "      <td>1.238082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.531811</td>\n",
       "      <td>1.201637</td>\n",
       "      <td>1.327129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.251612</td>\n",
       "      <td>1.402645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.670928</td>\n",
       "      <td>1.224301</td>\n",
       "      <td>1.357642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.334952</td>\n",
       "      <td>1.380333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.780921</td>\n",
       "      <td>1.260549</td>\n",
       "      <td>1.218048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.144769</td>\n",
       "      <td>1.291328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.548454</td>\n",
       "      <td>1.341325</td>\n",
       "      <td>1.325392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.355600</td>\n",
       "      <td>1.295183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     hid   nl      lr  Train MAPE  Val MAPE  Test MAPE  Next M MAPE  \\\n",
       "7    8.0  5.0  0.0010    0.638593  0.765966   0.891031          NaN   \n",
       "3    8.0  3.0  0.0010    0.673940  0.805833   1.065181          NaN   \n",
       "6    8.0  5.0  0.0001    0.724763  0.807115   0.944921          NaN   \n",
       "16  16.0  5.0  0.0001    0.542213  0.822736   0.919734          NaN   \n",
       "18  16.0  6.0  0.0001    0.639304  0.835669   0.856863          NaN   \n",
       "5    8.0  4.0  0.0010    0.681245  0.854044   0.997318          NaN   \n",
       "29  32.0  6.0  0.0010    0.529125  0.855680   0.852480          NaN   \n",
       "4    8.0  4.0  0.0001    0.713490  0.858679   1.055518          NaN   \n",
       "15  16.0  4.0  0.0010    0.660869  0.863296   0.955679          NaN   \n",
       "26  32.0  5.0  0.0001    0.548536  0.908169   1.015917          NaN   \n",
       "13  16.0  3.0  0.0010    0.607991  0.908847   1.096299          NaN   \n",
       "1    8.0  2.0  0.0010    0.677056  0.922679   1.012049          NaN   \n",
       "12  16.0  3.0  0.0001    0.546946  0.938841   1.129173          NaN   \n",
       "19  16.0  6.0  0.0010    0.753355  0.950601   0.923406          NaN   \n",
       "2    8.0  3.0  0.0001    0.751009  0.954845   1.100719          NaN   \n",
       "27  32.0  5.0  0.0010    0.629408  0.955789   0.945569          NaN   \n",
       "17  16.0  5.0  0.0010    0.812439  0.974948   0.975753          NaN   \n",
       "14  16.0  4.0  0.0001    0.616284  0.979806   1.117929          NaN   \n",
       "9    8.0  6.0  0.0010    0.920162  0.981579   1.148193          NaN   \n",
       "24  32.0  4.0  0.0001    0.532103  1.000070   0.992611          NaN   \n",
       "28  32.0  6.0  0.0001    0.566942  1.014970   1.017937          NaN   \n",
       "25  32.0  4.0  0.0010    0.687438  1.065906   1.051641          NaN   \n",
       "8    8.0  6.0  0.0001    0.980821  1.088308   1.222644          NaN   \n",
       "21  32.0  2.0  0.0010    0.589705  1.095669   1.238214          NaN   \n",
       "11  16.0  2.0  0.0010    0.648019  1.103528   1.222258          NaN   \n",
       "23  32.0  3.0  0.0010    0.709497  1.109473   1.236458          NaN   \n",
       "22  32.0  3.0  0.0001    0.531811  1.201637   1.327129          NaN   \n",
       "10  16.0  2.0  0.0001    0.670928  1.224301   1.357642          NaN   \n",
       "0    8.0  2.0  0.0001    0.780921  1.260549   1.218048          NaN   \n",
       "20  32.0  2.0  0.0001    0.548454  1.341325   1.325392          NaN   \n",
       "\n",
       "    Next D MAPE  Next H MAPE  \n",
       "7      0.862189     0.919873  \n",
       "3      1.017652     1.112709  \n",
       "6      0.875983     1.013859  \n",
       "16     0.954309     0.885159  \n",
       "18     0.814597     0.899128  \n",
       "5      0.991803     1.002832  \n",
       "29     0.895139     0.809822  \n",
       "4      0.943632     1.167404  \n",
       "15     0.932096     0.979262  \n",
       "26     1.039692     0.992143  \n",
       "13     1.144945     1.047653  \n",
       "1      0.987970     1.036128  \n",
       "12     1.151355     1.106991  \n",
       "19     0.973960     0.872852  \n",
       "2      1.108026     1.093412  \n",
       "27     1.006391     0.884748  \n",
       "17     1.039035     0.912471  \n",
       "14     1.108278     1.127580  \n",
       "9      1.130899     1.165488  \n",
       "24     1.056910     0.928311  \n",
       "28     0.998156     1.037717  \n",
       "25     1.067299     1.035983  \n",
       "8      1.209971     1.235317  \n",
       "21     1.156695     1.319732  \n",
       "11     1.151534     1.292982  \n",
       "23     1.234833     1.238082  \n",
       "22     1.251612     1.402645  \n",
       "10     1.334952     1.380333  \n",
       "0      1.144769     1.291328  \n",
       "20     1.355600     1.295183  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = results_df.groupby(['hid', 'nl', 'lr'])[['Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']].mean().reset_index()\n",
    "\n",
    "summary_df_sorted = summary_df.sort_values(by = 'Val MAPE', ascending = True)\n",
    "summary_df_sorted\n",
    "\n",
    "results_df.to_csv(f\"MLP_Domain_Source_{Source_Domain}_next_info.csv\")\n",
    "summary_df_sorted.to_csv(f\"MLP_Domain_Source_{Source_Domain}_next_info_sum.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82878289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hid    8.000\n",
       "nl     5.000\n",
       "lr     0.001\n",
       "Name: 7, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyper_parameter = summary_df_sorted.iloc[0][['hid', 'nl', 'lr']]\n",
    "best_hyper_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2dbb98c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 257\n",
      "Early stopping at epoch 299\n",
      "Rs: 100, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.63%, Val MAPE: 0.94%, Test MAPE: 1.30%\n",
      "Test MAPE by 'Next': M: 1.30%, D: nan%, H: nan%\n",
      "Rs: 100, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 1.51%, Val MAPE: 1.44%, Test MAPE: 1.84%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.46%, H: 2.23%\n",
      "Early stopping at epoch 180\n",
      "Early stopping at epoch 448\n",
      "Rs: 120, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.80%, Val MAPE: 0.74%, Test MAPE: 1.13%\n",
      "Test MAPE by 'Next': M: 1.13%, D: nan%, H: nan%\n",
      "Rs: 120, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.90%, Val MAPE: 0.80%, Test MAPE: 1.00%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.02%, H: 0.98%\n",
      "Early stopping at epoch 209\n",
      "Early stopping at epoch 611\n",
      "Rs: 140, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.49%, Val MAPE: 1.00%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 1.11%, D: nan%, H: nan%\n",
      "Rs: 140, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.88%, Val MAPE: 1.12%, Test MAPE: 0.97%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.00%, H: 0.93%\n",
      "Early stopping at epoch 169\n",
      "Early stopping at epoch 328\n",
      "Rs: 160, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.97%, Val MAPE: 1.07%, Test MAPE: 1.35%\n",
      "Test MAPE by 'Next': M: 1.35%, D: nan%, H: nan%\n",
      "Rs: 160, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 1.25%, Val MAPE: 1.05%, Test MAPE: 1.32%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.19%, H: 1.45%\n",
      "Early stopping at epoch 251\n",
      "Early stopping at epoch 300\n",
      "Rs: 180, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.70%, Val MAPE: 1.17%, Test MAPE: 1.11%\n",
      "Test MAPE by 'Next': M: 1.11%, D: nan%, H: nan%\n",
      "Rs: 180, hid: 8, 5 layers, lr: 0.001\n",
      " Train MAPE: 0.58%, Val MAPE: 0.87%, Test MAPE: 1.03%\n",
      "Test MAPE by 'Next': M: nan%, D: 1.07%, H: 0.99%\n"
     ]
    }
   ],
   "source": [
    "hid = int(best_hyper_parameter['hid'])\n",
    "nl  = int(best_hyper_parameter['nl'])\n",
    "lr  = float(best_hyper_parameter['lr'])\n",
    "\n",
    "results_df_Ta = pd.DataFrame(columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE'])\n",
    "results_df_Sc = pd.DataFrame(columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE'])\n",
    "\n",
    "\n",
    "for rs in random_states:\n",
    "    setRandomSeed(rs)\n",
    "\n",
    "    X_tn, X_te, y_tn, y_te = Even_Split(X_sc, y_sc, Target_Domain, 1/3, rs)\n",
    "    X_tr, X_va, y_tr, y_va = Even_Split(X_tn, y_tn, Target_Domain, 1/6, rs)\n",
    "\n",
    "    next_map = {'M': 0, 'D': 1, 'H': 2}\n",
    "    get_next = lambda idx: torch.nn.functional.one_hot(torch.tensor([next_map[i] for i in idx.get_level_values(\"Next\")]), num_classes=3).float()\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "    X_tr_std = std_scaler.fit_transform(X_tr)\n",
    "    X_val_std = std_scaler.transform(X_va)\n",
    "    X_te_std = std_scaler.transform(X_te)\n",
    "    \n",
    "    X_train = torch.Tensor(X_tr_std)\n",
    "    X_val = torch.Tensor(X_val_std)\n",
    "    X_test = torch.Tensor(X_te_std)\n",
    "    \n",
    "    y_train = torch.Tensor(y_tr[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_val = torch.Tensor(y_va[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_test = torch.Tensor(y_te[\"Next_SOH\"].values).unsqueeze(1)\n",
    "\n",
    "    next_train = get_next(X_tr.index)\n",
    "    next_val = get_next(X_va.index)\n",
    "    next_test = get_next(X_te.index)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, next_train, y_train), batch_size=bs, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, next_val, y_val), batch_size=bs, shuffle = False)\n",
    "    test_loader = DataLoader(TensorDataset(X_test, next_test, y_test), batch_size=bs, shuffle = False)\n",
    "    \n",
    "    model = MLP(hidden_dim=hid, num_layers=nl)\n",
    "    trainer = Trainer(model, lr=lr, epoch = ep, random_seed = rs)\n",
    "    \n",
    "    trainer.train(train_loader, val_loader, test_loader)\n",
    "\n",
    "    info = [rs, hid, nl, lr]\n",
    "    #results = plot_results(info, train_loader, val_loader, test_loader, plot = False)\n",
    "\n",
    "    trained_model = trainer.model\n",
    "    \n",
    "    for p in trained_model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    first_linear = trained_model.model[0]\n",
    "\n",
    "    first_linear.weight.requires_grad = True\n",
    "    first_linear.bias.requires_grad   = True  \n",
    "    \n",
    "    learn_idx = {\n",
    "        'M': -3,\n",
    "        'D': -2,\n",
    "        'H': -1\n",
    "    }\n",
    "\n",
    "    mask_w = torch.zeros_like(first_linear.weight)\n",
    "    for ta in Target_Domain:\n",
    "        mask_w[:, learn_idx[ta]] = 1.0\n",
    "\n",
    "    mask_b = torch.zeros_like(first_linear.bias)\n",
    "    for ta in Target_Domain:\n",
    "        mask_b[learn_idx[ta]] = 1.0\n",
    "\n",
    "    def grad_hook_weight(grad):\n",
    "        return grad * mask_w\n",
    "\n",
    "    def grad_hook_bias(grad):\n",
    "        return grad * mask_b\n",
    "\n",
    "    h1 = first_linear.weight.register_hook(grad_hook_weight)\n",
    "    h2 = first_linear.bias.register_hook(grad_hook_bias)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [p for p in trained_model.parameters() if p.requires_grad],\n",
    "        lr=lr,\n",
    "        weight_decay=0.0 \n",
    "    )\n",
    "    \n",
    "    X_ta_tn, X_ta_te, y_ta_tn, y_ta_te = Even_Split(X_ta, y_ta, Source_Domain, 8/9, rs)\n",
    "    X_ta_tr, X_ta_va, y_ta_tr, y_ta_va = Even_Split(X_ta_tn, y_ta_tn, Source_Domain, 1/6, rs)\n",
    "\n",
    "    X_ta_tr_std  = std_scaler.transform(X_ta_tr)\n",
    "    X_ta_val_std = std_scaler.transform(X_ta_va)\n",
    "    X_ta_te_std  = std_scaler.transform(X_ta_te)\n",
    "\n",
    "    X_ta_train = torch.Tensor(X_ta_tr_std)\n",
    "    X_ta_val   = torch.Tensor(X_ta_val_std)\n",
    "    X_ta_test  = torch.Tensor(X_ta_te_std)\n",
    "    \n",
    "    y_ta_train = torch.Tensor(y_ta_tr[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_ta_val   = torch.Tensor(y_ta_va[\"Next_SOH\"].values).unsqueeze(1)\n",
    "    y_ta_test  = torch.Tensor(y_ta_te[\"Next_SOH\"].values).unsqueeze(1)\n",
    "\n",
    "    next_ta_train = get_next(X_ta_tr.index)\n",
    "    next_ta_val   = get_next(X_ta_va.index)\n",
    "    next_ta_test  = get_next(X_ta_te.index)\n",
    "\n",
    "    train_ta_loader = DataLoader(TensorDataset(X_ta_train, next_ta_train, y_ta_train), batch_size=bs, shuffle=True)\n",
    "    val_ta_loader   = DataLoader(TensorDataset(X_ta_val, next_ta_val, y_ta_val), batch_size=bs, shuffle = False)\n",
    "    test_ta_loader  = DataLoader(TensorDataset(X_ta_test, next_ta_test, y_ta_test), batch_size=bs, shuffle = False)\n",
    "\n",
    "    trainer = Trainer(trained_model, lr=lr, epoch = ep, random_seed = rs, optimizer = optimizer)\n",
    "    \n",
    "    trainer.train(train_ta_loader, val_ta_loader, test_ta_loader)\n",
    "\n",
    "    info = [rs, hid, nl, lr]\n",
    "\n",
    "    results_Ta = plot_results(info, train_ta_loader, val_ta_loader, test_ta_loader, plot = False)\n",
    "    results_Sc = plot_results(info, train_loader, val_loader, test_loader, plot = False)\n",
    "\n",
    "    temp_df_Ta = pd.DataFrame(info+list(results_Ta)).T\n",
    "    temp_df_Sc = pd.DataFrame(info+list(results_Sc)).T\n",
    "\n",
    "    temp_df_Ta.columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']\n",
    "    temp_df_Sc.columns = ['rs', 'hid', 'nl', 'lr', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']\n",
    "\n",
    "    results_df_Ta = pd.concat([results_df_Ta, temp_df_Ta])\n",
    "    results_df_Sc = pd.concat([results_df_Sc, temp_df_Sc])\n",
    "\n",
    "    h1.remove()\n",
    "    h2.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3531aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hid</th>\n",
       "      <th>nl</th>\n",
       "      <th>lr</th>\n",
       "      <th>Train MAPE</th>\n",
       "      <th>Val MAPE</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Next M MAPE</th>\n",
       "      <th>Next D MAPE</th>\n",
       "      <th>Next H MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.022326</td>\n",
       "      <td>1.053898</td>\n",
       "      <td>1.231049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.146601</td>\n",
       "      <td>1.315498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hid   nl     lr  Train MAPE  Val MAPE  Test MAPE  Next M MAPE  Next D MAPE  \\\n",
       "0  8.0  5.0  0.001    1.022326  1.053898   1.231049          NaN     1.146601   \n",
       "\n",
       "   Next H MAPE  \n",
       "0     1.315498  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hid</th>\n",
       "      <th>nl</th>\n",
       "      <th>lr</th>\n",
       "      <th>Train MAPE</th>\n",
       "      <th>Val MAPE</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Next M MAPE</th>\n",
       "      <th>Next D MAPE</th>\n",
       "      <th>Next H MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.718268</td>\n",
       "      <td>0.984611</td>\n",
       "      <td>1.201515</td>\n",
       "      <td>1.201515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hid   nl     lr  Train MAPE  Val MAPE  Test MAPE  Next M MAPE  Next D MAPE  \\\n",
       "0  8.0  5.0  0.001    0.718268  0.984611   1.201515     1.201515          NaN   \n",
       "\n",
       "   Next H MAPE  \n",
       "0          NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df_Ta = results_df_Ta.groupby(['hid', 'nl', 'lr'])[['Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']].mean().reset_index()\n",
    "summary_df_Sc = results_df_Sc.groupby(['hid', 'nl', 'lr'])[['Train MAPE', 'Val MAPE', 'Test MAPE', 'Next M MAPE', 'Next D MAPE', 'Next H MAPE']].mean().reset_index()\n",
    "\n",
    "summary_df_Sc\n",
    "summary_df_Ta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
